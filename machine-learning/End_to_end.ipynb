{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers.merge import concatenate\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.models import Sequential\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "Wearable = pd.read_excel('Data_Folder/Demo3_5/Wearable_Sensor_Data.xlsx',header=0,index_col=0)\n",
    "Stationary = pd.read_csv('Data_Folder/Demo3_5/Stationary_imputation.csv',delimiter=',',header=0,index_col=False)\n",
    "Weather = pd.read_csv('Data_Folder/Demo3_5/weather_3_5.txt',delimiter=',',header=None,index_col=False)\n",
    "GPS = pd.read_csv('Data_Folder/Demo3_5/UPDATED_GPS.csv', delimiter=',', header=0)\n",
    "#Stationary.columns=['time','violet','blue','green','yellow','orange','red']\n",
    "Weather.columns=['DTime','Bar','TempIn','HumIn','TempOut','Wind','Wind10','Wdir','HumOut','RainRate','UV','Solar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/ipykernel_launcher.py:11: FutureWarning: set_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "Wearable = Wearable.iloc[147:,:] # 8:15 - 11:02\n",
    "Weather = Weather.iloc[2925:3912,:]\n",
    "GPS = GPS.iloc[15:183,:]\n",
    "\n",
    "Wearable.index = range(Wearable.shape[0])\n",
    "Weather.index = range(Weather.shape[0])\n",
    "\n",
    "#Wearable.index = range(Wearable.shape[0])\n",
    "from datetime import datetime\n",
    "for i in range(Weather.shape[0]):\n",
    "    Weather.set_value(i, 'New_Time', datetime.strptime(Weather.iloc[i,0], '%Y-%m-%d %H:%M:%S'))   \n",
    "\n",
    "Weather = Weather.resample('1T', on='New_Time').mean()\n",
    "\n",
    "Wearable.drop(columns=['time','second','H1','H2'],inplace=True)\n",
    "Weather.drop(columns=['RainRate'],inplace=True)\n",
    "Stationary.drop(columns=['time'],inplace=True)\n",
    "GPS.drop(columns=['time','isDataPoint','within15','distanceFromSensor','distanceFromSupercomputerSensor','locationType'],inplace=True)\n",
    "\n",
    "\n",
    "GPS.index=range(GPS.shape[0])\n",
    "\n",
    "GPS['insideOutsideVal'] = pd.Categorical(GPS['insideOutsideVal'])\n",
    "dfDummies = pd.get_dummies(GPS['insideOutsideVal'], prefix = 'category')\n",
    "GPS = pd.concat([GPS, dfDummies], axis=1)\n",
    "\n",
    "GPS.drop(columns=['insideOutsideVal'],inplace=True)\n",
    "\n",
    "Stationary.index = range(Stationary.shape[0])\n",
    "Weather.index = range(Weather.shape[0])\n",
    "\n",
    "Stationary = Stationary.fillna(method='ffill')\n",
    "#Wearable = Wearable.fillna(method='ffill')\n",
    "Weather = Weather.fillna(method='ffill')\n",
    "\n",
    "ALL = pd.concat([Weather, Stationary, GPS],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'latitude', u'longitude', u'speed', u'category_Inside'], dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPS.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(ALL, Wearable, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/site-packages/pandas/core/frame.py:3697: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  errors=errors)\n"
     ]
    }
   ],
   "source": [
    "GPS_label_train = pd.DataFrame(X_train.iloc[:,-1])\n",
    "X_train.drop(columns=['category_Inside'],inplace=True)\n",
    "GPS_label_test = pd.DataFrame(X_test.iloc[:,-1])\n",
    "X_test.drop(columns=['category_Inside'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "X_train_weather = X_train[:,:10]\n",
    "X_train_stationary = X_train[:,10:16]\n",
    "X_train_GPS = X_train[:,16:]\n",
    "X_test_weather = X_test[:,:10]\n",
    "X_test_stationary = X_test[:,10:16]\n",
    "X_test_GPS = X_test[:,16:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 134 samples, validate on 134 samples\n",
      "Epoch 1/5000\n",
      "134/134 [==============================] - 2s 12ms/step - loss: 71004020.2799 - val_loss: 71003422.8171\n",
      "Epoch 2/5000\n",
      "134/134 [==============================] - 0s 367us/step - loss: 71002536.5948 - val_loss: 70999905.0469\n",
      "Epoch 3/5000\n",
      "134/134 [==============================] - 0s 352us/step - loss: 70992430.9748 - val_loss: 70938318.9879\n",
      "Epoch 4/5000\n",
      "134/134 [==============================] - 0s 374us/step - loss: 70707403.4888 - val_loss: 70023718.4528\n",
      "Epoch 5/5000\n",
      "134/134 [==============================] - 0s 352us/step - loss: 69665973.9403 - val_loss: 68008589.4985\n",
      "Epoch 6/5000\n",
      "134/134 [==============================] - 0s 404us/step - loss: 67875980.6002 - val_loss: 68992411.8322\n",
      "Epoch 7/5000\n",
      "134/134 [==============================] - 0s 388us/step - loss: 63843237.2278 - val_loss: 55115833.4776\n",
      "Epoch 8/5000\n",
      "134/134 [==============================] - 0s 278us/step - loss: 66591676.7500 - val_loss: 57124618.9179\n",
      "Epoch 9/5000\n",
      "134/134 [==============================] - 0s 315us/step - loss: 56687897.4049 - val_loss: 80639947.2239\n",
      "Epoch 10/5000\n",
      "134/134 [==============================] - 0s 355us/step - loss: 60464748.6567 - val_loss: 62326329.6057\n",
      "Epoch 11/5000\n",
      "134/134 [==============================] - 0s 363us/step - loss: 51100397.3361 - val_loss: 46308819.4459\n",
      "Epoch 12/5000\n",
      "134/134 [==============================] - 0s 355us/step - loss: 48185465.9104 - val_loss: 46451872.5187\n",
      "Epoch 13/5000\n",
      "134/134 [==============================] - 0s 356us/step - loss: 48743899.1898 - val_loss: 42317618.9272\n",
      "Epoch 14/5000\n",
      "134/134 [==============================] - 0s 336us/step - loss: 51542738.3731 - val_loss: 52432219.6534\n",
      "Epoch 15/5000\n",
      "134/134 [==============================] - 0s 346us/step - loss: 49406638.3881 - val_loss: 41995449.4030\n",
      "Epoch 16/5000\n",
      "134/134 [==============================] - 0s 344us/step - loss: 49410501.5101 - val_loss: 43189749.8216\n",
      "Epoch 17/5000\n",
      "134/134 [==============================] - 0s 344us/step - loss: 54340615.5312 - val_loss: 45743877.8562\n",
      "Epoch 18/5000\n",
      "134/134 [==============================] - 0s 320us/step - loss: 43526471.5616 - val_loss: 46898780.6890\n",
      "Epoch 19/5000\n",
      "134/134 [==============================] - 0s 381us/step - loss: 40932289.5336 - val_loss: 33428824.2689\n",
      "Epoch 20/5000\n",
      "134/134 [==============================] - 0s 539us/step - loss: 35354531.8721 - val_loss: 41085779.4178\n",
      "Epoch 21/5000\n",
      "134/134 [==============================] - 0s 480us/step - loss: 66988344.5634 - val_loss: 50165465.5845\n",
      "Epoch 22/5000\n",
      "134/134 [==============================] - 0s 475us/step - loss: 44359428.8479 - val_loss: 34804596.6287\n",
      "Epoch 23/5000\n",
      "134/134 [==============================] - 0s 436us/step - loss: 33355631.0312 - val_loss: 33097578.5326\n",
      "Epoch 24/5000\n",
      "134/134 [==============================] - 0s 304us/step - loss: 35553390.8209 - val_loss: 91783586.6269\n",
      "Epoch 25/5000\n",
      "134/134 [==============================] - 0s 347us/step - loss: 35040580.5965 - val_loss: 33791835.7831\n",
      "Epoch 26/5000\n",
      "134/134 [==============================] - 0s 315us/step - loss: 33391145.9210 - val_loss: 31861855.4949\n",
      "Epoch 27/5000\n",
      "134/134 [==============================] - 0s 335us/step - loss: 38126299.3302 - val_loss: 59397173.5667\n",
      "Epoch 28/5000\n",
      "134/134 [==============================] - 0s 438us/step - loss: 39358502.2755 - val_loss: 30428287.7376\n",
      "Epoch 29/5000\n",
      "134/134 [==============================] - 0s 391us/step - loss: 34485791.5373 - val_loss: 30745584.3537\n",
      "Epoch 30/5000\n",
      "134/134 [==============================] - 0s 347us/step - loss: 35453321.9403 - val_loss: 44227288.3659\n",
      "Epoch 31/5000\n",
      "134/134 [==============================] - 0s 360us/step - loss: 46567376.0924 - val_loss: 29170251.1822\n",
      "Epoch 32/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 29266519.7938 - val_loss: 31815082.2987\n",
      "Epoch 33/5000\n",
      "134/134 [==============================] - 0s 381us/step - loss: 36614851.5858 - val_loss: 45378729.4756\n",
      "Epoch 34/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 42537345.0536 - val_loss: 30798345.5656\n",
      "Epoch 35/5000\n",
      "134/134 [==============================] - 0s 311us/step - loss: 32408951.5522 - val_loss: 35941666.1807\n",
      "Epoch 36/5000\n",
      "134/134 [==============================] - 0s 387us/step - loss: 25665150.5610 - val_loss: 36441167.5624\n",
      "Epoch 37/5000\n",
      "134/134 [==============================] - 0s 422us/step - loss: 31201590.7536 - val_loss: 24719562.1337\n",
      "Epoch 38/5000\n",
      "134/134 [==============================] - 0s 463us/step - loss: 28227978.3684 - val_loss: 35420531.8451\n",
      "Epoch 39/5000\n",
      "134/134 [==============================] - 0s 403us/step - loss: 33811308.0970 - val_loss: 27462365.0728\n",
      "Epoch 40/5000\n",
      "134/134 [==============================] - 0s 445us/step - loss: 29346005.5259 - val_loss: 36558723.5077\n",
      "Epoch 41/5000\n",
      "134/134 [==============================] - 0s 449us/step - loss: 32271338.2803 - val_loss: 28366408.2341\n",
      "Epoch 42/5000\n",
      "134/134 [==============================] - 0s 474us/step - loss: 31410794.3918 - val_loss: 27847181.0235\n",
      "Epoch 43/5000\n",
      "134/134 [==============================] - 0s 419us/step - loss: 31898690.5583 - val_loss: 25896120.4789\n",
      "Epoch 44/5000\n",
      "134/134 [==============================] - 0s 409us/step - loss: 30411454.0858 - val_loss: 31714795.4203\n",
      "Epoch 45/5000\n",
      "134/134 [==============================] - 0s 395us/step - loss: 26981175.0360 - val_loss: 24326120.2815\n",
      "Epoch 46/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 27295851.5625 - val_loss: 26001442.1439\n",
      "Epoch 47/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 24925324.6416 - val_loss: 30715079.4646\n",
      "Epoch 48/5000\n",
      "134/134 [==============================] - 0s 403us/step - loss: 28362934.3582 - val_loss: 22906287.6353\n",
      "Epoch 49/5000\n",
      "134/134 [==============================] - 0s 331us/step - loss: 34281738.4478 - val_loss: 27018998.3582\n",
      "Epoch 50/5000\n",
      "134/134 [==============================] - 0s 344us/step - loss: 31523785.3153 - val_loss: 43643833.7083\n",
      "Epoch 51/5000\n",
      "134/134 [==============================] - 0s 395us/step - loss: 38319362.3130 - val_loss: 32139254.5062\n",
      "Epoch 52/5000\n",
      "134/134 [==============================] - 0s 337us/step - loss: 27769252.4604 - val_loss: 23150062.7873\n",
      "Epoch 53/5000\n",
      "134/134 [==============================] - 0s 325us/step - loss: 25963515.8097 - val_loss: 23085258.4397\n",
      "Epoch 54/5000\n",
      "134/134 [==============================] - 0s 365us/step - loss: 25473369.0644 - val_loss: 23258409.2081\n",
      "Epoch 55/5000\n",
      "134/134 [==============================] - 0s 385us/step - loss: 27935143.2404 - val_loss: 22274604.3224\n",
      "Epoch 56/5000\n",
      "134/134 [==============================] - 0s 455us/step - loss: 23568192.7994 - val_loss: 22322234.4093\n",
      "Epoch 57/5000\n",
      "134/134 [==============================] - 0s 378us/step - loss: 23374621.8748 - val_loss: 24122695.2852\n",
      "Epoch 58/5000\n",
      "134/134 [==============================] - 0s 402us/step - loss: 24588418.2178 - val_loss: 25369058.9074\n",
      "Epoch 59/5000\n",
      "134/134 [==============================] - 0s 382us/step - loss: 26587116.7313 - val_loss: 23278931.7546\n",
      "Epoch 60/5000\n",
      "134/134 [==============================] - 0s 400us/step - loss: 24863625.9892 - val_loss: 21895129.3124\n",
      "Epoch 61/5000\n",
      "134/134 [==============================] - 0s 376us/step - loss: 25450975.8843 - val_loss: 21663879.3755\n",
      "Epoch 62/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 24320549.6861 - val_loss: 23068256.7474\n",
      "Epoch 63/5000\n",
      "134/134 [==============================] - 0s 330us/step - loss: 26592675.5208 - val_loss: 21589463.1105\n",
      "Epoch 64/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 23406505.8643 - val_loss: 21513105.3711\n",
      "Epoch 65/5000\n",
      "134/134 [==============================] - 0s 295us/step - loss: 24452208.3055 - val_loss: 21428018.2840\n",
      "Epoch 66/5000\n",
      "134/134 [==============================] - 0s 331us/step - loss: 22945778.6567 - val_loss: 21456599.4567\n",
      "Epoch 67/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 23092021.0508 - val_loss: 22943927.2259\n",
      "Epoch 68/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 26553994.9125 - val_loss: 21460460.7111\n",
      "Epoch 69/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 300us/step - loss: 22313820.4017 - val_loss: 21313691.6539\n",
      "Epoch 70/5000\n",
      "134/134 [==============================] - 0s 280us/step - loss: 23886755.4627 - val_loss: 22149220.7957\n",
      "Epoch 71/5000\n",
      "134/134 [==============================] - 0s 318us/step - loss: 23897238.5674 - val_loss: 21503152.4693\n",
      "Epoch 72/5000\n",
      "134/134 [==============================] - 0s 299us/step - loss: 23189609.5653 - val_loss: 26777740.7777\n",
      "Epoch 73/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 27590151.2607 - val_loss: 21881379.5901\n",
      "Epoch 74/5000\n",
      "134/134 [==============================] - 0s 274us/step - loss: 23608044.8061 - val_loss: 21051573.0724\n",
      "Epoch 75/5000\n",
      "134/134 [==============================] - 0s 289us/step - loss: 22543568.1376 - val_loss: 21052033.8827\n",
      "Epoch 76/5000\n",
      "134/134 [==============================] - 0s 345us/step - loss: 22997903.6834 - val_loss: 21098962.7742\n",
      "Epoch 77/5000\n",
      "134/134 [==============================] - 0s 380us/step - loss: 22971828.6194 - val_loss: 19614403.9734\n",
      "Epoch 78/5000\n",
      "134/134 [==============================] - 0s 360us/step - loss: 22050202.1306 - val_loss: 19069913.7480\n",
      "Epoch 79/5000\n",
      "134/134 [==============================] - 0s 335us/step - loss: 21429351.4750 - val_loss: 17608511.9598\n",
      "Epoch 80/5000\n",
      "134/134 [==============================] - 0s 378us/step - loss: 20070154.1828 - val_loss: 17566357.9737\n",
      "Epoch 81/5000\n",
      "134/134 [==============================] - 0s 342us/step - loss: 18569817.4352 - val_loss: 16702245.0371\n",
      "Epoch 82/5000\n",
      "134/134 [==============================] - 0s 455us/step - loss: 17386098.4296 - val_loss: 15821753.4002\n",
      "Epoch 83/5000\n",
      "134/134 [==============================] - 0s 331us/step - loss: 17798705.9269 - val_loss: 15553969.1621\n",
      "Epoch 84/5000\n",
      "134/134 [==============================] - 0s 365us/step - loss: 17410347.9887 - val_loss: 15102803.0336\n",
      "Epoch 85/5000\n",
      "134/134 [==============================] - 0s 286us/step - loss: 16221625.1942 - val_loss: 14756698.9957\n",
      "Epoch 86/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 16533895.3172 - val_loss: 14441445.4958\n",
      "Epoch 87/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 16246660.5033 - val_loss: 14461257.5127\n",
      "Epoch 88/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 16191051.5527 - val_loss: 15980809.6368\n",
      "Epoch 89/5000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 16089628.4017 - val_loss: 14700644.0647\n",
      "Epoch 90/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 14980741.0409 - val_loss: 13674232.2085\n",
      "Epoch 91/5000\n",
      "134/134 [==============================] - 0s 289us/step - loss: 15716850.4058 - val_loss: 13688833.9497\n",
      "Epoch 92/5000\n",
      "134/134 [==============================] - 0s 339us/step - loss: 15520280.0865 - val_loss: 13381992.6442\n",
      "Epoch 93/5000\n",
      "134/134 [==============================] - 0s 298us/step - loss: 15458661.4888 - val_loss: 13594438.8764\n",
      "Epoch 94/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 15259942.5534 - val_loss: 13509772.3017\n",
      "Epoch 95/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 14327444.5950 - val_loss: 13434641.4793\n",
      "Epoch 96/5000\n",
      "134/134 [==============================] - 0s 318us/step - loss: 14901068.5205 - val_loss: 12954619.8558\n",
      "Epoch 97/5000\n",
      "134/134 [==============================] - 0s 282us/step - loss: 14076263.7892 - val_loss: 12837175.4762\n",
      "Epoch 98/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 13729486.2146 - val_loss: 13041055.5824\n",
      "Epoch 99/5000\n",
      "134/134 [==============================] - 0s 301us/step - loss: 13553392.6178 - val_loss: 13460828.2326\n",
      "Epoch 100/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 15122740.3957 - val_loss: 12613205.4401\n",
      "Epoch 101/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 13782921.2152 - val_loss: 12934823.9188\n",
      "Epoch 102/5000\n",
      "134/134 [==============================] - 0s 300us/step - loss: 14274146.3391 - val_loss: 12585918.5020\n",
      "Epoch 103/5000\n",
      "134/134 [==============================] - 0s 295us/step - loss: 13925890.3891 - val_loss: 12495717.8130\n",
      "Epoch 104/5000\n",
      "134/134 [==============================] - 0s 317us/step - loss: 14041099.0382 - val_loss: 12425950.4661\n",
      "Epoch 105/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 14310855.8447 - val_loss: 12470372.6420\n",
      "Epoch 106/5000\n",
      "134/134 [==============================] - 0s 292us/step - loss: 13065567.0702 - val_loss: 12621422.9097\n",
      "Epoch 107/5000\n",
      "134/134 [==============================] - 0s 291us/step - loss: 13508971.5406 - val_loss: 12369677.8476\n",
      "Epoch 108/5000\n",
      "134/134 [==============================] - 0s 315us/step - loss: 13177314.6632 - val_loss: 12460852.6448\n",
      "Epoch 109/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 13024638.1082 - val_loss: 13094675.9117\n",
      "Epoch 110/5000\n",
      "134/134 [==============================] - 0s 321us/step - loss: 14121717.1124 - val_loss: 13871557.9377\n",
      "Epoch 111/5000\n",
      "134/134 [==============================] - 0s 291us/step - loss: 14440725.9552 - val_loss: 12351449.9608\n",
      "Epoch 112/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 12817967.7859 - val_loss: 12156622.1635\n",
      "Epoch 113/5000\n",
      "134/134 [==============================] - 0s 288us/step - loss: 12856930.0014 - val_loss: 12203979.0499\n",
      "Epoch 114/5000\n",
      "134/134 [==============================] - 0s 300us/step - loss: 13338620.2856 - val_loss: 12115253.3794\n",
      "Epoch 115/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 13645819.1741 - val_loss: 12487061.0399\n",
      "Epoch 116/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 13030182.2999 - val_loss: 12127057.4675\n",
      "Epoch 117/5000\n",
      "134/134 [==============================] - 0s 301us/step - loss: 13028034.2118 - val_loss: 12063167.0615\n",
      "Epoch 118/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 12801341.8012 - val_loss: 12191675.5919\n",
      "Epoch 119/5000\n",
      "134/134 [==============================] - 0s 331us/step - loss: 12638360.6884 - val_loss: 12103225.8479\n",
      "Epoch 120/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 12651012.3675 - val_loss: 12068563.1246\n",
      "Epoch 121/5000\n",
      "134/134 [==============================] - 0s 272us/step - loss: 12847734.9963 - val_loss: 12039894.7965\n",
      "Epoch 122/5000\n",
      "134/134 [==============================] - 0s 318us/step - loss: 12855775.5114 - val_loss: 11980809.3079\n",
      "Epoch 123/5000\n",
      "134/134 [==============================] - 0s 274us/step - loss: 12894800.1329 - val_loss: 11985543.5123\n",
      "Epoch 124/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 12911453.5014 - val_loss: 12381195.2298\n",
      "Epoch 125/5000\n",
      "134/134 [==============================] - 0s 304us/step - loss: 13004519.3937 - val_loss: 11985075.7334\n",
      "Epoch 126/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 12657303.0695 - val_loss: 11947596.0764\n",
      "Epoch 127/5000\n",
      "134/134 [==============================] - 0s 298us/step - loss: 12466595.1910 - val_loss: 12030940.0835\n",
      "Epoch 128/5000\n",
      "134/134 [==============================] - 0s 329us/step - loss: 12274035.0820 - val_loss: 11921014.9435\n",
      "Epoch 129/5000\n",
      "134/134 [==============================] - 0s 389us/step - loss: 12446479.5549 - val_loss: 11911954.0792\n",
      "Epoch 130/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 12485891.5933 - val_loss: 12110847.4561\n",
      "Epoch 131/5000\n",
      "134/134 [==============================] - 0s 292us/step - loss: 12649065.6081 - val_loss: 11901516.5921\n",
      "Epoch 132/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 12578478.5830 - val_loss: 11835338.4013\n",
      "Epoch 133/5000\n",
      "134/134 [==============================] - 0s 252us/step - loss: 12253810.1972 - val_loss: 11822274.5687\n",
      "Epoch 134/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 12017795.3285 - val_loss: 11800675.6090\n",
      "Epoch 135/5000\n",
      "134/134 [==============================] - 0s 267us/step - loss: 12387372.7313 - val_loss: 11818918.4521\n",
      "Epoch 136/5000\n",
      "134/134 [==============================] - 0s 282us/step - loss: 12571383.8806 - val_loss: 11865424.9243\n",
      "Epoch 137/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 317us/step - loss: 12453032.4888 - val_loss: 11814269.0441\n",
      "Epoch 138/5000\n",
      "134/134 [==============================] - 0s 354us/step - loss: 12962642.9571 - val_loss: 11761427.1807\n",
      "Epoch 139/5000\n",
      "134/134 [==============================] - 0s 352us/step - loss: 12397733.6325 - val_loss: 11745540.6899\n",
      "Epoch 140/5000\n",
      "134/134 [==============================] - 0s 318us/step - loss: 12301867.7416 - val_loss: 11755854.0508\n",
      "Epoch 141/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 12525064.7164 - val_loss: 11722676.6328\n",
      "Epoch 142/5000\n",
      "134/134 [==============================] - 0s 294us/step - loss: 12591035.5663 - val_loss: 11718421.2942\n",
      "Epoch 143/5000\n",
      "134/134 [==============================] - 0s 291us/step - loss: 12364411.0858 - val_loss: 11718176.6520\n",
      "Epoch 144/5000\n",
      "134/134 [==============================] - 0s 315us/step - loss: 12279720.8769 - val_loss: 11978581.0739\n",
      "Epoch 145/5000\n",
      "134/134 [==============================] - 0s 293us/step - loss: 12431786.1679 - val_loss: 11944815.9061\n",
      "Epoch 146/5000\n",
      "134/134 [==============================] - 0s 304us/step - loss: 12453077.7475 - val_loss: 11698771.5053\n",
      "Epoch 147/5000\n",
      "134/134 [==============================] - 0s 311us/step - loss: 12197885.2556 - val_loss: 12018205.8074\n",
      "Epoch 148/5000\n",
      "134/134 [==============================] - 0s 317us/step - loss: 12499011.2313 - val_loss: 11956959.5988\n",
      "Epoch 149/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 12335559.9277 - val_loss: 11637739.3513\n",
      "Epoch 150/5000\n",
      "134/134 [==============================] - 0s 284us/step - loss: 12303869.9239 - val_loss: 11632689.4963\n",
      "Epoch 151/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 11938457.3137 - val_loss: 11671317.9556\n",
      "Epoch 152/5000\n",
      "134/134 [==============================] - 0s 287us/step - loss: 12018377.6791 - val_loss: 11613702.8442\n",
      "Epoch 153/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 11802103.1874 - val_loss: 11600141.4998\n",
      "Epoch 154/5000\n",
      "134/134 [==============================] - 0s 284us/step - loss: 12213720.0056 - val_loss: 11614285.8869\n",
      "Epoch 155/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 12223936.8764 - val_loss: 11597099.7673\n",
      "Epoch 156/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 12473255.9515 - val_loss: 11576491.9736\n",
      "Epoch 157/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 12018122.7687 - val_loss: 11570520.5766\n",
      "Epoch 158/5000\n",
      "134/134 [==============================] - 0s 294us/step - loss: 11974995.1000 - val_loss: 11561821.0652\n",
      "Epoch 159/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 11974715.1339 - val_loss: 11548737.5505\n",
      "Epoch 160/5000\n",
      "134/134 [==============================] - 0s 321us/step - loss: 11950884.5275 - val_loss: 11543629.5622\n",
      "Epoch 161/5000\n",
      "134/134 [==============================] - 0s 287us/step - loss: 12250085.4301 - val_loss: 11560709.8552\n",
      "Epoch 162/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 12130242.1515 - val_loss: 11535866.9627\n",
      "Epoch 163/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 12078213.2598 - val_loss: 11599548.1086\n",
      "Epoch 164/5000\n",
      "134/134 [==============================] - 0s 320us/step - loss: 12243426.0532 - val_loss: 11521914.0020\n",
      "Epoch 165/5000\n",
      "134/134 [==============================] - 0s 319us/step - loss: 12079859.3507 - val_loss: 11551757.4769\n",
      "Epoch 166/5000\n",
      "134/134 [==============================] - 0s 293us/step - loss: 12176843.2496 - val_loss: 11484413.9471\n",
      "Epoch 167/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 11928706.1679 - val_loss: 11516304.7550\n",
      "Epoch 168/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 11955154.5019 - val_loss: 11468879.2182\n",
      "Epoch 169/5000\n",
      "134/134 [==============================] - 0s 342us/step - loss: 12055674.6418 - val_loss: 11503591.2663\n",
      "Epoch 170/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 12075165.3881 - val_loss: 11707268.5816\n",
      "Epoch 171/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 12153812.8095 - val_loss: 11568789.7864\n",
      "Epoch 172/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 11835496.2564 - val_loss: 11456053.0191\n",
      "Epoch 173/5000\n",
      "134/134 [==============================] - 0s 291us/step - loss: 11541329.4104 - val_loss: 11437445.6624\n",
      "Epoch 174/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 11832097.8573 - val_loss: 11437880.7811\n",
      "Epoch 175/5000\n",
      "134/134 [==============================] - 0s 298us/step - loss: 11901055.4221 - val_loss: 11467940.6415\n",
      "Epoch 176/5000\n",
      "134/134 [==============================] - 0s 330us/step - loss: 11636458.3657 - val_loss: 11527700.7759\n",
      "Epoch 177/5000\n",
      "134/134 [==============================] - 0s 272us/step - loss: 12078675.0504 - val_loss: 11432456.9770\n",
      "Epoch 178/5000\n",
      "134/134 [==============================] - 0s 317us/step - loss: 12106911.8716 - val_loss: 11388280.6464\n",
      "Epoch 179/5000\n",
      "134/134 [==============================] - 0s 292us/step - loss: 11599747.4195 - val_loss: 11371592.8142\n",
      "Epoch 180/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 12141489.0431 - val_loss: 11368864.2899\n",
      "Epoch 181/5000\n",
      "134/134 [==============================] - 0s 281us/step - loss: 11900045.4370 - val_loss: 11359728.3449\n",
      "Epoch 182/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 11835534.9888 - val_loss: 11390364.6344\n",
      "Epoch 183/5000\n",
      "134/134 [==============================] - 0s 293us/step - loss: 12169687.6409 - val_loss: 11363254.0487\n",
      "Epoch 184/5000\n",
      "134/134 [==============================] - 0s 295us/step - loss: 11706795.5649 - val_loss: 11333965.5678\n",
      "Epoch 185/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 12057083.9713 - val_loss: 11467770.6937\n",
      "Epoch 186/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 11747157.4418 - val_loss: 11351741.7388\n",
      "Epoch 187/5000\n",
      "134/134 [==============================] - 0s 300us/step - loss: 11859469.1586 - val_loss: 11330468.9660\n",
      "Epoch 188/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 11492625.3144 - val_loss: 11312175.1375\n",
      "Epoch 189/5000\n",
      "134/134 [==============================] - 0s 397us/step - loss: 11703067.7015 - val_loss: 11382085.3642\n",
      "Epoch 190/5000\n",
      "134/134 [==============================] - 0s 344us/step - loss: 11717870.9713 - val_loss: 11345363.5587\n",
      "Epoch 191/5000\n",
      "134/134 [==============================] - 0s 376us/step - loss: 11923446.6432 - val_loss: 11329354.3561\n",
      "Epoch 192/5000\n",
      "134/134 [==============================] - 0s 381us/step - loss: 11810948.1628 - val_loss: 11309373.9217\n",
      "Epoch 193/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 11550771.2702 - val_loss: 11299563.0318\n",
      "Epoch 194/5000\n",
      "134/134 [==============================] - 0s 386us/step - loss: 11547131.5698 - val_loss: 11282096.4759\n",
      "Epoch 195/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 11723053.7313 - val_loss: 11407448.6315\n",
      "Epoch 196/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 11709934.2575 - val_loss: 11340809.0565\n",
      "Epoch 197/5000\n",
      "134/134 [==============================] - 0s 288us/step - loss: 11473201.4110 - val_loss: 11274232.5941\n",
      "Epoch 198/5000\n",
      "134/134 [==============================] - 0s 339us/step - loss: 11757952.7141 - val_loss: 11262333.3307\n",
      "Epoch 199/5000\n",
      "134/134 [==============================] - 0s 357us/step - loss: 11440861.3060 - val_loss: 11298076.0326\n",
      "Epoch 200/5000\n",
      "134/134 [==============================] - 0s 446us/step - loss: 11641604.0840 - val_loss: 11307618.9354\n",
      "Epoch 201/5000\n",
      "134/134 [==============================] - 0s 379us/step - loss: 11714240.8155 - val_loss: 11248319.5535\n",
      "Epoch 202/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 11388455.4009 - val_loss: 11213206.0969\n",
      "Epoch 203/5000\n",
      "134/134 [==============================] - 0s 292us/step - loss: 11736834.5946 - val_loss: 11228822.7067\n",
      "Epoch 204/5000\n",
      "134/134 [==============================] - 0s 290us/step - loss: 11576159.4431 - val_loss: 11187445.2077\n",
      "Epoch 205/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 322us/step - loss: 11557617.6679 - val_loss: 11250495.1795\n",
      "Epoch 206/5000\n",
      "134/134 [==============================] - 0s 398us/step - loss: 11752945.4552 - val_loss: 11205134.1867\n",
      "Epoch 207/5000\n",
      "134/134 [==============================] - 0s 471us/step - loss: 11540317.4818 - val_loss: 11176977.5302\n",
      "Epoch 208/5000\n",
      "134/134 [==============================] - 0s 459us/step - loss: 11578209.1590 - val_loss: 11166274.3074\n",
      "Epoch 209/5000\n",
      "134/134 [==============================] - ETA: 0s - loss: 1115870.500 - 0s 499us/step - loss: 11237444.7883 - val_loss: 11145530.0733\n",
      "Epoch 210/5000\n",
      "134/134 [==============================] - 0s 443us/step - loss: 11595963.8657 - val_loss: 11141719.7992\n",
      "Epoch 211/5000\n",
      "134/134 [==============================] - 0s 375us/step - loss: 11286573.6877 - val_loss: 11131888.6388\n",
      "Epoch 212/5000\n",
      "134/134 [==============================] - 0s 336us/step - loss: 11484454.6418 - val_loss: 11179081.3541\n",
      "Epoch 213/5000\n",
      "134/134 [==============================] - 0s 415us/step - loss: 11673033.6231 - val_loss: 11130374.2861\n",
      "Epoch 214/5000\n",
      "134/134 [==============================] - 0s 374us/step - loss: 11320426.1477 - val_loss: 11112486.5695\n",
      "Epoch 215/5000\n",
      "134/134 [==============================] - 0s 357us/step - loss: 11543364.8954 - val_loss: 11104090.5793\n",
      "Epoch 216/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 11214097.9902 - val_loss: 11083753.1682\n",
      "Epoch 217/5000\n",
      "134/134 [==============================] - 0s 286us/step - loss: 11620025.4795 - val_loss: 11079861.3654\n",
      "Epoch 218/5000\n",
      "134/134 [==============================] - 0s 304us/step - loss: 11812499.4907 - val_loss: 11113586.6303\n",
      "Epoch 219/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 11824020.5891 - val_loss: 11127319.4958\n",
      "Epoch 220/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 11783952.5900 - val_loss: 11117464.0998\n",
      "Epoch 221/5000\n",
      "134/134 [==============================] - 0s 414us/step - loss: 11832675.1996 - val_loss: 11063513.6532\n",
      "Epoch 222/5000\n",
      "134/134 [==============================] - 0s 425us/step - loss: 11680597.5504 - val_loss: 11104941.3048\n",
      "Epoch 223/5000\n",
      "134/134 [==============================] - 0s 479us/step - loss: 11637809.6180 - val_loss: 11054639.9778\n",
      "Epoch 224/5000\n",
      "134/134 [==============================] - 0s 403us/step - loss: 11620398.9291 - val_loss: 11123947.7275\n",
      "Epoch 225/5000\n",
      "134/134 [==============================] - 0s 353us/step - loss: 11599388.5631 - val_loss: 10993444.5312\n",
      "Epoch 226/5000\n",
      "134/134 [==============================] - 0s 470us/step - loss: 11525631.2071 - val_loss: 10994941.2540\n",
      "Epoch 227/5000\n",
      "134/134 [==============================] - 0s 508us/step - loss: 11417946.4496 - val_loss: 10986453.1345\n",
      "Epoch 228/5000\n",
      "134/134 [==============================] - 0s 489us/step - loss: 11221212.1730 - val_loss: 10973868.1125\n",
      "Epoch 229/5000\n",
      "134/134 [==============================] - 0s 446us/step - loss: 11215388.1591 - val_loss: 10970358.3871\n",
      "Epoch 230/5000\n",
      "134/134 [==============================] - 0s 360us/step - loss: 11596820.4832 - val_loss: 10961010.5945\n",
      "Epoch 231/5000\n",
      "134/134 [==============================] - 0s 365us/step - loss: 11297626.5854 - val_loss: 10949397.8407\n",
      "Epoch 232/5000\n",
      "134/134 [==============================] - 0s 355us/step - loss: 11299148.1716 - val_loss: 10983237.4550\n",
      "Epoch 233/5000\n",
      "134/134 [==============================] - 0s 368us/step - loss: 11663337.9471 - val_loss: 10960788.1266\n",
      "Epoch 234/5000\n",
      "134/134 [==============================] - 0s 412us/step - loss: 11346446.1922 - val_loss: 10932227.5973\n",
      "Epoch 235/5000\n",
      "134/134 [==============================] - 0s 319us/step - loss: 11053780.3358 - val_loss: 10912707.2062\n",
      "Epoch 236/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 11603497.8396 - val_loss: 10985741.5554\n",
      "Epoch 237/5000\n",
      "134/134 [==============================] - 0s 374us/step - loss: 11363219.0212 - val_loss: 10951049.5241\n",
      "Epoch 238/5000\n",
      "134/134 [==============================] - 0s 304us/step - loss: 11476864.6119 - val_loss: 10976135.7310\n",
      "Epoch 239/5000\n",
      "134/134 [==============================] - 0s 370us/step - loss: 11391884.3425 - val_loss: 10920510.0655\n",
      "Epoch 240/5000\n",
      "134/134 [==============================] - 0s 357us/step - loss: 11496649.5037 - val_loss: 10882154.1624\n",
      "Epoch 241/5000\n",
      "134/134 [==============================] - 0s 323us/step - loss: 11500012.7768 - val_loss: 10868867.9456\n",
      "Epoch 242/5000\n",
      "134/134 [==============================] - 0s 443us/step - loss: 11296558.1754 - val_loss: 10863563.0670\n",
      "Epoch 243/5000\n",
      "134/134 [==============================] - 0s 409us/step - loss: 11217666.2799 - val_loss: 10843726.2198\n",
      "Epoch 244/5000\n",
      "134/134 [==============================] - 0s 492us/step - loss: 11029987.4884 - val_loss: 10833222.7372\n",
      "Epoch 245/5000\n",
      "134/134 [==============================] - 0s 429us/step - loss: 11494129.0790 - val_loss: 10829353.4987\n",
      "Epoch 246/5000\n",
      "134/134 [==============================] - 0s 444us/step - loss: 11231648.0513 - val_loss: 10829221.9079\n",
      "Epoch 247/5000\n",
      "134/134 [==============================] - 0s 376us/step - loss: 11453918.6978 - val_loss: 10829465.6766\n",
      "Epoch 248/5000\n",
      "134/134 [==============================] - 0s 420us/step - loss: 11105596.5261 - val_loss: 10877121.8889\n",
      "Epoch 249/5000\n",
      "134/134 [==============================] - 0s 382us/step - loss: 11721133.4356 - val_loss: 10816447.7167\n",
      "Epoch 250/5000\n",
      "134/134 [==============================] - 0s 385us/step - loss: 11201511.0976 - val_loss: 10787013.3842\n",
      "Epoch 251/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 11252027.2836 - val_loss: 10773982.2886\n",
      "Epoch 252/5000\n",
      "134/134 [==============================] - 0s 386us/step - loss: 11103925.9235 - val_loss: 10792958.0525\n",
      "Epoch 253/5000\n",
      "134/134 [==============================] - 0s 299us/step - loss: 11041993.0205 - val_loss: 10759443.1452\n",
      "Epoch 254/5000\n",
      "134/134 [==============================] - 0s 360us/step - loss: 11191397.8736 - val_loss: 10763148.2248\n",
      "Epoch 255/5000\n",
      "134/134 [==============================] - 0s 389us/step - loss: 11169493.3881 - val_loss: 10749011.8680\n",
      "Epoch 256/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 11258198.6175 - val_loss: 10742661.6901\n",
      "Epoch 257/5000\n",
      "134/134 [==============================] - 0s 304us/step - loss: 11139340.6091 - val_loss: 10735612.5948\n",
      "Epoch 258/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 11381926.0128 - val_loss: 10719348.2230\n",
      "Epoch 259/5000\n",
      "134/134 [==============================] - 0s 325us/step - loss: 11285686.5672 - val_loss: 10913946.8541\n",
      "Epoch 260/5000\n",
      "134/134 [==============================] - 0s 357us/step - loss: 11505890.5774 - val_loss: 10738964.4827\n",
      "Epoch 261/5000\n",
      "134/134 [==============================] - 0s 387us/step - loss: 11147927.5149 - val_loss: 10694431.8170\n",
      "Epoch 262/5000\n",
      "134/134 [==============================] - 0s 372us/step - loss: 11020620.0419 - val_loss: 10701698.7543\n",
      "Epoch 263/5000\n",
      "134/134 [==============================] - 0s 383us/step - loss: 11278874.7351 - val_loss: 10679148.5854\n",
      "Epoch 264/5000\n",
      "134/134 [==============================] - 0s 379us/step - loss: 10794079.6954 - val_loss: 10672909.2124\n",
      "Epoch 265/5000\n",
      "134/134 [==============================] - 0s 418us/step - loss: 10944975.5392 - val_loss: 10725575.4811\n",
      "Epoch 266/5000\n",
      "134/134 [==============================] - 0s 374us/step - loss: 11057929.4683 - val_loss: 10699696.9351\n",
      "Epoch 267/5000\n",
      "134/134 [==============================] - 0s 350us/step - loss: 11237601.6151 - val_loss: 10663216.9249\n",
      "Epoch 268/5000\n",
      "134/134 [==============================] - 0s 361us/step - loss: 10892745.0903 - val_loss: 10645649.1308\n",
      "Epoch 269/5000\n",
      "134/134 [==============================] - 0s 332us/step - loss: 11118702.9358 - val_loss: 10643016.6820\n",
      "Epoch 270/5000\n",
      "134/134 [==============================] - 0s 267us/step - loss: 10769886.6175 - val_loss: 10624550.0371\n",
      "Epoch 271/5000\n",
      "134/134 [==============================] - 0s 343us/step - loss: 11171274.4337 - val_loss: 10630551.1525\n",
      "Epoch 272/5000\n",
      "134/134 [==============================] - 0s 420us/step - loss: 10786793.9060 - val_loss: 10615281.5786\n",
      "Epoch 273/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 449us/step - loss: 11191700.1403 - val_loss: 10600620.4919\n",
      "Epoch 274/5000\n",
      "134/134 [==============================] - 0s 448us/step - loss: 10949024.5556 - val_loss: 10607981.9707\n",
      "Epoch 275/5000\n",
      "134/134 [==============================] - 0s 496us/step - loss: 10892981.0462 - val_loss: 10605335.5180\n",
      "Epoch 276/5000\n",
      "134/134 [==============================] - 0s 424us/step - loss: 11048093.1194 - val_loss: 10580429.5197\n",
      "Epoch 277/5000\n",
      "134/134 [==============================] - 0s 358us/step - loss: 11093383.5075 - val_loss: 10595821.4925\n",
      "Epoch 278/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 11101954.2883 - val_loss: 10576276.5840\n",
      "Epoch 279/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 10652411.2785 - val_loss: 10562634.3746\n",
      "Epoch 280/5000\n",
      "134/134 [==============================] - 0s 317us/step - loss: 11124668.4235 - val_loss: 10560949.9029\n",
      "Epoch 281/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 10613793.4713 - val_loss: 10536428.8388\n",
      "Epoch 282/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 11312028.0368 - val_loss: 10536249.9289\n",
      "Epoch 283/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 10936424.5896 - val_loss: 10624612.2950\n",
      "Epoch 284/5000\n",
      "134/134 [==============================] - 0s 304us/step - loss: 11205220.8400 - val_loss: 10643228.0767\n",
      "Epoch 285/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 11146764.6250 - val_loss: 10554260.5285\n",
      "Epoch 286/5000\n",
      "134/134 [==============================] - 0s 334us/step - loss: 11171456.2463 - val_loss: 10495039.5522\n",
      "Epoch 287/5000\n",
      "134/134 [==============================] - 0s 317us/step - loss: 11135247.2492 - val_loss: 10480486.6653\n",
      "Epoch 288/5000\n",
      "134/134 [==============================] - 0s 447us/step - loss: 10651489.2799 - val_loss: 10485942.2612\n",
      "Epoch 289/5000\n",
      "134/134 [==============================] - 0s 459us/step - loss: 10917221.6828 - val_loss: 10518633.3843\n",
      "Epoch 290/5000\n",
      "134/134 [==============================] - 0s 384us/step - loss: 11189010.0667 - val_loss: 10695945.7351\n",
      "Epoch 291/5000\n",
      "134/134 [==============================] - 0s 325us/step - loss: 10884281.3013 - val_loss: 10506792.8808\n",
      "Epoch 292/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 10934527.5858 - val_loss: 10465293.8325\n",
      "Epoch 293/5000\n",
      "134/134 [==============================] - 0s 358us/step - loss: 11235895.6623 - val_loss: 10443210.9273\n",
      "Epoch 294/5000\n",
      "134/134 [==============================] - 0s 432us/step - loss: 10884628.4104 - val_loss: 10654688.1978\n",
      "Epoch 295/5000\n",
      "134/134 [==============================] - 0s 363us/step - loss: 11023921.2234 - val_loss: 10497786.6635\n",
      "Epoch 296/5000\n",
      "134/134 [==============================] - 0s 329us/step - loss: 10892717.3582 - val_loss: 10426508.2425\n",
      "Epoch 297/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 10777442.0154 - val_loss: 10447579.4963\n",
      "Epoch 298/5000\n",
      "134/134 [==============================] - 0s 366us/step - loss: 11029383.8904 - val_loss: 10409836.1226\n",
      "Epoch 299/5000\n",
      "134/134 [==============================] - 0s 259us/step - loss: 10757340.6521 - val_loss: 10383853.4615\n",
      "Epoch 300/5000\n",
      "134/134 [==============================] - 0s 275us/step - loss: 10665556.0989 - val_loss: 10531272.2761\n",
      "Epoch 301/5000\n",
      "134/134 [==============================] - 0s 416us/step - loss: 10778574.5345 - val_loss: 10431013.6843\n",
      "Epoch 302/5000\n",
      "134/134 [==============================] - 0s 416us/step - loss: 10560813.9165 - val_loss: 10396361.5847\n",
      "Epoch 303/5000\n",
      "134/134 [==============================] - 0s 407us/step - loss: 11018411.2254 - val_loss: 10354248.8701\n",
      "Epoch 304/5000\n",
      "134/134 [==============================] - 0s 397us/step - loss: 10487378.9310 - val_loss: 10335990.2537\n",
      "Epoch 305/5000\n",
      "134/134 [==============================] - 0s 370us/step - loss: 10771004.9472 - val_loss: 10331264.4281\n",
      "Epoch 306/5000\n",
      "134/134 [==============================] - 0s 357us/step - loss: 10794209.4944 - val_loss: 10433437.0000\n",
      "Epoch 307/5000\n",
      "134/134 [==============================] - 0s 363us/step - loss: 10728333.4663 - val_loss: 10330333.0336\n",
      "Epoch 308/5000\n",
      "134/134 [==============================] - 0s 344us/step - loss: 10753094.8955 - val_loss: 10298711.6750\n",
      "Epoch 309/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 10408873.0312 - val_loss: 10296055.8969\n",
      "Epoch 310/5000\n",
      "134/134 [==============================] - 0s 365us/step - loss: 10701346.7901 - val_loss: 10279694.4000\n",
      "Epoch 311/5000\n",
      "134/134 [==============================] - 0s 381us/step - loss: 10991744.9366 - val_loss: 10298753.0831\n",
      "Epoch 312/5000\n",
      "134/134 [==============================] - 0s 393us/step - loss: 10522519.5000 - val_loss: 10303881.0480\n",
      "Epoch 313/5000\n",
      "134/134 [==============================] - 0s 384us/step - loss: 10729429.1903 - val_loss: 10339299.7742\n",
      "Epoch 314/5000\n",
      "134/134 [==============================] - 0s 394us/step - loss: 10591204.5140 - val_loss: 10264822.4098\n",
      "Epoch 315/5000\n",
      "134/134 [==============================] - 0s 425us/step - loss: 10553213.4496 - val_loss: 10256180.4144\n",
      "Epoch 316/5000\n",
      "134/134 [==============================] - 0s 401us/step - loss: 10379334.7090 - val_loss: 10235040.7418\n",
      "Epoch 317/5000\n",
      "134/134 [==============================] - 0s 413us/step - loss: 10517570.6362 - val_loss: 10226143.4419\n",
      "Epoch 318/5000\n",
      "134/134 [==============================] - 0s 407us/step - loss: 10519195.0518 - val_loss: 10218512.9800\n",
      "Epoch 319/5000\n",
      "134/134 [==============================] - 0s 394us/step - loss: 10533579.9039 - val_loss: 10208744.9223\n",
      "Epoch 320/5000\n",
      "134/134 [==============================] - 0s 353us/step - loss: 10389844.7519 - val_loss: 10204948.0364\n",
      "Epoch 321/5000\n",
      "134/134 [==============================] - 0s 286us/step - loss: 10639885.8022 - val_loss: 10191291.4274\n",
      "Epoch 322/5000\n",
      "134/134 [==============================] - 0s 283us/step - loss: 10671027.9832 - val_loss: 10196220.0641\n",
      "Epoch 323/5000\n",
      "134/134 [==============================] - 0s 288us/step - loss: 10598108.7929 - val_loss: 10201526.3908\n",
      "Epoch 324/5000\n",
      "134/134 [==============================] - 0s 271us/step - loss: 10616909.2360 - val_loss: 10173284.5657\n",
      "Epoch 325/5000\n",
      "134/134 [==============================] - 0s 280us/step - loss: 10758106.7168 - val_loss: 10165587.7392\n",
      "Epoch 326/5000\n",
      "134/134 [==============================] - 0s 315us/step - loss: 10507079.5802 - val_loss: 10157756.1707\n",
      "Epoch 327/5000\n",
      "134/134 [==============================] - 0s 304us/step - loss: 10644282.7649 - val_loss: 10155483.1944\n",
      "Epoch 328/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 10609141.9499 - val_loss: 10141601.9248\n",
      "Epoch 329/5000\n",
      "134/134 [==============================] - 0s 418us/step - loss: 10689825.4980 - val_loss: 10141048.2748\n",
      "Epoch 330/5000\n",
      "134/134 [==============================] - 0s 390us/step - loss: 10731388.3116 - val_loss: 10133521.5212\n",
      "Epoch 331/5000\n",
      "134/134 [==============================] - 0s 413us/step - loss: 10530151.9949 - val_loss: 10121047.4389\n",
      "Epoch 332/5000\n",
      "134/134 [==============================] - 0s 351us/step - loss: 10642291.8923 - val_loss: 10140946.6011\n",
      "Epoch 333/5000\n",
      "134/134 [==============================] - 0s 336us/step - loss: 10533820.9440 - val_loss: 10102734.1444\n",
      "Epoch 334/5000\n",
      "134/134 [==============================] - 0s 293us/step - loss: 10314756.5998 - val_loss: 10094615.2201\n",
      "Epoch 335/5000\n",
      "134/134 [==============================] - 0s 298us/step - loss: 10623798.1213 - val_loss: 10082460.7640\n",
      "Epoch 336/5000\n",
      "134/134 [==============================] - 0s 311us/step - loss: 10549781.7988 - val_loss: 10086868.5693\n",
      "Epoch 337/5000\n",
      "134/134 [==============================] - 0s 345us/step - loss: 10544709.1167 - val_loss: 10113490.3760\n",
      "Epoch 338/5000\n",
      "134/134 [==============================] - 0s 402us/step - loss: 10927870.8330 - val_loss: 10084015.9291\n",
      "Epoch 339/5000\n",
      "134/134 [==============================] - 0s 487us/step - loss: 10667597.5075 - val_loss: 10092778.4647\n",
      "Epoch 340/5000\n",
      "134/134 [==============================] - 0s 319us/step - loss: 10766785.4832 - val_loss: 10062071.3232\n",
      "Epoch 341/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 321us/step - loss: 10422003.7178 - val_loss: 10312503.0409\n",
      "Epoch 342/5000\n",
      "134/134 [==============================] - 0s 385us/step - loss: 10378327.8196 - val_loss: 10101270.8938\n",
      "Epoch 343/5000\n",
      "134/134 [==============================] - 0s 439us/step - loss: 10627570.1049 - val_loss: 10027672.0499\n",
      "Epoch 344/5000\n",
      "134/134 [==============================] - 0s 378us/step - loss: 10237972.6940 - val_loss: 10017086.5716\n",
      "Epoch 345/5000\n",
      "134/134 [==============================] - 0s 366us/step - loss: 10316290.0065 - val_loss: 10005557.6455\n",
      "Epoch 346/5000\n",
      "134/134 [==============================] - 0s 404us/step - loss: 10478487.5672 - val_loss: 9983661.6382\n",
      "Epoch 347/5000\n",
      "134/134 [==============================] - 0s 345us/step - loss: 10430113.7376 - val_loss: 9973256.5322\n",
      "Epoch 348/5000\n",
      "134/134 [==============================] - 0s 325us/step - loss: 10505878.2836 - val_loss: 10120828.2470\n",
      "Epoch 349/5000\n",
      "134/134 [==============================] - 0s 315us/step - loss: 10248245.2966 - val_loss: 9974657.7022\n",
      "Epoch 350/5000\n",
      "134/134 [==============================] - 0s 300us/step - loss: 10374638.6847 - val_loss: 9979694.8831\n",
      "Epoch 351/5000\n",
      "134/134 [==============================] - 0s 329us/step - loss: 10264047.5560 - val_loss: 9964742.2566\n",
      "Epoch 352/5000\n",
      "134/134 [==============================] - 0s 300us/step - loss: 10307516.8717 - val_loss: 9929344.8812\n",
      "Epoch 353/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 10393260.4412 - val_loss: 9920163.3592\n",
      "Epoch 354/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 10608049.5373 - val_loss: 9916531.0979\n",
      "Epoch 355/5000\n",
      "134/134 [==============================] - 0s 293us/step - loss: 10408998.2731 - val_loss: 9934752.8762\n",
      "Epoch 356/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 10309889.7761 - val_loss: 10072032.8096\n",
      "Epoch 357/5000\n",
      "134/134 [==============================] - 0s 297us/step - loss: 10775068.3057 - val_loss: 9935730.4958\n",
      "Epoch 358/5000\n",
      "134/134 [==============================] - 0s 361us/step - loss: 10198997.6094 - val_loss: 9888414.0774\n",
      "Epoch 359/5000\n",
      "134/134 [==============================] - 0s 380us/step - loss: 10200470.6463 - val_loss: 9875387.8479\n",
      "Epoch 360/5000\n",
      "134/134 [==============================] - 0s 402us/step - loss: 10370940.1835 - val_loss: 9916491.6237\n",
      "Epoch 361/5000\n",
      "134/134 [==============================] - 0s 378us/step - loss: 10566528.6093 - val_loss: 9875274.2782\n",
      "Epoch 362/5000\n",
      "134/134 [==============================] - 0s 359us/step - loss: 10351313.2090 - val_loss: 9860303.4008\n",
      "Epoch 363/5000\n",
      "134/134 [==============================] - 0s 387us/step - loss: 10255318.6319 - val_loss: 9842967.9402\n",
      "Epoch 364/5000\n",
      "134/134 [==============================] - 0s 392us/step - loss: 10368684.9776 - val_loss: 9969432.3603\n",
      "Epoch 365/5000\n",
      "134/134 [==============================] - 0s 365us/step - loss: 10062076.3955 - val_loss: 9932615.8735\n",
      "Epoch 366/5000\n",
      "134/134 [==============================] - 0s 381us/step - loss: 10303880.2210 - val_loss: 9890699.0471\n",
      "Epoch 367/5000\n",
      "134/134 [==============================] - 0s 368us/step - loss: 10607661.2548 - val_loss: 9825927.6857\n",
      "Epoch 368/5000\n",
      "134/134 [==============================] - 0s 339us/step - loss: 10738909.4869 - val_loss: 9800024.6235\n",
      "Epoch 369/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 10296833.7316 - val_loss: 9797539.7848\n",
      "Epoch 370/5000\n",
      "134/134 [==============================] - 0s 280us/step - loss: 10259421.8830 - val_loss: 9784679.2468\n",
      "Epoch 371/5000\n",
      "134/134 [==============================] - 0s 269us/step - loss: 10195825.9552 - val_loss: 9780677.2754\n",
      "Epoch 372/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 10094440.6208 - val_loss: 9767646.9783\n",
      "Epoch 373/5000\n",
      "134/134 [==============================] - 0s 339us/step - loss: 10213481.6079 - val_loss: 9799372.6334\n",
      "Epoch 374/5000\n",
      "134/134 [==============================] - 0s 343us/step - loss: 10421009.8088 - val_loss: 9772278.3472\n",
      "Epoch 375/5000\n",
      "134/134 [==============================] - 0s 360us/step - loss: 10417386.8753 - val_loss: 9738279.2398\n",
      "Epoch 376/5000\n",
      "134/134 [==============================] - 0s 574us/step - loss: 9925279.3528 - val_loss: 9701398.2919\n",
      "Epoch 377/5000\n",
      "134/134 [==============================] - 0s 388us/step - loss: 10072955.4445 - val_loss: 9717622.7541\n",
      "Epoch 378/5000\n",
      "134/134 [==============================] - 0s 324us/step - loss: 9891116.2556 - val_loss: 9687565.9285\n",
      "Epoch 379/5000\n",
      "134/134 [==============================] - 0s 288us/step - loss: 10284338.8012 - val_loss: 9699141.1497\n",
      "Epoch 380/5000\n",
      "134/134 [==============================] - 0s 329us/step - loss: 10102496.9384 - val_loss: 9670262.4003\n",
      "Epoch 381/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 10154486.2090 - val_loss: 9786947.3208\n",
      "Epoch 382/5000\n",
      "134/134 [==============================] - 0s 366us/step - loss: 10138926.6922 - val_loss: 9687054.9232\n",
      "Epoch 383/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 10220315.1007 - val_loss: 9673306.8678\n",
      "Epoch 384/5000\n",
      "134/134 [==============================] - 0s 318us/step - loss: 10240679.4291 - val_loss: 9664491.3478\n",
      "Epoch 385/5000\n",
      "134/134 [==============================] - 0s 348us/step - loss: 10332344.6940 - val_loss: 9634130.5712\n",
      "Epoch 386/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 10381279.7183 - val_loss: 9630513.0153\n",
      "Epoch 387/5000\n",
      "134/134 [==============================] - 0s 301us/step - loss: 10151260.6189 - val_loss: 9641207.6922\n",
      "Epoch 388/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 10210078.6637 - val_loss: 9617452.0866\n",
      "Epoch 389/5000\n",
      "134/134 [==============================] - 0s 415us/step - loss: 10026556.9151 - val_loss: 9594718.1408\n",
      "Epoch 390/5000\n",
      "134/134 [==============================] - 0s 333us/step - loss: 10086344.2463 - val_loss: 9788010.2937\n",
      "Epoch 391/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 10203701.0541 - val_loss: 9609742.2946\n",
      "Epoch 392/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 9954593.2994 - val_loss: 9621240.1380\n",
      "Epoch 393/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 9938368.2680 - val_loss: 9559376.9102\n",
      "Epoch 394/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 9943317.9042 - val_loss: 9556708.6257\n",
      "Epoch 395/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 9874864.9282 - val_loss: 9583971.4073\n",
      "Epoch 396/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 9998293.9403 - val_loss: 9774827.1319\n",
      "Epoch 397/5000\n",
      "134/134 [==============================] - 0s 292us/step - loss: 10130559.6399 - val_loss: 9552616.1659\n",
      "Epoch 398/5000\n",
      "134/134 [==============================] - 0s 304us/step - loss: 9959110.1231 - val_loss: 9565443.6162\n",
      "Epoch 399/5000\n",
      "134/134 [==============================] - 0s 356us/step - loss: 10014577.8891 - val_loss: 9528812.9062\n",
      "Epoch 400/5000\n",
      "134/134 [==============================] - 0s 347us/step - loss: 9992551.7276 - val_loss: 9498491.2794\n",
      "Epoch 401/5000\n",
      "134/134 [==============================] - 0s 353us/step - loss: 9907543.2768 - val_loss: 9471692.2109\n",
      "Epoch 402/5000\n",
      "134/134 [==============================] - 0s 324us/step - loss: 9903523.8638 - val_loss: 9468681.0529\n",
      "Epoch 403/5000\n",
      "134/134 [==============================] - 0s 353us/step - loss: 9743401.5191 - val_loss: 9455213.9406\n",
      "Epoch 404/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 9742832.6493 - val_loss: 9457564.1126\n",
      "Epoch 405/5000\n",
      "134/134 [==============================] - 0s 315us/step - loss: 9866188.9053 - val_loss: 9433485.8746\n",
      "Epoch 406/5000\n",
      "134/134 [==============================] - 0s 286us/step - loss: 9980024.3563 - val_loss: 9427402.8279\n",
      "Epoch 407/5000\n",
      "134/134 [==============================] - 0s 345us/step - loss: 9585977.4888 - val_loss: 9423777.8490\n",
      "Epoch 408/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 9499973.0019 - val_loss: 9400952.5923\n",
      "Epoch 409/5000\n",
      "134/134 [==============================] - 0s 345us/step - loss: 9929114.5204 - val_loss: 9426393.5844\n",
      "Epoch 410/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 360us/step - loss: 9931651.3088 - val_loss: 9399556.1892\n",
      "Epoch 411/5000\n",
      "134/134 [==============================] - 0s 439us/step - loss: 9577277.5382 - val_loss: 9377259.3662\n",
      "Epoch 412/5000\n",
      "134/134 [==============================] - 0s 399us/step - loss: 9840248.1957 - val_loss: 9621042.2684\n",
      "Epoch 413/5000\n",
      "134/134 [==============================] - 0s 384us/step - loss: 9792662.4226 - val_loss: 9440965.8244\n",
      "Epoch 414/5000\n",
      "134/134 [==============================] - 0s 304us/step - loss: 9739333.5299 - val_loss: 9361936.0307\n",
      "Epoch 415/5000\n",
      "134/134 [==============================] - 0s 330us/step - loss: 9824025.7463 - val_loss: 9458612.6498\n",
      "Epoch 416/5000\n",
      "134/134 [==============================] - 0s 466us/step - loss: 9843996.1064 - val_loss: 9358184.4970\n",
      "Epoch 417/5000\n",
      "134/134 [==============================] - 0s 381us/step - loss: 9853058.0900 - val_loss: 9337746.4327\n",
      "Epoch 418/5000\n",
      "134/134 [==============================] - 0s 372us/step - loss: 9747842.4570 - val_loss: 9342293.1313\n",
      "Epoch 419/5000\n",
      "134/134 [==============================] - 0s 367us/step - loss: 9676122.3941 - val_loss: 9430091.2902\n",
      "Epoch 420/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 9856609.6940 - val_loss: 9437875.7880\n",
      "Epoch 421/5000\n",
      "134/134 [==============================] - 0s 331us/step - loss: 9728009.0035 - val_loss: 9359637.7427\n",
      "Epoch 422/5000\n",
      "134/134 [==============================] - 0s 385us/step - loss: 9639809.4789 - val_loss: 9290284.1415\n",
      "Epoch 423/5000\n",
      "134/134 [==============================] - 0s 354us/step - loss: 9858039.4322 - val_loss: 9270023.7837\n",
      "Epoch 424/5000\n",
      "134/134 [==============================] - 0s 365us/step - loss: 9446428.2004 - val_loss: 9246331.8611\n",
      "Epoch 425/5000\n",
      "134/134 [==============================] - 0s 456us/step - loss: 9789947.5672 - val_loss: 9278022.3242\n",
      "Epoch 426/5000\n",
      "134/134 [==============================] - 0s 353us/step - loss: 9909114.4785 - val_loss: 9231597.6319\n",
      "Epoch 427/5000\n",
      "134/134 [==============================] - 0s 366us/step - loss: 9630213.4328 - val_loss: 9230755.3116\n",
      "Epoch 428/5000\n",
      "134/134 [==============================] - 0s 395us/step - loss: 9692082.2015 - val_loss: 9403761.7137\n",
      "Epoch 429/5000\n",
      "134/134 [==============================] - 0s 390us/step - loss: 9927299.6430 - val_loss: 9242723.5148\n",
      "Epoch 430/5000\n",
      "134/134 [==============================] - 0s 400us/step - loss: 9676566.7836 - val_loss: 9318088.1103\n",
      "Epoch 431/5000\n",
      "134/134 [==============================] - 0s 528us/step - loss: 9470487.2388 - val_loss: 9248669.8072\n",
      "Epoch 432/5000\n",
      "134/134 [==============================] - 0s 489us/step - loss: 9660657.0037 - val_loss: 9364321.9692\n",
      "Epoch 433/5000\n",
      "134/134 [==============================] - 0s 506us/step - loss: 9674238.0896 - val_loss: 9179720.3150\n",
      "Epoch 434/5000\n",
      "134/134 [==============================] - 0s 403us/step - loss: 9677016.0485 - val_loss: 9157833.5909\n",
      "Epoch 435/5000\n",
      "134/134 [==============================] - 0s 378us/step - loss: 9481443.0835 - val_loss: 9150739.4693\n",
      "Epoch 436/5000\n",
      "134/134 [==============================] - 0s 318us/step - loss: 9467775.9855 - val_loss: 9268384.2337\n",
      "Epoch 437/5000\n",
      "134/134 [==============================] - 0s 344us/step - loss: 9741739.6903 - val_loss: 9136494.0292\n",
      "Epoch 438/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 9547163.1530 - val_loss: 9175271.6455\n",
      "Epoch 439/5000\n",
      "134/134 [==============================] - 0s 431us/step - loss: 9472507.9872 - val_loss: 9103533.3455\n",
      "Epoch 440/5000\n",
      "134/134 [==============================] - 0s 398us/step - loss: 9249405.6179 - val_loss: 9102640.8596\n",
      "Epoch 441/5000\n",
      "134/134 [==============================] - 0s 331us/step - loss: 9491640.3881 - val_loss: 9134849.2552\n",
      "Epoch 442/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 9486486.0914 - val_loss: 9081031.0477\n",
      "Epoch 443/5000\n",
      "134/134 [==============================] - 0s 335us/step - loss: 9406287.5942 - val_loss: 9084463.8975\n",
      "Epoch 444/5000\n",
      "134/134 [==============================] - 0s 401us/step - loss: 9269041.0075 - val_loss: 9058873.0698\n",
      "Epoch 445/5000\n",
      "134/134 [==============================] - 0s 361us/step - loss: 9516944.6157 - val_loss: 9058797.7343\n",
      "Epoch 446/5000\n",
      "134/134 [==============================] - 0s 498us/step - loss: 9575961.0280 - val_loss: 9173452.4349\n",
      "Epoch 447/5000\n",
      "134/134 [==============================] - 0s 417us/step - loss: 9409011.9380 - val_loss: 9189515.2588\n",
      "Epoch 448/5000\n",
      "134/134 [==============================] - 0s 399us/step - loss: 9594925.2407 - val_loss: 9030967.2240\n",
      "Epoch 449/5000\n",
      "134/134 [==============================] - 0s 381us/step - loss: 9154842.1828 - val_loss: 9141761.3803\n",
      "Epoch 450/5000\n",
      "134/134 [==============================] - 0s 374us/step - loss: 9395383.5620 - val_loss: 9078358.4953\n",
      "Epoch 451/5000\n",
      "134/134 [==============================] - 0s 297us/step - loss: 9424155.3203 - val_loss: 9023036.6221\n",
      "Epoch 452/5000\n",
      "134/134 [==============================] - 0s 292us/step - loss: 9288410.9902 - val_loss: 8997843.8921\n",
      "Epoch 453/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 9495633.7435 - val_loss: 9028008.7480\n",
      "Epoch 454/5000\n",
      "134/134 [==============================] - 0s 364us/step - loss: 9464211.6507 - val_loss: 8990783.2667\n",
      "Epoch 455/5000\n",
      "134/134 [==============================] - 0s 377us/step - loss: 9496232.5112 - val_loss: 9165051.4937\n",
      "Epoch 456/5000\n",
      "134/134 [==============================] - 0s 379us/step - loss: 9429034.6011 - val_loss: 9010695.1665\n",
      "Epoch 457/5000\n",
      "134/134 [==============================] - 0s 352us/step - loss: 9578725.9332 - val_loss: 9056538.2136\n",
      "Epoch 458/5000\n",
      "134/134 [==============================] - 0s 293us/step - loss: 9576505.8769 - val_loss: 8980296.3199\n",
      "Epoch 459/5000\n",
      "134/134 [==============================] - 0s 330us/step - loss: 9295059.4921 - val_loss: 8975641.6652\n",
      "Epoch 460/5000\n",
      "134/134 [==============================] - 0s 317us/step - loss: 9158347.1250 - val_loss: 8925234.3624\n",
      "Epoch 461/5000\n",
      "134/134 [==============================] - 0s 319us/step - loss: 9658757.4925 - val_loss: 8907566.9153\n",
      "Epoch 462/5000\n",
      "134/134 [==============================] - 0s 497us/step - loss: 9383595.4443 - val_loss: 8902148.0010\n",
      "Epoch 463/5000\n",
      "134/134 [==============================] - 0s 622us/step - loss: 9319033.3638 - val_loss: 8887093.4997\n",
      "Epoch 464/5000\n",
      "134/134 [==============================] - 0s 333us/step - loss: 9293759.8807 - val_loss: 8914095.4435\n",
      "Epoch 465/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 9447090.0450 - val_loss: 8875123.7675\n",
      "Epoch 466/5000\n",
      "134/134 [==============================] - 0s 290us/step - loss: 9463458.9145 - val_loss: 8902223.8217\n",
      "Epoch 467/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 9418267.9445 - val_loss: 8851104.9378\n",
      "Epoch 468/5000\n",
      "134/134 [==============================] - 0s 244us/step - loss: 9479730.1940 - val_loss: 8832880.9015\n",
      "Epoch 469/5000\n",
      "134/134 [==============================] - 0s 324us/step - loss: 9127985.0187 - val_loss: 8843977.2745\n",
      "Epoch 470/5000\n",
      "134/134 [==============================] - 0s 334us/step - loss: 9287604.4167 - val_loss: 8846047.4177\n",
      "Epoch 471/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 9153314.1371 - val_loss: 8804047.1087\n",
      "Epoch 472/5000\n",
      "134/134 [==============================] - 0s 320us/step - loss: 9173087.7239 - val_loss: 8791618.4241\n",
      "Epoch 473/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 9207764.5616 - val_loss: 8788587.6743\n",
      "Epoch 474/5000\n",
      "134/134 [==============================] - 0s 348us/step - loss: 9474065.3109 - val_loss: 8779072.4759\n",
      "Epoch 475/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 9341966.6996 - val_loss: 8904586.1458\n",
      "Epoch 476/5000\n",
      "134/134 [==============================] - 0s 347us/step - loss: 9655437.8750 - val_loss: 8765283.1751\n",
      "Epoch 477/5000\n",
      "134/134 [==============================] - 0s 321us/step - loss: 9349388.6019 - val_loss: 8739236.2776\n",
      "Epoch 478/5000\n",
      "134/134 [==============================] - 0s 339us/step - loss: 9435705.2682 - val_loss: 8719422.0692\n",
      "Epoch 479/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 276us/step - loss: 9185415.7400 - val_loss: 8717104.3640\n",
      "Epoch 480/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 9115440.4216 - val_loss: 8718449.5653\n",
      "Epoch 481/5000\n",
      "134/134 [==============================] - 0s 298us/step - loss: 9256605.7712 - val_loss: 8702597.4572\n",
      "Epoch 482/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 9052055.0771 - val_loss: 8721091.1896\n",
      "Epoch 483/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 9345063.4274 - val_loss: 8680494.3375\n",
      "Epoch 484/5000\n",
      "134/134 [==============================] - 0s 325us/step - loss: 8842454.3311 - val_loss: 8654468.2034\n",
      "Epoch 485/5000\n",
      "134/134 [==============================] - 0s 352us/step - loss: 9221865.5663 - val_loss: 8684804.8833\n",
      "Epoch 486/5000\n",
      "134/134 [==============================] - 0s 384us/step - loss: 9409541.8763 - val_loss: 8660936.2208\n",
      "Epoch 487/5000\n",
      "134/134 [==============================] - 0s 393us/step - loss: 9168886.1642 - val_loss: 8692322.2199\n",
      "Epoch 488/5000\n",
      "134/134 [==============================] - 0s 375us/step - loss: 9440502.9240 - val_loss: 8613100.7380\n",
      "Epoch 489/5000\n",
      "134/134 [==============================] - 0s 291us/step - loss: 8953716.2668 - val_loss: 8723969.1647\n",
      "Epoch 490/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 9169480.1269 - val_loss: 8622994.5958\n",
      "Epoch 491/5000\n",
      "134/134 [==============================] - 0s 366us/step - loss: 9025985.4005 - val_loss: 8616052.4456\n",
      "Epoch 492/5000\n",
      "134/134 [==============================] - 0s 771us/step - loss: 8934633.7352 - val_loss: 8620048.8579\n",
      "Epoch 493/5000\n",
      "134/134 [==============================] - 0s 548us/step - loss: 9089353.9055 - val_loss: 8590654.2925\n",
      "Epoch 494/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 9137854.7307 - val_loss: 8553080.0159\n",
      "Epoch 495/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 9031335.1978 - val_loss: 8721002.8991\n",
      "Epoch 496/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 9021722.6880 - val_loss: 8592245.4687\n",
      "Epoch 497/5000\n",
      "134/134 [==============================] - 0s 319us/step - loss: 8873625.6940 - val_loss: 8563549.2885\n",
      "Epoch 498/5000\n",
      "134/134 [==============================] - 0s 329us/step - loss: 9148478.3097 - val_loss: 8531438.9565\n",
      "Epoch 499/5000\n",
      "134/134 [==============================] - 0s 301us/step - loss: 8979948.2327 - val_loss: 8504002.0371\n",
      "Epoch 500/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 8993875.2905 - val_loss: 8495160.7340\n",
      "Epoch 501/5000\n",
      "134/134 [==============================] - 0s 391us/step - loss: 9068834.8959 - val_loss: 8502629.2287\n",
      "Epoch 502/5000\n",
      "134/134 [==============================] - 0s 357us/step - loss: 8919864.8517 - val_loss: 8472674.2061\n",
      "Epoch 503/5000\n",
      "134/134 [==============================] - 0s 368us/step - loss: 8809206.3535 - val_loss: 8499468.7389\n",
      "Epoch 504/5000\n",
      "134/134 [==============================] - 0s 544us/step - loss: 8869749.5721 - val_loss: 8457431.5223\n",
      "Epoch 505/5000\n",
      "134/134 [==============================] - 0s 470us/step - loss: 9150936.5821 - val_loss: 8440486.1403\n",
      "Epoch 506/5000\n",
      "134/134 [==============================] - 0s 512us/step - loss: 8748240.4069 - val_loss: 8438462.7682\n",
      "Epoch 507/5000\n",
      "134/134 [==============================] - 0s 578us/step - loss: 8906591.0820 - val_loss: 8434940.0991\n",
      "Epoch 508/5000\n",
      "134/134 [==============================] - 0s 577us/step - loss: 8698466.7108 - val_loss: 8450101.4107\n",
      "Epoch 509/5000\n",
      "134/134 [==============================] - 0s 405us/step - loss: 8571489.0634 - val_loss: 8462739.7578\n",
      "Epoch 510/5000\n",
      "134/134 [==============================] - 0s 393us/step - loss: 8774925.6084 - val_loss: 8388070.8694\n",
      "Epoch 511/5000\n",
      "134/134 [==============================] - 0s 389us/step - loss: 8902443.2355 - val_loss: 8377008.9607\n",
      "Epoch 512/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 8868497.6860 - val_loss: 8351973.3574\n",
      "Epoch 513/5000\n",
      "134/134 [==============================] - 0s 289us/step - loss: 8827205.7379 - val_loss: 8379002.9499\n",
      "Epoch 514/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 8980999.7369 - val_loss: 8359091.6966\n",
      "Epoch 515/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 8669377.0114 - val_loss: 8463633.9888\n",
      "Epoch 516/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 8725275.6119 - val_loss: 8433558.1202\n",
      "Epoch 517/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 8814114.1068 - val_loss: 8338224.4829\n",
      "Epoch 518/5000\n",
      "134/134 [==============================] - 0s 570us/step - loss: 8668006.3544 - val_loss: 8334543.6377\n",
      "Epoch 519/5000\n",
      "134/134 [==============================] - 0s 422us/step - loss: 8903561.4403 - val_loss: 8403491.7294\n",
      "Epoch 520/5000\n",
      "134/134 [==============================] - 0s 402us/step - loss: 8646018.2537 - val_loss: 8584043.8103\n",
      "Epoch 521/5000\n",
      "134/134 [==============================] - 0s 795us/step - loss: 8585661.1810 - val_loss: 8420248.7356\n",
      "Epoch 522/5000\n",
      "134/134 [==============================] - ETA: 0s - loss: 2128980.000 - 0s 573us/step - loss: 8909539.5718 - val_loss: 8342040.3992\n",
      "Epoch 523/5000\n",
      "134/134 [==============================] - 0s 469us/step - loss: 8765382.2206 - val_loss: 8313211.9089\n",
      "Epoch 524/5000\n",
      "134/134 [==============================] - 0s 377us/step - loss: 8771558.7804 - val_loss: 8296409.5883\n",
      "Epoch 525/5000\n",
      "134/134 [==============================] - 0s 357us/step - loss: 8353070.8863 - val_loss: 8217979.2494\n",
      "Epoch 526/5000\n",
      "134/134 [==============================] - 0s 270us/step - loss: 8762832.6056 - val_loss: 8400871.7777\n",
      "Epoch 527/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 8640486.9160 - val_loss: 8290809.7222\n",
      "Epoch 528/5000\n",
      "134/134 [==============================] - 0s 338us/step - loss: 8686714.8442 - val_loss: 8230793.9478\n",
      "Epoch 529/5000\n",
      "134/134 [==============================] - 0s 364us/step - loss: 8503717.8955 - val_loss: 8261284.9506\n",
      "Epoch 530/5000\n",
      "134/134 [==============================] - 0s 367us/step - loss: 8494974.4767 - val_loss: 8155637.9105\n",
      "Epoch 531/5000\n",
      "134/134 [==============================] - 0s 406us/step - loss: 8319287.1045 - val_loss: 8141548.2005\n",
      "Epoch 532/5000\n",
      "134/134 [==============================] - 0s 417us/step - loss: 8402927.1726 - val_loss: 8208385.0801\n",
      "Epoch 533/5000\n",
      "134/134 [==============================] - 0s 411us/step - loss: 8470578.8286 - val_loss: 8170366.6672\n",
      "Epoch 534/5000\n",
      "134/134 [==============================] - 0s 407us/step - loss: 8508732.9478 - val_loss: 8298765.5418\n",
      "Epoch 535/5000\n",
      "134/134 [==============================] - 0s 362us/step - loss: 8580440.2292 - val_loss: 8202195.0081\n",
      "Epoch 536/5000\n",
      "134/134 [==============================] - 0s 358us/step - loss: 8550186.7099 - val_loss: 8141848.5335\n",
      "Epoch 537/5000\n",
      "134/134 [==============================] - 0s 323us/step - loss: 8500930.2649 - val_loss: 8151070.3142\n",
      "Epoch 538/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 8436295.9545 - val_loss: 8075583.9102\n",
      "Epoch 539/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 8500528.1842 - val_loss: 8064363.1795\n",
      "Epoch 540/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 8264850.9418 - val_loss: 8046918.5204\n",
      "Epoch 541/5000\n",
      "134/134 [==============================] - 0s 332us/step - loss: 8335143.3022 - val_loss: 8036661.1998\n",
      "Epoch 542/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 8358432.9998 - val_loss: 8110250.6572\n",
      "Epoch 543/5000\n",
      "134/134 [==============================] - 0s 359us/step - loss: 8377119.3412 - val_loss: 8060942.4559\n",
      "Epoch 544/5000\n",
      "134/134 [==============================] - 0s 339us/step - loss: 8574302.7276 - val_loss: 8022194.5968\n",
      "Epoch 545/5000\n",
      "134/134 [==============================] - 0s 355us/step - loss: 8329406.3848 - val_loss: 8083652.8913\n",
      "Epoch 546/5000\n",
      "134/134 [==============================] - 0s 341us/step - loss: 8307078.2920 - val_loss: 8086689.2425\n",
      "Epoch 547/5000\n",
      "134/134 [==============================] - 0s 343us/step - loss: 8375957.7822 - val_loss: 7982043.0949\n",
      "Epoch 548/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 301us/step - loss: 8202523.0679 - val_loss: 8060094.3284\n",
      "Epoch 549/5000\n",
      "134/134 [==============================] - 0s 287us/step - loss: 8338899.7313 - val_loss: 7961732.4366\n",
      "Epoch 550/5000\n",
      "134/134 [==============================] - 0s 324us/step - loss: 8162102.4579 - val_loss: 7952156.6377\n",
      "Epoch 551/5000\n",
      "134/134 [==============================] - 0s 364us/step - loss: 8129668.2738 - val_loss: 7927093.7546\n",
      "Epoch 552/5000\n",
      "134/134 [==============================] - 0s 323us/step - loss: 8070574.5949 - val_loss: 7918622.5448\n",
      "Epoch 553/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 8524471.8172 - val_loss: 7925439.2759\n",
      "Epoch 554/5000\n",
      "134/134 [==============================] - 0s 276us/step - loss: 8579709.2603 - val_loss: 7948191.0685\n",
      "Epoch 555/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 8435739.9338 - val_loss: 7938395.0410\n",
      "Epoch 556/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 8261199.7873 - val_loss: 7887944.7500\n",
      "Epoch 557/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 8129078.9416 - val_loss: 7859512.7351\n",
      "Epoch 558/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 8389435.0281 - val_loss: 7844882.2458\n",
      "Epoch 559/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 8268835.6295 - val_loss: 7850091.4888\n",
      "Epoch 560/5000\n",
      "134/134 [==============================] - 0s 299us/step - loss: 8366571.5075 - val_loss: 7838200.8552\n",
      "Epoch 561/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 8273882.9795 - val_loss: 7797637.8358\n",
      "Epoch 562/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 8251070.2500 - val_loss: 7789111.5597\n",
      "Epoch 563/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 8351402.8816 - val_loss: 7790136.0149\n",
      "Epoch 564/5000\n",
      "134/134 [==============================] - 0s 320us/step - loss: 8317274.8899 - val_loss: 7765188.5429\n",
      "Epoch 565/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 8082177.6866 - val_loss: 7854714.0634\n",
      "Epoch 566/5000\n",
      "134/134 [==============================] - 0s 300us/step - loss: 8459191.7463 - val_loss: 7791785.7649\n",
      "Epoch 567/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 8192042.4953 - val_loss: 7767226.6567\n",
      "Epoch 568/5000\n",
      "134/134 [==============================] - 0s 304us/step - loss: 8190068.3778 - val_loss: 7723534.1343\n",
      "Epoch 569/5000\n",
      "134/134 [==============================] - 0s 336us/step - loss: 8203347.6063 - val_loss: 7719930.1119\n",
      "Epoch 570/5000\n",
      "134/134 [==============================] - 0s 261us/step - loss: 8093085.7500 - val_loss: 7752696.7245\n",
      "Epoch 571/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 8216997.1343 - val_loss: 7670400.3806\n",
      "Epoch 572/5000\n",
      "134/134 [==============================] - 0s 289us/step - loss: 8010373.0460 - val_loss: 7669226.3657\n",
      "Epoch 573/5000\n",
      "134/134 [==============================] - 0s 301us/step - loss: 7992913.3335 - val_loss: 7650967.5485\n",
      "Epoch 574/5000\n",
      "134/134 [==============================] - 0s 298us/step - loss: 7752534.0860 - val_loss: 7657967.4632\n",
      "Epoch 575/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 8112863.8582 - val_loss: 7835087.6851\n",
      "Epoch 576/5000\n",
      "134/134 [==============================] - 0s 300us/step - loss: 8026982.5247 - val_loss: 7658504.5262\n",
      "Epoch 577/5000\n",
      "134/134 [==============================] - 0s 278us/step - loss: 7857053.9482 - val_loss: 7592883.3184\n",
      "Epoch 578/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 7891380.7201 - val_loss: 7596621.0784\n",
      "Epoch 579/5000\n",
      "134/134 [==============================] - 0s 343us/step - loss: 8033539.8930 - val_loss: 7575830.8619\n",
      "Epoch 580/5000\n",
      "134/134 [==============================] - 0s 339us/step - loss: 8049021.5299 - val_loss: 7559740.9963\n",
      "Epoch 581/5000\n",
      "134/134 [==============================] - 0s 368us/step - loss: 7671288.9055 - val_loss: 7535727.4493\n",
      "Epoch 582/5000\n",
      "134/134 [==============================] - ETA: 0s - loss: 16024582.00 - 0s 381us/step - loss: 8053247.0817 - val_loss: 7578008.0908\n",
      "Epoch 583/5000\n",
      "134/134 [==============================] - 0s 441us/step - loss: 7836120.7052 - val_loss: 7577604.0634\n",
      "Epoch 584/5000\n",
      "134/134 [==============================] - 0s 477us/step - loss: 7994055.3983 - val_loss: 7497744.5616\n",
      "Epoch 585/5000\n",
      "134/134 [==============================] - 0s 382us/step - loss: 7857377.0743 - val_loss: 7537066.7074\n",
      "Epoch 586/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 7760257.6063 - val_loss: 7462136.5634\n",
      "Epoch 587/5000\n",
      "134/134 [==============================] - 0s 297us/step - loss: 7973110.9453 - val_loss: 7465670.9515\n",
      "Epoch 588/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 8046139.5224 - val_loss: 7544434.2836\n",
      "Epoch 589/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 7928803.4338 - val_loss: 7796799.9099\n",
      "Epoch 590/5000\n",
      "134/134 [==============================] - 0s 290us/step - loss: 7972100.0310 - val_loss: 7462485.4740\n",
      "Epoch 591/5000\n",
      "134/134 [==============================] - 0s 319us/step - loss: 7911366.1796 - val_loss: 7450244.5149\n",
      "Epoch 592/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 8027961.5965 - val_loss: 7429243.6231\n",
      "Epoch 593/5000\n",
      "134/134 [==============================] - 0s 339us/step - loss: 8149634.3209 - val_loss: 7423699.8731\n",
      "Epoch 594/5000\n",
      "134/134 [==============================] - 0s 333us/step - loss: 7704856.2566 - val_loss: 7443653.4925\n",
      "Epoch 595/5000\n",
      "134/134 [==============================] - 0s 345us/step - loss: 7734052.6981 - val_loss: 7354271.2612\n",
      "Epoch 596/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 7501122.3270 - val_loss: 7364391.2799\n",
      "Epoch 597/5000\n",
      "134/134 [==============================] - 0s 297us/step - loss: 7776356.0373 - val_loss: 7446685.3657\n",
      "Epoch 598/5000\n",
      "134/134 [==============================] - 0s 290us/step - loss: 7687493.8829 - val_loss: 7302043.0112\n",
      "Epoch 599/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 7664115.1968 - val_loss: 7308566.8918\n",
      "Epoch 600/5000\n",
      "134/134 [==============================] - 0s 436us/step - loss: 7589337.2533 - val_loss: 7281258.8321\n",
      "Epoch 601/5000\n",
      "134/134 [==============================] - 0s 494us/step - loss: 7591527.0874 - val_loss: 7293778.6791\n",
      "Epoch 602/5000\n",
      "134/134 [==============================] - 0s 396us/step - loss: 7769813.6690 - val_loss: 7239704.4702\n",
      "Epoch 603/5000\n",
      "134/134 [==============================] - 0s 439us/step - loss: 7606530.6158 - val_loss: 7301196.6082\n",
      "Epoch 604/5000\n",
      "134/134 [==============================] - 0s 428us/step - loss: 7525458.5830 - val_loss: 7230947.4216\n",
      "Epoch 605/5000\n",
      "134/134 [==============================] - 0s 396us/step - loss: 7744449.1581 - val_loss: 7302431.4179\n",
      "Epoch 606/5000\n",
      "134/134 [==============================] - 0s 386us/step - loss: 7604335.8825 - val_loss: 7241479.1828\n",
      "Epoch 607/5000\n",
      "134/134 [==============================] - 0s 371us/step - loss: 7563580.1061 - val_loss: 7564454.6306\n",
      "Epoch 608/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 7771226.3239 - val_loss: 7410452.2948\n",
      "Epoch 609/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 7876318.0420 - val_loss: 7170458.2202\n",
      "Epoch 610/5000\n",
      "134/134 [==============================] - 0s 355us/step - loss: 7763724.8361 - val_loss: 7203831.3022\n",
      "Epoch 611/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 7399172.3619 - val_loss: 7144938.5709\n",
      "Epoch 612/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 7401603.2332 - val_loss: 7199966.4478\n",
      "Epoch 613/5000\n",
      "134/134 [==============================] - 0s 281us/step - loss: 7597555.5382 - val_loss: 7096294.1530\n",
      "Epoch 614/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 7710704.7690 - val_loss: 7130156.2463\n",
      "Epoch 615/5000\n",
      "134/134 [==============================] - 0s 333us/step - loss: 7245442.4677 - val_loss: 7098392.5261\n",
      "Epoch 616/5000\n",
      "134/134 [==============================] - 0s 292us/step - loss: 7205369.0512 - val_loss: 7057558.5933\n",
      "Epoch 617/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 352us/step - loss: 7900563.2559 - val_loss: 7041399.3433\n",
      "Epoch 618/5000\n",
      "134/134 [==============================] - 0s 382us/step - loss: 7588375.0391 - val_loss: 7039743.6007\n",
      "Epoch 619/5000\n",
      "134/134 [==============================] - 0s 371us/step - loss: 7540727.8491 - val_loss: 7001562.0634\n",
      "Epoch 620/5000\n",
      "134/134 [==============================] - 0s 349us/step - loss: 7264954.6861 - val_loss: 6982203.2761\n",
      "Epoch 621/5000\n",
      "134/134 [==============================] - 0s 335us/step - loss: 7481717.1735 - val_loss: 7314406.6530\n",
      "Epoch 622/5000\n",
      "134/134 [==============================] - 0s 351us/step - loss: 7827568.4069 - val_loss: 7192065.2052\n",
      "Epoch 623/5000\n",
      "134/134 [==============================] - 0s 387us/step - loss: 7326792.7500 - val_loss: 7021340.5485\n",
      "Epoch 624/5000\n",
      "134/134 [==============================] - 0s 339us/step - loss: 7206727.6364 - val_loss: 6932257.1903\n",
      "Epoch 625/5000\n",
      "134/134 [==============================] - 0s 382us/step - loss: 7392764.2467 - val_loss: 7207462.1679\n",
      "Epoch 626/5000\n",
      "134/134 [==============================] - 0s 334us/step - loss: 7523753.6067 - val_loss: 6928943.7500\n",
      "Epoch 627/5000\n",
      "134/134 [==============================] - 0s 344us/step - loss: 7286472.0291 - val_loss: 6891904.2761\n",
      "Epoch 628/5000\n",
      "134/134 [==============================] - 0s 372us/step - loss: 7534942.6023 - val_loss: 6880222.9552\n",
      "Epoch 629/5000\n",
      "134/134 [==============================] - 0s 368us/step - loss: 7022926.4771 - val_loss: 6872478.0149\n",
      "Epoch 630/5000\n",
      "134/134 [==============================] - 0s 299us/step - loss: 7321312.3506 - val_loss: 6846594.4813\n",
      "Epoch 631/5000\n",
      "134/134 [==============================] - 0s 364us/step - loss: 7109033.5578 - val_loss: 7050698.4067\n",
      "Epoch 632/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 7485107.8125 - val_loss: 7109952.2910\n",
      "Epoch 633/5000\n",
      "134/134 [==============================] - 0s 304us/step - loss: 7406269.9407 - val_loss: 6833287.3358\n",
      "Epoch 634/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 7140535.9088 - val_loss: 6794445.1157\n",
      "Epoch 635/5000\n",
      "134/134 [==============================] - 0s 330us/step - loss: 7101302.9685 - val_loss: 6776047.1530\n",
      "Epoch 636/5000\n",
      "134/134 [==============================] - 0s 324us/step - loss: 7213786.2873 - val_loss: 6892164.1754\n",
      "Epoch 637/5000\n",
      "134/134 [==============================] - 0s 319us/step - loss: 7223947.4923 - val_loss: 6807360.8097\n",
      "Epoch 638/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 7227733.3990 - val_loss: 6750473.8284\n",
      "Epoch 639/5000\n",
      "134/134 [==============================] - 0s 335us/step - loss: 7094727.4701 - val_loss: 6806992.5821\n",
      "Epoch 640/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 6990889.1402 - val_loss: 6715042.0448\n",
      "Epoch 641/5000\n",
      "134/134 [==============================] - 0s 325us/step - loss: 7142533.0534 - val_loss: 6715655.9813\n",
      "Epoch 642/5000\n",
      "134/134 [==============================] - 0s 336us/step - loss: 6956187.0299 - val_loss: 6709580.1231\n",
      "Epoch 643/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 6906945.5926 - val_loss: 6668085.5000\n",
      "Epoch 644/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 6985373.2613 - val_loss: 6714557.3806\n",
      "Epoch 645/5000\n",
      "134/134 [==============================] - 0s 413us/step - loss: 7036942.5204 - val_loss: 6638919.8022\n",
      "Epoch 646/5000\n",
      "134/134 [==============================] - 0s 453us/step - loss: 7078271.6455 - val_loss: 6646782.5336\n",
      "Epoch 647/5000\n",
      "134/134 [==============================] - 0s 408us/step - loss: 7180864.6445 - val_loss: 6619988.7799\n",
      "Epoch 648/5000\n",
      "134/134 [==============================] - 0s 384us/step - loss: 7001667.2687 - val_loss: 6678110.5896\n",
      "Epoch 649/5000\n",
      "134/134 [==============================] - 0s 392us/step - loss: 7032117.7411 - val_loss: 6587564.1940\n",
      "Epoch 650/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 6953449.7724 - val_loss: 6630618.0634\n",
      "Epoch 651/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 7136246.2659 - val_loss: 6719303.0672\n",
      "Epoch 652/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 7034247.3793 - val_loss: 6549050.8060\n",
      "Epoch 653/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 7097332.1714 - val_loss: 6607811.1567\n",
      "Epoch 654/5000\n",
      "134/134 [==============================] - 0s 286us/step - loss: 7143214.8731 - val_loss: 6569919.3955\n",
      "Epoch 655/5000\n",
      "134/134 [==============================] - 0s 344us/step - loss: 6703243.9320 - val_loss: 6514079.2985\n",
      "Epoch 656/5000\n",
      "134/134 [==============================] - 0s 281us/step - loss: 6758875.7438 - val_loss: 6508421.5858\n",
      "Epoch 657/5000\n",
      "134/134 [==============================] - 0s 329us/step - loss: 6822655.0140 - val_loss: 6784791.8060\n",
      "Epoch 658/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 6983051.9496 - val_loss: 6452904.5597\n",
      "Epoch 659/5000\n",
      "134/134 [==============================] - 0s 287us/step - loss: 6836316.8207 - val_loss: 6438482.7425\n",
      "Epoch 660/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 6768483.5391 - val_loss: 6449507.8843\n",
      "Epoch 661/5000\n",
      "134/134 [==============================] - 0s 311us/step - loss: 6832435.1544 - val_loss: 6778234.3843\n",
      "Epoch 662/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 6885697.8433 - val_loss: 6497556.5746\n",
      "Epoch 663/5000\n",
      "134/134 [==============================] - 0s 361us/step - loss: 6739878.8620 - val_loss: 6397752.4328\n",
      "Epoch 664/5000\n",
      "134/134 [==============================] - 0s 331us/step - loss: 6810385.1866 - val_loss: 6383816.0821\n",
      "Epoch 665/5000\n",
      "134/134 [==============================] - 0s 282us/step - loss: 6541004.0596 - val_loss: 6360848.9067\n",
      "Epoch 666/5000\n",
      "134/134 [==============================] - 0s 329us/step - loss: 6750517.1159 - val_loss: 6342344.2836\n",
      "Epoch 667/5000\n",
      "134/134 [==============================] - 0s 294us/step - loss: 6534557.7351 - val_loss: 6422151.0597\n",
      "Epoch 668/5000\n",
      "134/134 [==============================] - 0s 329us/step - loss: 6782626.2799 - val_loss: 6309967.0075\n",
      "Epoch 669/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 6744916.8638 - val_loss: 6330811.7015\n",
      "Epoch 670/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 6761564.5680 - val_loss: 6286549.9403\n",
      "Epoch 671/5000\n",
      "134/134 [==============================] - 0s 295us/step - loss: 6442589.7848 - val_loss: 6277177.7985\n",
      "Epoch 672/5000\n",
      "134/134 [==============================] - 0s 319us/step - loss: 6624275.5939 - val_loss: 6334981.1754\n",
      "Epoch 673/5000\n",
      "134/134 [==============================] - 0s 276us/step - loss: 6849575.9958 - val_loss: 6254899.1455\n",
      "Epoch 674/5000\n",
      "134/134 [==============================] - 0s 324us/step - loss: 6685143.4907 - val_loss: 6290292.2425\n",
      "Epoch 675/5000\n",
      "134/134 [==============================] - 0s 343us/step - loss: 6538912.4515 - val_loss: 6306821.3507\n",
      "Epoch 676/5000\n",
      "134/134 [==============================] - 0s 294us/step - loss: 6756852.5030 - val_loss: 6206375.9851\n",
      "Epoch 677/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 6570190.6866 - val_loss: 6169081.3097\n",
      "Epoch 678/5000\n",
      "134/134 [==============================] - 0s 355us/step - loss: 6529351.7761 - val_loss: 6545026.3284\n",
      "Epoch 679/5000\n",
      "134/134 [==============================] - 0s 341us/step - loss: 6583519.8433 - val_loss: 6158518.9067\n",
      "Epoch 680/5000\n",
      "134/134 [==============================] - 0s 321us/step - loss: 6751057.2242 - val_loss: 6136494.8396\n",
      "Epoch 681/5000\n",
      "134/134 [==============================] - 0s 330us/step - loss: 6604147.1883 - val_loss: 6314017.5336\n",
      "Epoch 682/5000\n",
      "134/134 [==============================] - ETA: 0s - loss: 26306344.00 - 0s 388us/step - loss: 6899568.5095 - val_loss: 6191016.7351\n",
      "Epoch 683/5000\n",
      "134/134 [==============================] - 0s 342us/step - loss: 6486547.4076 - val_loss: 6099323.0597\n",
      "Epoch 684/5000\n",
      "134/134 [==============================] - 0s 367us/step - loss: 6525986.7971 - val_loss: 6077234.4925\n",
      "Epoch 685/5000\n",
      "134/134 [==============================] - 0s 362us/step - loss: 6348082.0455 - val_loss: 6047106.4105\n",
      "Epoch 686/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 298us/step - loss: 6313289.5387 - val_loss: 6076620.8694\n",
      "Epoch 687/5000\n",
      "134/134 [==============================] - 0s 311us/step - loss: 6395959.4065 - val_loss: 6151671.1679\n",
      "Epoch 688/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 6291909.6418 - val_loss: 6296542.3470\n",
      "Epoch 689/5000\n",
      "134/134 [==============================] - 0s 334us/step - loss: 6470877.4739 - val_loss: 6053102.7649\n",
      "Epoch 690/5000\n",
      "134/134 [==============================] - 0s 293us/step - loss: 6463455.4515 - val_loss: 5979414.2724\n",
      "Epoch 691/5000\n",
      "134/134 [==============================] - 0s 300us/step - loss: 6171547.5243 - val_loss: 6002361.7836\n",
      "Epoch 692/5000\n",
      "134/134 [==============================] - 0s 318us/step - loss: 6384947.1978 - val_loss: 5968536.8955\n",
      "Epoch 693/5000\n",
      "134/134 [==============================] - 0s 440us/step - loss: 6595973.1726 - val_loss: 5975154.5560\n",
      "Epoch 694/5000\n",
      "134/134 [==============================] - 0s 672us/step - loss: 6485718.4459 - val_loss: 5950424.6978\n",
      "Epoch 695/5000\n",
      "134/134 [==============================] - 0s 372us/step - loss: 6101219.5245 - val_loss: 5916090.5149\n",
      "Epoch 696/5000\n",
      "134/134 [==============================] - 0s 329us/step - loss: 6148683.1269 - val_loss: 5885778.1269\n",
      "Epoch 697/5000\n",
      "134/134 [==============================] - 0s 365us/step - loss: 6291275.7155 - val_loss: 6067515.0112\n",
      "Epoch 698/5000\n",
      "134/134 [==============================] - 0s 366us/step - loss: 6284752.8843 - val_loss: 5865966.9291\n",
      "Epoch 699/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 6418021.6928 - val_loss: 5883311.9291\n",
      "Epoch 700/5000\n",
      "134/134 [==============================] - 0s 353us/step - loss: 6270857.0520 - val_loss: 5948038.3769\n",
      "Epoch 701/5000\n",
      "134/134 [==============================] - 0s 440us/step - loss: 6087047.3964 - val_loss: 5834829.4552\n",
      "Epoch 702/5000\n",
      "134/134 [==============================] - 0s 480us/step - loss: 6168680.4109 - val_loss: 5793208.3769\n",
      "Epoch 703/5000\n",
      "134/134 [==============================] - 0s 442us/step - loss: 5969829.6539 - val_loss: 5810655.6007\n",
      "Epoch 704/5000\n",
      "134/134 [==============================] - 0s 412us/step - loss: 6201149.7153 - val_loss: 5802298.2276\n",
      "Epoch 705/5000\n",
      "134/134 [==============================] - 0s 420us/step - loss: 6175266.4515 - val_loss: 5799067.8769\n",
      "Epoch 706/5000\n",
      "134/134 [==============================] - 0s 380us/step - loss: 6075821.7368 - val_loss: 5966653.1679\n",
      "Epoch 707/5000\n",
      "134/134 [==============================] - 0s 359us/step - loss: 5967589.0131 - val_loss: 5796223.5858\n",
      "Epoch 708/5000\n",
      "134/134 [==============================] - 0s 412us/step - loss: 6206759.4832 - val_loss: 5772889.1082\n",
      "Epoch 709/5000\n",
      "134/134 [==============================] - 0s 390us/step - loss: 6022325.4104 - val_loss: 5888155.1679\n",
      "Epoch 710/5000\n",
      "134/134 [==============================] - 0s 392us/step - loss: 5968791.6870 - val_loss: 5725834.9478\n",
      "Epoch 711/5000\n",
      "134/134 [==============================] - 0s 325us/step - loss: 5976652.6040 - val_loss: 5709623.6343\n",
      "Epoch 712/5000\n",
      "134/134 [==============================] - 0s 304us/step - loss: 5971728.3828 - val_loss: 5707932.2873\n",
      "Epoch 713/5000\n",
      "134/134 [==============================] - 0s 329us/step - loss: 5922548.8914 - val_loss: 5693299.5149\n",
      "Epoch 714/5000\n",
      "134/134 [==============================] - 0s 346us/step - loss: 6171786.6528 - val_loss: 5644651.4963\n",
      "Epoch 715/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 5937219.8218 - val_loss: 5744968.7351\n",
      "Epoch 716/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 6288604.0749 - val_loss: 5638734.1716\n",
      "Epoch 717/5000\n",
      "134/134 [==============================] - 0s 294us/step - loss: 5898889.0319 - val_loss: 5623330.4440\n",
      "Epoch 718/5000\n",
      "134/134 [==============================] - 0s 385us/step - loss: 5989963.5112 - val_loss: 5741220.9142\n",
      "Epoch 719/5000\n",
      "134/134 [==============================] - 0s 346us/step - loss: 6020583.5546 - val_loss: 5618964.5037\n",
      "Epoch 720/5000\n",
      "134/134 [==============================] - 0s 336us/step - loss: 6014595.1688 - val_loss: 5642047.4702\n",
      "Epoch 721/5000\n",
      "134/134 [==============================] - 0s 341us/step - loss: 5989084.8946 - val_loss: 5604336.4478\n",
      "Epoch 722/5000\n",
      "134/134 [==============================] - 0s 403us/step - loss: 6055793.0429 - val_loss: 5631573.5299\n",
      "Epoch 723/5000\n",
      "134/134 [==============================] - 0s 350us/step - loss: 6039945.4832 - val_loss: 5538029.3358\n",
      "Epoch 724/5000\n",
      "134/134 [==============================] - 0s 317us/step - loss: 5835403.8786 - val_loss: 5617184.4105\n",
      "Epoch 725/5000\n",
      "134/134 [==============================] - ETA: 0s - loss: 50919.109 - 0s 364us/step - loss: 5838980.1026 - val_loss: 5534888.8619\n",
      "Epoch 726/5000\n",
      "134/134 [==============================] - 0s 351us/step - loss: 5657801.6362 - val_loss: 5490260.3545\n",
      "Epoch 727/5000\n",
      "134/134 [==============================] - 0s 459us/step - loss: 5915369.8868 - val_loss: 5476441.9664\n",
      "Epoch 728/5000\n",
      "134/134 [==============================] - 0s 426us/step - loss: 5997890.2474 - val_loss: 5538351.0933\n",
      "Epoch 729/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 5912090.6455 - val_loss: 5461248.7687\n",
      "Epoch 730/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 5952890.9356 - val_loss: 5443660.5709\n",
      "Epoch 731/5000\n",
      "134/134 [==============================] - 0s 392us/step - loss: 5727321.5135 - val_loss: 5432437.0000\n",
      "Epoch 732/5000\n",
      "134/134 [==============================] - 0s 434us/step - loss: 5904794.8668 - val_loss: 5443428.1231\n",
      "Epoch 733/5000\n",
      "134/134 [==============================] - 0s 350us/step - loss: 5661591.4922 - val_loss: 5388209.2090\n",
      "Epoch 734/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 5716384.4496 - val_loss: 5876472.5634\n",
      "Epoch 735/5000\n",
      "134/134 [==============================] - 0s 324us/step - loss: 5971141.7108 - val_loss: 5537215.4888\n",
      "Epoch 736/5000\n",
      "134/134 [==============================] - 0s 400us/step - loss: 5688650.6161 - val_loss: 5335666.1940\n",
      "Epoch 737/5000\n",
      "134/134 [==============================] - 0s 405us/step - loss: 5632462.6198 - val_loss: 5322295.1119\n",
      "Epoch 738/5000\n",
      "134/134 [==============================] - 0s 360us/step - loss: 5839243.1418 - val_loss: 5432323.9702\n",
      "Epoch 739/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 5861320.8451 - val_loss: 5304006.0037\n",
      "Epoch 740/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 5722506.1810 - val_loss: 5379403.2537\n",
      "Epoch 741/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 5772756.5518 - val_loss: 5302106.2052\n",
      "Epoch 742/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 5958451.3340 - val_loss: 5277892.5373\n",
      "Epoch 743/5000\n",
      "134/134 [==============================] - 0s 267us/step - loss: 5437940.8444 - val_loss: 5242764.0299\n",
      "Epoch 744/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 5768467.5942 - val_loss: 5263503.6119\n",
      "Epoch 745/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 5532322.1443 - val_loss: 5234437.8134\n",
      "Epoch 746/5000\n",
      "134/134 [==============================] - 0s 292us/step - loss: 5605938.2656 - val_loss: 5248210.8172\n",
      "Epoch 747/5000\n",
      "134/134 [==============================] - 0s 284us/step - loss: 5522888.8752 - val_loss: 5276961.4963\n",
      "Epoch 748/5000\n",
      "134/134 [==============================] - 0s 319us/step - loss: 5601871.7044 - val_loss: 5174034.5299\n",
      "Epoch 749/5000\n",
      "134/134 [==============================] - 0s 325us/step - loss: 5408960.1129 - val_loss: 5193975.9254\n",
      "Epoch 750/5000\n",
      "134/134 [==============================] - 0s 329us/step - loss: 5591643.1329 - val_loss: 5540777.9216\n",
      "Epoch 751/5000\n",
      "134/134 [==============================] - 0s 291us/step - loss: 5736519.0448 - val_loss: 5163883.0187\n",
      "Epoch 752/5000\n",
      "134/134 [==============================] - 0s 275us/step - loss: 5280853.0389 - val_loss: 5210903.2127\n",
      "Epoch 753/5000\n",
      "134/134 [==============================] - 0s 281us/step - loss: 5512117.4155 - val_loss: 5277323.1530\n",
      "Epoch 754/5000\n",
      "134/134 [==============================] - 0s 330us/step - loss: 5430563.3377 - val_loss: 5187376.1679\n",
      "Epoch 755/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 331us/step - loss: 5683212.0319 - val_loss: 5136818.7799\n",
      "Epoch 756/5000\n",
      "134/134 [==============================] - 0s 356us/step - loss: 5562896.1716 - val_loss: 5100288.4776\n",
      "Epoch 757/5000\n",
      "134/134 [==============================] - 0s 410us/step - loss: 5474287.9208 - val_loss: 5127579.3843\n",
      "Epoch 758/5000\n",
      "134/134 [==============================] - 0s 429us/step - loss: 5610532.1617 - val_loss: 5107922.9291\n",
      "Epoch 759/5000\n",
      "134/134 [==============================] - 0s 332us/step - loss: 5450809.5979 - val_loss: 5075006.1082\n",
      "Epoch 760/5000\n",
      "134/134 [==============================] - 0s 345us/step - loss: 5551157.5685 - val_loss: 5031058.9963\n",
      "Epoch 761/5000\n",
      "134/134 [==============================] - 0s 345us/step - loss: 5381032.4619 - val_loss: 5014422.0373\n",
      "Epoch 762/5000\n",
      "134/134 [==============================] - 0s 348us/step - loss: 5310308.6759 - val_loss: 5021072.9328\n",
      "Epoch 763/5000\n",
      "134/134 [==============================] - 0s 350us/step - loss: 5233723.0581 - val_loss: 5007884.2164\n",
      "Epoch 764/5000\n",
      "134/134 [==============================] - ETA: 0s - loss: 3378486.750 - 0s 373us/step - loss: 5252813.0471 - val_loss: 5018228.9925\n",
      "Epoch 765/5000\n",
      "134/134 [==============================] - 0s 367us/step - loss: 5425796.8638 - val_loss: 4975706.4216\n",
      "Epoch 766/5000\n",
      "134/134 [==============================] - 0s 349us/step - loss: 5375021.0211 - val_loss: 4946967.4328\n",
      "Epoch 767/5000\n",
      "134/134 [==============================] - ETA: 0s - loss: 7012749.500 - 0s 355us/step - loss: 5347884.1194 - val_loss: 4970715.5634\n",
      "Epoch 768/5000\n",
      "134/134 [==============================] - 0s 369us/step - loss: 5398147.6157 - val_loss: 5132161.7463\n",
      "Epoch 769/5000\n",
      "134/134 [==============================] - 0s 295us/step - loss: 5499051.5317 - val_loss: 4910583.6306\n",
      "Epoch 770/5000\n",
      "134/134 [==============================] - 0s 301us/step - loss: 5334400.1409 - val_loss: 4954389.4702\n",
      "Epoch 771/5000\n",
      "134/134 [==============================] - 0s 380us/step - loss: 5240276.0485 - val_loss: 4934047.7239\n",
      "Epoch 772/5000\n",
      "134/134 [==============================] - 0s 320us/step - loss: 5312719.5998 - val_loss: 4865746.9067\n",
      "Epoch 773/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 5351158.6157 - val_loss: 4908234.6716\n",
      "Epoch 774/5000\n",
      "134/134 [==============================] - 0s 320us/step - loss: 5266088.9838 - val_loss: 4913531.0075\n",
      "Epoch 775/5000\n",
      "134/134 [==============================] - 0s 361us/step - loss: 5358278.6814 - val_loss: 4845956.2537\n",
      "Epoch 776/5000\n",
      "134/134 [==============================] - 0s 311us/step - loss: 5178458.6047 - val_loss: 4889312.9963\n",
      "Epoch 777/5000\n",
      "134/134 [==============================] - 0s 304us/step - loss: 5148488.5190 - val_loss: 4951976.8993\n",
      "Epoch 778/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 5241205.6698 - val_loss: 5013626.6269\n",
      "Epoch 779/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 5397155.7444 - val_loss: 4804681.0149\n",
      "Epoch 780/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 5234116.0878 - val_loss: 4790444.8881\n",
      "Epoch 781/5000\n",
      "134/134 [==============================] - 0s 339us/step - loss: 5327151.3799 - val_loss: 4977900.8172\n",
      "Epoch 782/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 5153863.5638 - val_loss: 4796642.4813\n",
      "Epoch 783/5000\n",
      "134/134 [==============================] - 0s 297us/step - loss: 4930605.7357 - val_loss: 4773503.5075\n",
      "Epoch 784/5000\n",
      "134/134 [==============================] - 0s 324us/step - loss: 4970004.8126 - val_loss: 4783535.5000\n",
      "Epoch 785/5000\n",
      "134/134 [==============================] - 0s 336us/step - loss: 5060371.8041 - val_loss: 4799611.6679\n",
      "Epoch 786/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 4990907.4972 - val_loss: 4707311.3470\n",
      "Epoch 787/5000\n",
      "134/134 [==============================] - 0s 405us/step - loss: 5001345.4424 - val_loss: 4758902.9254\n",
      "Epoch 788/5000\n",
      "134/134 [==============================] - 0s 364us/step - loss: 5107916.0606 - val_loss: 4913424.3507\n",
      "Epoch 789/5000\n",
      "134/134 [==============================] - 0s 391us/step - loss: 5389659.3517 - val_loss: 4706194.1306\n",
      "Epoch 790/5000\n",
      "134/134 [==============================] - 0s 402us/step - loss: 5177790.9748 - val_loss: 4680076.5784\n",
      "Epoch 791/5000\n",
      "134/134 [==============================] - 0s 425us/step - loss: 4969015.0896 - val_loss: 5020518.8321\n",
      "Epoch 792/5000\n",
      "134/134 [==============================] - 0s 402us/step - loss: 5016678.7477 - val_loss: 4686391.1940\n",
      "Epoch 793/5000\n",
      "134/134 [==============================] - 0s 400us/step - loss: 4802544.1623 - val_loss: 4663255.2388\n",
      "Epoch 794/5000\n",
      "134/134 [==============================] - 0s 431us/step - loss: 4825077.0131 - val_loss: 4745759.3619\n",
      "Epoch 795/5000\n",
      "134/134 [==============================] - 0s 347us/step - loss: 4819203.9468 - val_loss: 4631143.4067\n",
      "Epoch 796/5000\n",
      "134/134 [==============================] - 0s 264us/step - loss: 4996164.8531 - val_loss: 4934216.4440\n",
      "Epoch 797/5000\n",
      "134/134 [==============================] - 0s 265us/step - loss: 4929194.2945 - val_loss: 4609475.6791\n",
      "Epoch 798/5000\n",
      "134/134 [==============================] - 0s 299us/step - loss: 4968686.9253 - val_loss: 4602601.2948\n",
      "Epoch 799/5000\n",
      "134/134 [==============================] - 0s 402us/step - loss: 4979154.7743 - val_loss: 4575824.7463\n",
      "Epoch 800/5000\n",
      "134/134 [==============================] - 0s 381us/step - loss: 4742450.4585 - val_loss: 4567079.3731\n",
      "Epoch 801/5000\n",
      "134/134 [==============================] - 0s 330us/step - loss: 4797939.7229 - val_loss: 4553355.3881\n",
      "Epoch 802/5000\n",
      "134/134 [==============================] - 0s 369us/step - loss: 4750819.5265 - val_loss: 4547404.7612\n",
      "Epoch 803/5000\n",
      "134/134 [==============================] - 0s 331us/step - loss: 4872667.5914 - val_loss: 4594891.0522\n",
      "Epoch 804/5000\n",
      "134/134 [==============================] - 0s 280us/step - loss: 4937054.2288 - val_loss: 4513692.2799\n",
      "Epoch 805/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 4734121.3323 - val_loss: 4503439.8694\n",
      "Epoch 806/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 4777251.2343 - val_loss: 4541032.9403\n",
      "Epoch 807/5000\n",
      "134/134 [==============================] - 0s 359us/step - loss: 4658390.9988 - val_loss: 4477671.6828\n",
      "Epoch 808/5000\n",
      "134/134 [==============================] - 0s 290us/step - loss: 4856391.1767 - val_loss: 4573207.4963\n",
      "Epoch 809/5000\n",
      "134/134 [==============================] - 0s 274us/step - loss: 4865713.4907 - val_loss: 4711372.8694\n",
      "Epoch 810/5000\n",
      "134/134 [==============================] - 0s 285us/step - loss: 4901054.8694 - val_loss: 4450767.0560\n",
      "Epoch 811/5000\n",
      "134/134 [==============================] - 0s 295us/step - loss: 4763094.6709 - val_loss: 4693052.8545\n",
      "Epoch 812/5000\n",
      "134/134 [==============================] - 0s 363us/step - loss: 4945574.1168 - val_loss: 4479510.4664\n",
      "Epoch 813/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 4675055.9086 - val_loss: 4462717.3769\n",
      "Epoch 814/5000\n",
      "134/134 [==============================] - 0s 282us/step - loss: 4761608.7771 - val_loss: 4529120.7127\n",
      "Epoch 815/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 4778282.9011 - val_loss: 4447382.4254\n",
      "Epoch 816/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 4674662.3458 - val_loss: 4392108.8806\n",
      "Epoch 817/5000\n",
      "134/134 [==============================] - 0s 286us/step - loss: 4892377.6076 - val_loss: 4365926.2649\n",
      "Epoch 818/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 4780673.9960 - val_loss: 4402226.2425\n",
      "Epoch 819/5000\n",
      "134/134 [==============================] - 0s 381us/step - loss: 4673047.5462 - val_loss: 4575003.7948\n",
      "Epoch 820/5000\n",
      "134/134 [==============================] - 0s 367us/step - loss: 4714306.6091 - val_loss: 4426783.5000\n",
      "Epoch 821/5000\n",
      "134/134 [==============================] - 0s 462us/step - loss: 4637247.8361 - val_loss: 4342332.6642\n",
      "Epoch 822/5000\n",
      "134/134 [==============================] - 0s 394us/step - loss: 4677334.5084 - val_loss: 4740066.5112\n",
      "Epoch 823/5000\n",
      "134/134 [==============================] - 0s 435us/step - loss: 4642038.6728 - val_loss: 4347795.8806\n",
      "Epoch 824/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 436us/step - loss: 4652106.4644 - val_loss: 4349087.0261\n",
      "Epoch 825/5000\n",
      "134/134 [==============================] - 0s 355us/step - loss: 4699535.6915 - val_loss: 4292518.5933\n",
      "Epoch 826/5000\n",
      "134/134 [==============================] - 0s 372us/step - loss: 4587753.6138 - val_loss: 4263584.2425\n",
      "Epoch 827/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 4427615.8246 - val_loss: 4390112.8918\n",
      "Epoch 828/5000\n",
      "134/134 [==============================] - 0s 357us/step - loss: 4558771.0250 - val_loss: 4250842.3918\n",
      "Epoch 829/5000\n",
      "134/134 [==============================] - 0s 285us/step - loss: 4696256.8860 - val_loss: 4241327.4739\n",
      "Epoch 830/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 4645905.8898 - val_loss: 4223092.4515\n",
      "Epoch 831/5000\n",
      "134/134 [==============================] - 0s 311us/step - loss: 4456025.3756 - val_loss: 4203289.6716\n",
      "Epoch 832/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 4466718.0758 - val_loss: 4334256.5858\n",
      "Epoch 833/5000\n",
      "134/134 [==============================] - 0s 324us/step - loss: 4593622.4900 - val_loss: 4243351.8246\n",
      "Epoch 834/5000\n",
      "134/134 [==============================] - 0s 298us/step - loss: 4612389.5647 - val_loss: 4216941.1007\n",
      "Epoch 835/5000\n",
      "134/134 [==============================] - 0s 293us/step - loss: 4438448.7146 - val_loss: 4196034.5149\n",
      "Epoch 836/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 4578477.6418 - val_loss: 4391715.8022\n",
      "Epoch 837/5000\n",
      "134/134 [==============================] - 0s 315us/step - loss: 4779581.5392 - val_loss: 4224646.2127\n",
      "Epoch 838/5000\n",
      "134/134 [==============================] - 0s 331us/step - loss: 4323260.2732 - val_loss: 4159282.9888\n",
      "Epoch 839/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 4389764.1034 - val_loss: 4197129.4851\n",
      "Epoch 840/5000\n",
      "134/134 [==============================] - 0s 349us/step - loss: 4284263.2971 - val_loss: 4133715.8731\n",
      "Epoch 841/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 4400791.9832 - val_loss: 4214969.5075\n",
      "Epoch 842/5000\n",
      "134/134 [==============================] - 0s 333us/step - loss: 4640132.7361 - val_loss: 4110522.7425\n",
      "Epoch 843/5000\n",
      "134/134 [==============================] - 0s 299us/step - loss: 4456081.0000 - val_loss: 4323523.4739\n",
      "Epoch 844/5000\n",
      "134/134 [==============================] - 0s 301us/step - loss: 4502278.3237 - val_loss: 4099880.5709\n",
      "Epoch 845/5000\n",
      "134/134 [==============================] - 0s 267us/step - loss: 4408291.7235 - val_loss: 4049890.6045\n",
      "Epoch 846/5000\n",
      "134/134 [==============================] - 0s 279us/step - loss: 4480984.4405 - val_loss: 4160956.5634\n",
      "Epoch 847/5000\n",
      "134/134 [==============================] - 0s 318us/step - loss: 4148521.4949 - val_loss: 4034072.8619\n",
      "Epoch 848/5000\n",
      "134/134 [==============================] - 0s 301us/step - loss: 4204990.6136 - val_loss: 4115264.5224\n",
      "Epoch 849/5000\n",
      "134/134 [==============================] - 0s 315us/step - loss: 4331076.6754 - val_loss: 4305167.3993\n",
      "Epoch 850/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 4506776.4347 - val_loss: 4010671.1716\n",
      "Epoch 851/5000\n",
      "134/134 [==============================] - 0s 297us/step - loss: 4241812.5494 - val_loss: 4334195.0485\n",
      "Epoch 852/5000\n",
      "134/134 [==============================] - 0s 331us/step - loss: 4418909.2150 - val_loss: 3997086.1194\n",
      "Epoch 853/5000\n",
      "134/134 [==============================] - 0s 348us/step - loss: 4251335.2444 - val_loss: 4001343.5000\n",
      "Epoch 854/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 4363652.0410 - val_loss: 4011322.7537\n",
      "Epoch 855/5000\n",
      "134/134 [==============================] - 0s 295us/step - loss: 4261134.8820 - val_loss: 3961085.4888\n",
      "Epoch 856/5000\n",
      "134/134 [==============================] - 0s 348us/step - loss: 4238044.0964 - val_loss: 3955967.1455\n",
      "Epoch 857/5000\n",
      "134/134 [==============================] - 0s 320us/step - loss: 4230488.7687 - val_loss: 4178407.6530\n",
      "Epoch 858/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 4143196.1034 - val_loss: 4017141.6978\n",
      "Epoch 859/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 4235140.1805 - val_loss: 3913852.2799\n",
      "Epoch 860/5000\n",
      "134/134 [==============================] - 0s 352us/step - loss: 4339517.9440 - val_loss: 3923008.8022\n",
      "Epoch 861/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 4117033.8102 - val_loss: 3953386.1828\n",
      "Epoch 862/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 4095770.2453 - val_loss: 3896664.3246\n",
      "Epoch 863/5000\n",
      "134/134 [==============================] - 0s 334us/step - loss: 4105448.8327 - val_loss: 3876957.4963\n",
      "Epoch 864/5000\n",
      "134/134 [==============================] - 0s 317us/step - loss: 4129176.7476 - val_loss: 3902390.5299\n",
      "Epoch 865/5000\n",
      "134/134 [==============================] - 0s 336us/step - loss: 4153222.0438 - val_loss: 3997983.5634\n",
      "Epoch 866/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 4443042.4960 - val_loss: 3954626.0037\n",
      "Epoch 867/5000\n",
      "134/134 [==============================] - 0s 343us/step - loss: 4289126.1371 - val_loss: 3968383.7276\n",
      "Epoch 868/5000\n",
      "134/134 [==============================] - 0s 325us/step - loss: 4138968.4408 - val_loss: 4320805.7127\n",
      "Epoch 869/5000\n",
      "134/134 [==============================] - 0s 349us/step - loss: 4227562.2295 - val_loss: 3846522.8881\n",
      "Epoch 870/5000\n",
      "134/134 [==============================] - 0s 318us/step - loss: 4204233.5705 - val_loss: 3846885.5075\n",
      "Epoch 871/5000\n",
      "134/134 [==============================] - 0s 319us/step - loss: 4237571.8905 - val_loss: 3822868.2537\n",
      "Epoch 872/5000\n",
      "134/134 [==============================] - 0s 325us/step - loss: 4002361.7835 - val_loss: 3891277.5896\n",
      "Epoch 873/5000\n",
      "134/134 [==============================] - 0s 331us/step - loss: 3988937.1877 - val_loss: 3765957.5187\n",
      "Epoch 874/5000\n",
      "134/134 [==============================] - 0s 324us/step - loss: 3960894.9978 - val_loss: 3915373.7202\n",
      "Epoch 875/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 4189272.3451 - val_loss: 4053540.0037\n",
      "Epoch 876/5000\n",
      "134/134 [==============================] - 0s 334us/step - loss: 4067775.1856 - val_loss: 4038387.5075\n",
      "Epoch 877/5000\n",
      "134/134 [==============================] - 0s 355us/step - loss: 4057741.0596 - val_loss: 3784893.8358\n",
      "Epoch 878/5000\n",
      "134/134 [==============================] - 0s 367us/step - loss: 4256434.2431 - val_loss: 3749586.5597\n",
      "Epoch 879/5000\n",
      "134/134 [==============================] - 0s 292us/step - loss: 3977130.8419 - val_loss: 3778029.8993\n",
      "Epoch 880/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 4045494.2931 - val_loss: 3777868.1978\n",
      "Epoch 881/5000\n",
      "134/134 [==============================] - 0s 267us/step - loss: 3926244.8518 - val_loss: 3938567.4067\n",
      "Epoch 882/5000\n",
      "134/134 [==============================] - 0s 337us/step - loss: 3904299.4460 - val_loss: 3739007.4590\n",
      "Epoch 883/5000\n",
      "134/134 [==============================] - 0s 298us/step - loss: 3848779.2754 - val_loss: 3702429.7425\n",
      "Epoch 884/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 3840718.1658 - val_loss: 3719260.5933\n",
      "Epoch 885/5000\n",
      "134/134 [==============================] - 0s 321us/step - loss: 3976264.5471 - val_loss: 3701002.6082\n",
      "Epoch 886/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 4044231.1493 - val_loss: 3957258.5952\n",
      "Epoch 887/5000\n",
      "134/134 [==============================] - 0s 269us/step - loss: 3818006.5520 - val_loss: 3680675.8060\n",
      "Epoch 888/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 3875599.1337 - val_loss: 3655084.8694\n",
      "Epoch 889/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 3777501.2598 - val_loss: 3655145.7239\n",
      "Epoch 890/5000\n",
      "134/134 [==============================] - 0s 330us/step - loss: 3841257.8029 - val_loss: 3610156.2873\n",
      "Epoch 891/5000\n",
      "134/134 [==============================] - 0s 319us/step - loss: 3791463.0199 - val_loss: 3689802.0485\n",
      "Epoch 892/5000\n",
      "134/134 [==============================] - 0s 377us/step - loss: 3752696.4249 - val_loss: 3589518.2313\n",
      "Epoch 893/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 311us/step - loss: 3728413.3618 - val_loss: 3644926.9776\n",
      "Epoch 894/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 3833680.5746 - val_loss: 3738216.2873\n",
      "Epoch 895/5000\n",
      "134/134 [==============================] - 0s 329us/step - loss: 3866329.2048 - val_loss: 3583173.5037\n",
      "Epoch 896/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 3785763.3372 - val_loss: 3582046.0299\n",
      "Epoch 897/5000\n",
      "134/134 [==============================] - 0s 365us/step - loss: 3757194.5304 - val_loss: 3562694.7910\n",
      "Epoch 898/5000\n",
      "134/134 [==============================] - 0s 300us/step - loss: 3793988.6842 - val_loss: 3545543.9515\n",
      "Epoch 899/5000\n",
      "134/134 [==============================] - 0s 256us/step - loss: 3647095.2227 - val_loss: 3530073.8321\n",
      "Epoch 900/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 3808373.3779 - val_loss: 3617614.1157\n",
      "Epoch 901/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 3771850.9639 - val_loss: 3680762.9142\n",
      "Epoch 902/5000\n",
      "134/134 [==============================] - 0s 298us/step - loss: 3831747.3344 - val_loss: 3783398.6754\n",
      "Epoch 903/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 3812098.9977 - val_loss: 3512838.4030\n",
      "Epoch 904/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 3645453.6041 - val_loss: 3515609.0746\n",
      "Epoch 905/5000\n",
      "134/134 [==============================] - 0s 297us/step - loss: 3603663.4086 - val_loss: 3697855.6231\n",
      "Epoch 906/5000\n",
      "134/134 [==============================] - 0s 332us/step - loss: 3874043.9570 - val_loss: 3504792.1119\n",
      "Epoch 907/5000\n",
      "134/134 [==============================] - 0s 311us/step - loss: 3733736.3759 - val_loss: 3600573.8806\n",
      "Epoch 908/5000\n",
      "134/134 [==============================] - 0s 300us/step - loss: 3847007.7745 - val_loss: 3472326.3769\n",
      "Epoch 909/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 3528218.1368 - val_loss: 3448247.3619\n",
      "Epoch 910/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 3703729.0893 - val_loss: 3435972.2127\n",
      "Epoch 911/5000\n",
      "134/134 [==============================] - 0s 318us/step - loss: 3597624.2571 - val_loss: 3481432.2836\n",
      "Epoch 912/5000\n",
      "134/134 [==============================] - 0s 300us/step - loss: 3636583.1698 - val_loss: 3452559.2052\n",
      "Epoch 913/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 3628968.5701 - val_loss: 3516591.8470\n",
      "Epoch 914/5000\n",
      "134/134 [==============================] - 0s 287us/step - loss: 3513845.4864 - val_loss: 3411164.9030\n",
      "Epoch 915/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 3538846.5020 - val_loss: 3417755.6269\n",
      "Epoch 916/5000\n",
      "134/134 [==============================] - 0s 368us/step - loss: 3643870.8879 - val_loss: 3447452.4627\n",
      "Epoch 917/5000\n",
      "134/134 [==============================] - 0s 354us/step - loss: 3599619.4514 - val_loss: 3404507.3097\n",
      "Epoch 918/5000\n",
      "134/134 [==============================] - 0s 347us/step - loss: 3711088.6901 - val_loss: 3792576.9702\n",
      "Epoch 919/5000\n",
      "134/134 [==============================] - 0s 346us/step - loss: 3791030.7202 - val_loss: 3382151.7687\n",
      "Epoch 920/5000\n",
      "134/134 [==============================] - 0s 331us/step - loss: 3713954.1740 - val_loss: 3364199.6119\n",
      "Epoch 921/5000\n",
      "134/134 [==============================] - 0s 294us/step - loss: 3413531.5271 - val_loss: 3350387.9403\n",
      "Epoch 922/5000\n",
      "134/134 [==============================] - 0s 294us/step - loss: 3514152.1311 - val_loss: 3364160.8694\n",
      "Epoch 923/5000\n",
      "134/134 [==============================] - 0s 317us/step - loss: 3422418.3976 - val_loss: 3490522.1567\n",
      "Epoch 924/5000\n",
      "134/134 [==============================] - 0s 301us/step - loss: 3618341.0399 - val_loss: 3711429.2202\n",
      "Epoch 925/5000\n",
      "134/134 [==============================] - 0s 277us/step - loss: 3867575.7962 - val_loss: 3414545.0112\n",
      "Epoch 926/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 3587897.1847 - val_loss: 3836227.6940\n",
      "Epoch 927/5000\n",
      "134/134 [==============================] - 0s 288us/step - loss: 3853845.6240 - val_loss: 3366048.6642\n",
      "Epoch 928/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 3498537.9993 - val_loss: 3307023.5522\n",
      "Epoch 929/5000\n",
      "134/134 [==============================] - 0s 299us/step - loss: 3454785.5080 - val_loss: 3291148.5336\n",
      "Epoch 930/5000\n",
      "134/134 [==============================] - 0s 318us/step - loss: 3417845.2338 - val_loss: 3295950.0373\n",
      "Epoch 931/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 3496885.8981 - val_loss: 3251881.3060\n",
      "Epoch 932/5000\n",
      "134/134 [==============================] - 0s 282us/step - loss: 3446516.9591 - val_loss: 3266608.8172\n",
      "Epoch 933/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 3545671.3097 - val_loss: 3616456.6605\n",
      "Epoch 934/5000\n",
      "134/134 [==============================] - 0s 311us/step - loss: 3798558.0407 - val_loss: 3295186.0746\n",
      "Epoch 935/5000\n",
      "134/134 [==============================] - 0s 290us/step - loss: 3385428.8470 - val_loss: 3255198.0037\n",
      "Epoch 936/5000\n",
      "134/134 [==============================] - 0s 321us/step - loss: 3505719.2025 - val_loss: 3238870.6306\n",
      "Epoch 937/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 3469345.5223 - val_loss: 3243680.6381\n",
      "Epoch 938/5000\n",
      "134/134 [==============================] - 0s 363us/step - loss: 3431220.7998 - val_loss: 3302851.4627\n",
      "Epoch 939/5000\n",
      "134/134 [==============================] - 0s 365us/step - loss: 3458614.4312 - val_loss: 3189557.0709\n",
      "Epoch 940/5000\n",
      "134/134 [==============================] - 0s 345us/step - loss: 3533354.3479 - val_loss: 3244770.5821\n",
      "Epoch 941/5000\n",
      "134/134 [==============================] - 0s 272us/step - loss: 3432612.3960 - val_loss: 3356732.0858\n",
      "Epoch 942/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 3504703.4376 - val_loss: 3398650.8694\n",
      "Epoch 943/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 3625867.8582 - val_loss: 3202889.8881\n",
      "Epoch 944/5000\n",
      "134/134 [==============================] - 0s 360us/step - loss: 3378064.6974 - val_loss: 3156433.7351\n",
      "Epoch 945/5000\n",
      "134/134 [==============================] - 0s 368us/step - loss: 3406131.9611 - val_loss: 3147367.4105\n",
      "Epoch 946/5000\n",
      "134/134 [==============================] - 0s 352us/step - loss: 3513460.4002 - val_loss: 3138105.9142\n",
      "Epoch 947/5000\n",
      "134/134 [==============================] - 0s 407us/step - loss: 3323038.3321 - val_loss: 3495141.8377\n",
      "Epoch 948/5000\n",
      "134/134 [==============================] - 0s 349us/step - loss: 3342056.6460 - val_loss: 3140007.7873\n",
      "Epoch 949/5000\n",
      "134/134 [==============================] - 0s 280us/step - loss: 3314018.1214 - val_loss: 3144514.9440\n",
      "Epoch 950/5000\n",
      "134/134 [==============================] - 0s 284us/step - loss: 3248882.2782 - val_loss: 3159706.1194\n",
      "Epoch 951/5000\n",
      "134/134 [==============================] - 0s 311us/step - loss: 3205808.9627 - val_loss: 3103830.8545\n",
      "Epoch 952/5000\n",
      "134/134 [==============================] - 0s 335us/step - loss: 3271602.0905 - val_loss: 3099712.4179\n",
      "Epoch 953/5000\n",
      "134/134 [==============================] - 0s 277us/step - loss: 3202398.1196 - val_loss: 3103290.7351\n",
      "Epoch 954/5000\n",
      "134/134 [==============================] - 0s 324us/step - loss: 3099567.1178 - val_loss: 3106677.0056\n",
      "Epoch 955/5000\n",
      "134/134 [==============================] - 0s 299us/step - loss: 3322252.4611 - val_loss: 3128231.2500\n",
      "Epoch 956/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 3329740.4193 - val_loss: 3057884.9440\n",
      "Epoch 957/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 3326779.9766 - val_loss: 3142373.5373\n",
      "Epoch 958/5000\n",
      "134/134 [==============================] - 0s 274us/step - loss: 3324583.6194 - val_loss: 3074102.5075\n",
      "Epoch 959/5000\n",
      "134/134 [==============================] - 0s 259us/step - loss: 3311156.1770 - val_loss: 3054909.3806\n",
      "Epoch 960/5000\n",
      "134/134 [==============================] - 0s 324us/step - loss: 3323126.9064 - val_loss: 3055296.1791\n",
      "Epoch 961/5000\n",
      "134/134 [==============================] - 0s 318us/step - loss: 3217963.1741 - val_loss: 3001258.3134\n",
      "Epoch 962/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 371us/step - loss: 3121470.1077 - val_loss: 3044756.2202\n",
      "Epoch 963/5000\n",
      "134/134 [==============================] - 0s 354us/step - loss: 3180235.3735 - val_loss: 3060637.6716\n",
      "Epoch 964/5000\n",
      "134/134 [==============================] - 0s 364us/step - loss: 3237216.8369 - val_loss: 2981573.4515\n",
      "Epoch 965/5000\n",
      "134/134 [==============================] - 0s 376us/step - loss: 3051140.0452 - val_loss: 3240210.4813\n",
      "Epoch 966/5000\n",
      "134/134 [==============================] - 0s 332us/step - loss: 3035745.9426 - val_loss: 3147400.2164\n",
      "Epoch 967/5000\n",
      "134/134 [==============================] - 0s 345us/step - loss: 3155974.7190 - val_loss: 2950645.7910\n",
      "Epoch 968/5000\n",
      "134/134 [==============================] - 0s 283us/step - loss: 3129000.5236 - val_loss: 3020899.0896\n",
      "Epoch 969/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 3055997.2759 - val_loss: 2983532.1567\n",
      "Epoch 970/5000\n",
      "134/134 [==============================] - 0s 304us/step - loss: 3112851.1243 - val_loss: 3039814.9030\n",
      "Epoch 971/5000\n",
      "134/134 [==============================] - 0s 298us/step - loss: 3303486.0340 - val_loss: 2925545.1903\n",
      "Epoch 972/5000\n",
      "134/134 [==============================] - 0s 318us/step - loss: 3115436.6655 - val_loss: 2943575.6455\n",
      "Epoch 973/5000\n",
      "134/134 [==============================] - 0s 297us/step - loss: 3243028.2604 - val_loss: 2968256.3246\n",
      "Epoch 974/5000\n",
      "134/134 [==============================] - 0s 315us/step - loss: 3218987.2516 - val_loss: 2907109.2164\n",
      "Epoch 975/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 3011789.4366 - val_loss: 2898322.5784\n",
      "Epoch 976/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 3083312.8441 - val_loss: 2944437.7892\n",
      "Epoch 977/5000\n",
      "134/134 [==============================] - 0s 339us/step - loss: 3086481.6613 - val_loss: 3137249.2537\n",
      "Epoch 978/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 3227199.2160 - val_loss: 2890595.8358\n",
      "Epoch 979/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 3195017.0485 - val_loss: 3081442.7687\n",
      "Epoch 980/5000\n",
      "134/134 [==============================] - 0s 315us/step - loss: 3081932.4921 - val_loss: 2916082.5746\n",
      "Epoch 981/5000\n",
      "134/134 [==============================] - 0s 337us/step - loss: 3116841.4537 - val_loss: 2964920.6828\n",
      "Epoch 982/5000\n",
      "134/134 [==============================] - 0s 285us/step - loss: 2955870.5429 - val_loss: 2860601.9888\n",
      "Epoch 983/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 2992083.1783 - val_loss: 3412612.5709\n",
      "Epoch 984/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 3279666.9993 - val_loss: 2946180.1381\n",
      "Epoch 985/5000\n",
      "134/134 [==============================] - 0s 290us/step - loss: 3001718.2432 - val_loss: 2860386.1213\n",
      "Epoch 986/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 3119754.9511 - val_loss: 2804509.7575\n",
      "Epoch 987/5000\n",
      "134/134 [==============================] - 0s 304us/step - loss: 3097927.5818 - val_loss: 2917196.4478\n",
      "Epoch 988/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 3148566.2709 - val_loss: 2881905.5858\n",
      "Epoch 989/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 2886546.4103 - val_loss: 2907885.7649\n",
      "Epoch 990/5000\n",
      "134/134 [==============================] - 0s 323us/step - loss: 3007278.9972 - val_loss: 2842874.6269\n",
      "Epoch 991/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 2910963.0659 - val_loss: 2831962.5224\n",
      "Epoch 992/5000\n",
      "134/134 [==============================] - 0s 334us/step - loss: 2909237.6674 - val_loss: 3055369.1660\n",
      "Epoch 993/5000\n",
      "134/134 [==============================] - 0s 317us/step - loss: 3458340.7338 - val_loss: 2797965.8097\n",
      "Epoch 994/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 2951075.9402 - val_loss: 2959430.5075\n",
      "Epoch 995/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 2980419.1782 - val_loss: 2858256.4291\n",
      "Epoch 996/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 2967608.5180 - val_loss: 2841927.5485\n",
      "Epoch 997/5000\n",
      "134/134 [==============================] - 0s 330us/step - loss: 3003578.8907 - val_loss: 2901768.0410\n",
      "Epoch 998/5000\n",
      "134/134 [==============================] - 0s 336us/step - loss: 3001635.7675 - val_loss: 2734076.7687\n",
      "Epoch 999/5000\n",
      "134/134 [==============================] - 0s 336us/step - loss: 2910839.4523 - val_loss: 2785461.0896\n",
      "Epoch 1000/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 2834480.9236 - val_loss: 2719512.6418\n",
      "Epoch 1001/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 2876205.7463 - val_loss: 2746735.0168\n",
      "Epoch 1002/5000\n",
      "134/134 [==============================] - 0s 365us/step - loss: 2824368.1017 - val_loss: 2734057.6940\n",
      "Epoch 1003/5000\n",
      "134/134 [==============================] - 0s 343us/step - loss: 2791746.0311 - val_loss: 2741583.5560\n",
      "Epoch 1004/5000\n",
      "134/134 [==============================] - 0s 357us/step - loss: 2975291.3917 - val_loss: 2763859.4925\n",
      "Epoch 1005/5000\n",
      "134/134 [==============================] - 0s 356us/step - loss: 2777842.6567 - val_loss: 3399439.7052\n",
      "Epoch 1006/5000\n",
      "134/134 [==============================] - 0s 365us/step - loss: 3046139.6812 - val_loss: 2689615.7425\n",
      "Epoch 1007/5000\n",
      "134/134 [==============================] - 0s 379us/step - loss: 2830878.4337 - val_loss: 2676705.5075\n",
      "Epoch 1008/5000\n",
      "134/134 [==============================] - 0s 357us/step - loss: 2753503.8547 - val_loss: 3018644.6045\n",
      "Epoch 1009/5000\n",
      "134/134 [==============================] - 0s 356us/step - loss: 2781947.8511 - val_loss: 2717888.0522\n",
      "Epoch 1010/5000\n",
      "134/134 [==============================] - 0s 333us/step - loss: 2909015.2795 - val_loss: 2720501.7873\n",
      "Epoch 1011/5000\n",
      "134/134 [==============================] - ETA: 0s - loss: 753288.81 - 0s 358us/step - loss: 2826807.6539 - val_loss: 3164565.1306\n",
      "Epoch 1012/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 2961092.3752 - val_loss: 2688607.3619\n",
      "Epoch 1013/5000\n",
      "134/134 [==============================] - 0s 299us/step - loss: 2865503.9936 - val_loss: 2653130.7351\n",
      "Epoch 1014/5000\n",
      "134/134 [==============================] - 0s 318us/step - loss: 2796733.2637 - val_loss: 2638982.4403\n",
      "Epoch 1015/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 2942946.4725 - val_loss: 2660378.0522\n",
      "Epoch 1016/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 2842627.5655 - val_loss: 2617046.8396\n",
      "Epoch 1017/5000\n",
      "134/134 [==============================] - 0s 335us/step - loss: 2855577.1530 - val_loss: 2620945.2948\n",
      "Epoch 1018/5000\n",
      "134/134 [==============================] - 0s 330us/step - loss: 2782074.1369 - val_loss: 2615273.1679\n",
      "Epoch 1019/5000\n",
      "134/134 [==============================] - 0s 286us/step - loss: 2757639.4678 - val_loss: 2642009.4888\n",
      "Epoch 1020/5000\n",
      "134/134 [==============================] - 0s 333us/step - loss: 2835449.7055 - val_loss: 2708040.7724\n",
      "Epoch 1021/5000\n",
      "134/134 [==============================] - 0s 311us/step - loss: 2856596.6307 - val_loss: 2737460.3601\n",
      "Epoch 1022/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 2806236.1500 - val_loss: 2900957.1754\n",
      "Epoch 1023/5000\n",
      "134/134 [==============================] - 0s 333us/step - loss: 2997340.7603 - val_loss: 2577622.7164\n",
      "Epoch 1024/5000\n",
      "134/134 [==============================] - 0s 343us/step - loss: 2745755.7103 - val_loss: 2898706.1605\n",
      "Epoch 1025/5000\n",
      "134/134 [==============================] - 0s 362us/step - loss: 2780401.9914 - val_loss: 2587669.2649\n",
      "Epoch 1026/5000\n",
      "134/134 [==============================] - 0s 362us/step - loss: 2774418.3247 - val_loss: 2564991.9328\n",
      "Epoch 1027/5000\n",
      "134/134 [==============================] - 0s 390us/step - loss: 2800489.1577 - val_loss: 2617066.9963\n",
      "Epoch 1028/5000\n",
      "134/134 [==============================] - 0s 386us/step - loss: 2740190.3161 - val_loss: 2527760.5784\n",
      "Epoch 1029/5000\n",
      "134/134 [==============================] - 0s 369us/step - loss: 2770950.0803 - val_loss: 2548573.2575\n",
      "Epoch 1030/5000\n",
      "134/134 [==============================] - 0s 356us/step - loss: 2716488.5317 - val_loss: 2526653.8955\n",
      "Epoch 1031/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 363us/step - loss: 2564595.5864 - val_loss: 2569767.8022\n",
      "Epoch 1032/5000\n",
      "134/134 [==============================] - 0s 399us/step - loss: 2818854.2010 - val_loss: 2541276.3731\n",
      "Epoch 1033/5000\n",
      "134/134 [==============================] - 0s 352us/step - loss: 2755311.5982 - val_loss: 2495701.0112\n",
      "Epoch 1034/5000\n",
      "134/134 [==============================] - 0s 332us/step - loss: 2728295.8542 - val_loss: 2507297.2164\n",
      "Epoch 1035/5000\n",
      "134/134 [==============================] - 0s 377us/step - loss: 2743314.0595 - val_loss: 2533752.7500\n",
      "Epoch 1036/5000\n",
      "134/134 [==============================] - 0s 338us/step - loss: 2758884.5172 - val_loss: 2497638.1306\n",
      "Epoch 1037/5000\n",
      "134/134 [==============================] - 0s 341us/step - loss: 2789219.3284 - val_loss: 2516466.4142\n",
      "Epoch 1038/5000\n",
      "134/134 [==============================] - 0s 331us/step - loss: 2845955.0667 - val_loss: 2534641.3433\n",
      "Epoch 1039/5000\n",
      "134/134 [==============================] - 0s 377us/step - loss: 2718803.0186 - val_loss: 2522384.2202\n",
      "Epoch 1040/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 2727811.3174 - val_loss: 2535719.9944\n",
      "Epoch 1041/5000\n",
      "134/134 [==============================] - 0s 378us/step - loss: 2720033.0081 - val_loss: 2469575.3358\n",
      "Epoch 1042/5000\n",
      "134/134 [==============================] - 0s 332us/step - loss: 2770508.2682 - val_loss: 2874827.3246\n",
      "Epoch 1043/5000\n",
      "134/134 [==============================] - 0s 357us/step - loss: 2856800.1041 - val_loss: 2500900.6082\n",
      "Epoch 1044/5000\n",
      "134/134 [==============================] - 0s 349us/step - loss: 2509218.8876 - val_loss: 2432555.5560\n",
      "Epoch 1045/5000\n",
      "134/134 [==============================] - 0s 368us/step - loss: 2607741.4608 - val_loss: 2405730.6903\n",
      "Epoch 1046/5000\n",
      "134/134 [==============================] - 0s 363us/step - loss: 2502100.4701 - val_loss: 2473978.2873\n",
      "Epoch 1047/5000\n",
      "134/134 [==============================] - 0s 359us/step - loss: 2484322.3064 - val_loss: 2404600.9291\n",
      "Epoch 1048/5000\n",
      "134/134 [==============================] - 0s 365us/step - loss: 2532589.0366 - val_loss: 2659627.7164\n",
      "Epoch 1049/5000\n",
      "134/134 [==============================] - 0s 373us/step - loss: 2672439.4882 - val_loss: 2970678.7202\n",
      "Epoch 1050/5000\n",
      "134/134 [==============================] - 0s 439us/step - loss: 2690191.7379 - val_loss: 2361700.5112\n",
      "Epoch 1051/5000\n",
      "134/134 [==============================] - 0s 380us/step - loss: 2635847.8565 - val_loss: 2618041.6343\n",
      "Epoch 1052/5000\n",
      "134/134 [==============================] - 0s 399us/step - loss: 2587656.2281 - val_loss: 2616030.8246\n",
      "Epoch 1053/5000\n",
      "134/134 [==============================] - 0s 299us/step - loss: 2648503.8879 - val_loss: 2530066.5075\n",
      "Epoch 1054/5000\n",
      "134/134 [==============================] - 0s 291us/step - loss: 2658323.6026 - val_loss: 2586124.5522\n",
      "Epoch 1055/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 2992860.5168 - val_loss: 2428437.8134\n",
      "Epoch 1056/5000\n",
      "134/134 [==============================] - 0s 294us/step - loss: 2409484.1185 - val_loss: 2358144.1007\n",
      "Epoch 1057/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 2410888.2933 - val_loss: 2576982.9813\n",
      "Epoch 1058/5000\n",
      "134/134 [==============================] - 0s 290us/step - loss: 2528836.0714 - val_loss: 2339474.1754\n",
      "Epoch 1059/5000\n",
      "134/134 [==============================] - 0s 292us/step - loss: 2543244.3783 - val_loss: 3008850.1325\n",
      "Epoch 1060/5000\n",
      "134/134 [==============================] - 0s 304us/step - loss: 2686643.1502 - val_loss: 2377050.9776\n",
      "Epoch 1061/5000\n",
      "134/134 [==============================] - 0s 329us/step - loss: 2449029.2915 - val_loss: 2317463.9067\n",
      "Epoch 1062/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 2457390.9390 - val_loss: 2382632.4254\n",
      "Epoch 1063/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 2504103.9468 - val_loss: 2316058.7500\n",
      "Epoch 1064/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 2519111.4272 - val_loss: 2276658.4851\n",
      "Epoch 1065/5000\n",
      "134/134 [==============================] - 0s 356us/step - loss: 2387014.4874 - val_loss: 2320253.2202\n",
      "Epoch 1066/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 2414834.3362 - val_loss: 2325715.7239\n",
      "Epoch 1067/5000\n",
      "134/134 [==============================] - 0s 293us/step - loss: 2396003.0683 - val_loss: 2728751.6530\n",
      "Epoch 1068/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 2555520.8465 - val_loss: 2245025.4440\n",
      "Epoch 1069/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 2297875.5310 - val_loss: 2226140.3358\n",
      "Epoch 1070/5000\n",
      "134/134 [==============================] - 0s 418us/step - loss: 2288839.4359 - val_loss: 2259531.0187\n",
      "Epoch 1071/5000\n",
      "134/134 [==============================] - 0s 334us/step - loss: 2465607.0697 - val_loss: 2205986.3246\n",
      "Epoch 1072/5000\n",
      "134/134 [==============================] - 0s 368us/step - loss: 2303617.3559 - val_loss: 2236466.7537\n",
      "Epoch 1073/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 2463566.2794 - val_loss: 2240586.8806\n",
      "Epoch 1074/5000\n",
      "134/134 [==============================] - 0s 343us/step - loss: 2650575.9994 - val_loss: 2206198.6493\n",
      "Epoch 1075/5000\n",
      "134/134 [==============================] - 0s 297us/step - loss: 2461886.8525 - val_loss: 2206431.2052\n",
      "Epoch 1076/5000\n",
      "134/134 [==============================] - 0s 334us/step - loss: 2249653.2206 - val_loss: 2216326.2948\n",
      "Epoch 1077/5000\n",
      "134/134 [==============================] - 0s 275us/step - loss: 2447676.5830 - val_loss: 2258914.3358\n",
      "Epoch 1078/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 2567487.7220 - val_loss: 2188143.6866\n",
      "Epoch 1079/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 2256172.1431 - val_loss: 2183634.1754\n",
      "Epoch 1080/5000\n",
      "134/134 [==============================] - 0s 297us/step - loss: 2267532.6638 - val_loss: 2167487.5746\n",
      "Epoch 1081/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 2386850.3260 - val_loss: 2914939.4925\n",
      "Epoch 1082/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 2662905.0364 - val_loss: 2159400.9366\n",
      "Epoch 1083/5000\n",
      "134/134 [==============================] - 0s 293us/step - loss: 2241885.4145 - val_loss: 2325099.6866\n",
      "Epoch 1084/5000\n",
      "134/134 [==============================] - 0s 334us/step - loss: 2532110.2498 - val_loss: 2128322.4627\n",
      "Epoch 1085/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 2421307.6412 - val_loss: 2148529.3284\n",
      "Epoch 1086/5000\n",
      "134/134 [==============================] - 0s 284us/step - loss: 2401423.2969 - val_loss: 2126454.6119\n",
      "Epoch 1087/5000\n",
      "134/134 [==============================] - 0s 279us/step - loss: 2337588.7282 - val_loss: 2198457.5709\n",
      "Epoch 1088/5000\n",
      "134/134 [==============================] - 0s 283us/step - loss: 2268448.2940 - val_loss: 2462335.1642\n",
      "Epoch 1089/5000\n",
      "134/134 [==============================] - 0s 291us/step - loss: 2368869.1562 - val_loss: 2088287.8731\n",
      "Epoch 1090/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 2204186.2445 - val_loss: 2211323.8918\n",
      "Epoch 1091/5000\n",
      "134/134 [==============================] - 0s 338us/step - loss: 2414829.3378 - val_loss: 2117615.8060\n",
      "Epoch 1092/5000\n",
      "134/134 [==============================] - 0s 331us/step - loss: 2309982.5438 - val_loss: 2514739.3470\n",
      "Epoch 1093/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 2473055.1449 - val_loss: 2122703.1493\n",
      "Epoch 1094/5000\n",
      "134/134 [==============================] - 0s 336us/step - loss: 2352404.0239 - val_loss: 2083625.3769\n",
      "Epoch 1095/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 2388218.2105 - val_loss: 2228865.7127\n",
      "Epoch 1096/5000\n",
      "134/134 [==============================] - 0s 338us/step - loss: 2391903.6595 - val_loss: 2049634.2202\n",
      "Epoch 1097/5000\n",
      "134/134 [==============================] - 0s 350us/step - loss: 2237344.8381 - val_loss: 2435548.1269\n",
      "Epoch 1098/5000\n",
      "134/134 [==============================] - 0s 321us/step - loss: 2509377.6175 - val_loss: 2073401.5448\n",
      "Epoch 1099/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 2412809.3479 - val_loss: 2506756.0952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1100/5000\n",
      "134/134 [==============================] - 0s 331us/step - loss: 2240375.0262 - val_loss: 2078614.6978\n",
      "Epoch 1101/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 2229012.4173 - val_loss: 2189741.4216\n",
      "Epoch 1102/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 2095385.3819 - val_loss: 2272106.8769\n",
      "Epoch 1103/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 2102015.9944 - val_loss: 2060213.4254\n",
      "Epoch 1104/5000\n",
      "134/134 [==============================] - 0s 318us/step - loss: 2162229.3616 - val_loss: 2081955.8955\n",
      "Epoch 1105/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 2224479.5194 - val_loss: 2053542.7836\n",
      "Epoch 1106/5000\n",
      "134/134 [==============================] - 0s 317us/step - loss: 2158133.6384 - val_loss: 2022233.6007\n",
      "Epoch 1107/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 2166504.5341 - val_loss: 2250883.4664\n",
      "Epoch 1108/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 2354143.5905 - val_loss: 1997928.8657\n",
      "Epoch 1109/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 2269426.5141 - val_loss: 1990123.9590\n",
      "Epoch 1110/5000\n",
      "134/134 [==============================] - 0s 333us/step - loss: 2265063.3980 - val_loss: 2000071.9403\n",
      "Epoch 1111/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 2130635.5153 - val_loss: 2148893.9515\n",
      "Epoch 1112/5000\n",
      "134/134 [==============================] - 0s 321us/step - loss: 2057654.5977 - val_loss: 2042165.0410\n",
      "Epoch 1113/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 2136338.7750 - val_loss: 2451634.0336\n",
      "Epoch 1114/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 2300118.6879 - val_loss: 2013558.5336\n",
      "Epoch 1115/5000\n",
      "134/134 [==============================] - 0s 350us/step - loss: 2114349.8208 - val_loss: 2015927.4440\n",
      "Epoch 1116/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 2178263.5497 - val_loss: 1954678.3433\n",
      "Epoch 1117/5000\n",
      "134/134 [==============================] - 0s 341us/step - loss: 2097165.2569 - val_loss: 1985661.0672\n",
      "Epoch 1118/5000\n",
      "134/134 [==============================] - 0s 320us/step - loss: 2035148.5118 - val_loss: 2107259.9366\n",
      "Epoch 1119/5000\n",
      "134/134 [==============================] - 0s 298us/step - loss: 2200765.9310 - val_loss: 1957505.7015\n",
      "Epoch 1120/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 2270256.6684 - val_loss: 1940771.6418\n",
      "Epoch 1121/5000\n",
      "134/134 [==============================] - 0s 295us/step - loss: 2076067.8815 - val_loss: 2296768.0187\n",
      "Epoch 1122/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 2213677.3042 - val_loss: 1929818.4478\n",
      "Epoch 1123/5000\n",
      "134/134 [==============================] - 0s 338us/step - loss: 2159725.8374 - val_loss: 1936778.6791\n",
      "Epoch 1124/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 2128373.7076 - val_loss: 2058713.1157\n",
      "Epoch 1125/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 2149721.9781 - val_loss: 2350089.8843\n",
      "Epoch 1126/5000\n",
      "134/134 [==============================] - 0s 291us/step - loss: 2149764.7966 - val_loss: 2086610.7649\n",
      "Epoch 1127/5000\n",
      "134/134 [==============================] - 0s 295us/step - loss: 2075615.5765 - val_loss: 1938447.1716\n",
      "Epoch 1128/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 2271349.4811 - val_loss: 1908738.9664\n",
      "Epoch 1129/5000\n",
      "134/134 [==============================] - 0s 351us/step - loss: 2092056.6177 - val_loss: 1911281.2985\n",
      "Epoch 1130/5000\n",
      "134/134 [==============================] - 0s 285us/step - loss: 2000474.0429 - val_loss: 1894612.2799\n",
      "Epoch 1131/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 2028520.6283 - val_loss: 1999863.0448\n",
      "Epoch 1132/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 1953578.5949 - val_loss: 2104983.2836\n",
      "Epoch 1133/5000\n",
      "134/134 [==============================] - 0s 348us/step - loss: 2166409.8800 - val_loss: 2222705.2351\n",
      "Epoch 1134/5000\n",
      "134/134 [==============================] - 0s 356us/step - loss: 2083382.0479 - val_loss: 1901271.4291\n",
      "Epoch 1135/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 2073679.5193 - val_loss: 1918544.0821\n",
      "Epoch 1136/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 2091666.3864 - val_loss: 1854139.6605\n",
      "Epoch 1137/5000\n",
      "134/134 [==============================] - 0s 347us/step - loss: 2006881.3993 - val_loss: 1876654.9254\n",
      "Epoch 1138/5000\n",
      "134/134 [==============================] - 0s 351us/step - loss: 2120191.4485 - val_loss: 1966694.4105\n",
      "Epoch 1139/5000\n",
      "134/134 [==============================] - 0s 345us/step - loss: 2053956.4421 - val_loss: 1872275.7724\n",
      "Epoch 1140/5000\n",
      "134/134 [==============================] - 0s 362us/step - loss: 1877697.8844 - val_loss: 2017159.7015\n",
      "Epoch 1141/5000\n",
      "134/134 [==============================] - 0s 317us/step - loss: 1957077.0455 - val_loss: 2440293.9459\n",
      "Epoch 1142/5000\n",
      "134/134 [==============================] - 0s 311us/step - loss: 2073281.0732 - val_loss: 2202818.9888\n",
      "Epoch 1143/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 2075922.3546 - val_loss: 1920194.8545\n",
      "Epoch 1144/5000\n",
      "134/134 [==============================] - 0s 352us/step - loss: 1857449.9757 - val_loss: 1941873.1493\n",
      "Epoch 1145/5000\n",
      "134/134 [==============================] - 0s 344us/step - loss: 2041908.6320 - val_loss: 1837901.5896\n",
      "Epoch 1146/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 1982139.9184 - val_loss: 1850198.0261\n",
      "Epoch 1147/5000\n",
      "134/134 [==============================] - 0s 356us/step - loss: 2099777.8561 - val_loss: 1805007.5448\n",
      "Epoch 1148/5000\n",
      "134/134 [==============================] - 0s 329us/step - loss: 2109578.0011 - val_loss: 1831950.3470\n",
      "Epoch 1149/5000\n",
      "134/134 [==============================] - 0s 324us/step - loss: 1922074.1836 - val_loss: 2394600.9813\n",
      "Epoch 1150/5000\n",
      "134/134 [==============================] - 0s 330us/step - loss: 2093357.7996 - val_loss: 1924215.4478\n",
      "Epoch 1151/5000\n",
      "134/134 [==============================] - 0s 353us/step - loss: 1965355.2948 - val_loss: 2147686.0112\n",
      "Epoch 1152/5000\n",
      "134/134 [==============================] - 0s 335us/step - loss: 1963009.3085 - val_loss: 1810318.4067\n",
      "Epoch 1153/5000\n",
      "134/134 [==============================] - 0s 321us/step - loss: 2035178.7278 - val_loss: 1793413.0746\n",
      "Epoch 1154/5000\n",
      "134/134 [==============================] - 0s 324us/step - loss: 1850891.5380 - val_loss: 2206209.1082\n",
      "Epoch 1155/5000\n",
      "134/134 [==============================] - 0s 352us/step - loss: 2039347.2369 - val_loss: 1796625.6940\n",
      "Epoch 1156/5000\n",
      "134/134 [==============================] - 0s 360us/step - loss: 1975887.0854 - val_loss: 2181285.9813\n",
      "Epoch 1157/5000\n",
      "134/134 [==============================] - 0s 369us/step - loss: 2129065.7729 - val_loss: 2016941.3396\n",
      "Epoch 1158/5000\n",
      "134/134 [==============================] - 0s 344us/step - loss: 1887701.1665 - val_loss: 1797317.6530\n",
      "Epoch 1159/5000\n",
      "134/134 [==============================] - 0s 336us/step - loss: 1968751.7833 - val_loss: 1879793.3134\n",
      "Epoch 1160/5000\n",
      "134/134 [==============================] - 0s 329us/step - loss: 1919684.2698 - val_loss: 1802280.4813\n",
      "Epoch 1161/5000\n",
      "134/134 [==============================] - 0s 318us/step - loss: 1817612.6215 - val_loss: 1812857.7761\n",
      "Epoch 1162/5000\n",
      "134/134 [==============================] - 0s 315us/step - loss: 1949941.6851 - val_loss: 1757744.6679\n",
      "Epoch 1163/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 1907036.6305 - val_loss: 1747038.6978\n",
      "Epoch 1164/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 2040512.0131 - val_loss: 1754054.4776\n",
      "Epoch 1165/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 1970025.1405 - val_loss: 1741795.1530\n",
      "Epoch 1166/5000\n",
      "134/134 [==============================] - 0s 280us/step - loss: 2102778.4960 - val_loss: 1755323.5485\n",
      "Epoch 1167/5000\n",
      "134/134 [==============================] - 0s 318us/step - loss: 1945407.4209 - val_loss: 1840482.9590\n",
      "Epoch 1168/5000\n",
      "134/134 [==============================] - 0s 269us/step - loss: 1832473.5782 - val_loss: 1947906.6119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1169/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 2073221.8001 - val_loss: 1769527.0448\n",
      "Epoch 1170/5000\n",
      "134/134 [==============================] - 0s 315us/step - loss: 2016372.0615 - val_loss: 1737099.0933\n",
      "Epoch 1171/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 1776085.8543 - val_loss: 1772205.1194\n",
      "Epoch 1172/5000\n",
      "134/134 [==============================] - 0s 319us/step - loss: 1835683.5545 - val_loss: 1725151.0709\n",
      "Epoch 1173/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 2004921.8405 - val_loss: 2069801.2202\n",
      "Epoch 1174/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 1778222.3222 - val_loss: 1791701.3619\n",
      "Epoch 1175/5000\n",
      "134/134 [==============================] - 0s 336us/step - loss: 1905325.1642 - val_loss: 1802118.0299\n",
      "Epoch 1176/5000\n",
      "134/134 [==============================] - 0s 315us/step - loss: 1945275.8775 - val_loss: 1730021.0821\n",
      "Epoch 1177/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 1876321.3344 - val_loss: 1717778.1754\n",
      "Epoch 1178/5000\n",
      "134/134 [==============================] - 0s 315us/step - loss: 1864962.9304 - val_loss: 1773779.4627\n",
      "Epoch 1179/5000\n",
      "134/134 [==============================] - 0s 291us/step - loss: 1932580.7153 - val_loss: 1762295.5075\n",
      "Epoch 1180/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 1866956.0453 - val_loss: 1787878.4366\n",
      "Epoch 1181/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 1898730.9195 - val_loss: 1697463.3358\n",
      "Epoch 1182/5000\n",
      "134/134 [==============================] - 0s 294us/step - loss: 1756009.6730 - val_loss: 1835365.4664\n",
      "Epoch 1183/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 1924669.7792 - val_loss: 1698835.3358\n",
      "Epoch 1184/5000\n",
      "134/134 [==============================] - 0s 295us/step - loss: 1795352.3253 - val_loss: 2530286.2500\n",
      "Epoch 1185/5000\n",
      "134/134 [==============================] - 0s 325us/step - loss: 2099621.2912 - val_loss: 1723782.8470\n",
      "Epoch 1186/5000\n",
      "134/134 [==============================] - 0s 288us/step - loss: 1804022.2141 - val_loss: 1874248.9664\n",
      "Epoch 1187/5000\n",
      "134/134 [==============================] - 0s 300us/step - loss: 1754479.7292 - val_loss: 1885125.6381\n",
      "Epoch 1188/5000\n",
      "134/134 [==============================] - 0s 356us/step - loss: 1773404.5000 - val_loss: 1692186.6381\n",
      "Epoch 1189/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 1850570.9186 - val_loss: 1725609.0522\n",
      "Epoch 1190/5000\n",
      "134/134 [==============================] - 0s 341us/step - loss: 1714437.9459 - val_loss: 1700065.6045\n",
      "Epoch 1191/5000\n",
      "134/134 [==============================] - 0s 318us/step - loss: 1825340.6722 - val_loss: 1701032.6455\n",
      "Epoch 1192/5000\n",
      "134/134 [==============================] - 0s 360us/step - loss: 1981369.5254 - val_loss: 1667707.8993\n",
      "Epoch 1193/5000\n",
      "134/134 [==============================] - 0s 330us/step - loss: 1836434.6364 - val_loss: 1744373.5224\n",
      "Epoch 1194/5000\n",
      "134/134 [==============================] - 0s 449us/step - loss: 1817389.5280 - val_loss: 2535691.0634\n",
      "Epoch 1195/5000\n",
      "134/134 [==============================] - 0s 382us/step - loss: 2079693.4799 - val_loss: 1666541.8881\n",
      "Epoch 1196/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 1739926.2677 - val_loss: 1650208.7052\n",
      "Epoch 1197/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 1882766.2487 - val_loss: 1661730.9515\n",
      "Epoch 1198/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 1809813.7164 - val_loss: 1661649.1903\n",
      "Epoch 1199/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 1861102.2463 - val_loss: 1707334.2313\n",
      "Epoch 1200/5000\n",
      "134/134 [==============================] - 0s 278us/step - loss: 1889272.0840 - val_loss: 1653283.8433\n",
      "Epoch 1201/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 1857766.7172 - val_loss: 1767892.9179\n",
      "Epoch 1202/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 1896415.7384 - val_loss: 1676564.5299\n",
      "Epoch 1203/5000\n",
      "134/134 [==============================] - 0s 285us/step - loss: 1835470.9104 - val_loss: 2789645.6007\n",
      "Epoch 1204/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 1922442.8400 - val_loss: 1747902.6119\n",
      "Epoch 1205/5000\n",
      "134/134 [==============================] - 0s 299us/step - loss: 1801073.9559 - val_loss: 2187298.3806\n",
      "Epoch 1206/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 1941710.4391 - val_loss: 1656228.8955\n",
      "Epoch 1207/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 1820874.4708 - val_loss: 1682894.4291\n",
      "Epoch 1208/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 1782900.6396 - val_loss: 1633823.5896\n",
      "Epoch 1209/5000\n",
      "134/134 [==============================] - 0s 295us/step - loss: 1784010.4012 - val_loss: 1620059.9366\n",
      "Epoch 1210/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 1827470.9772 - val_loss: 1738689.2649\n",
      "Epoch 1211/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 1835392.7040 - val_loss: 1637471.2612\n",
      "Epoch 1212/5000\n",
      "134/134 [==============================] - 0s 299us/step - loss: 1649681.1136 - val_loss: 1619994.8582\n",
      "Epoch 1213/5000\n",
      "134/134 [==============================] - 0s 334us/step - loss: 1745880.3850 - val_loss: 1607700.5933\n",
      "Epoch 1214/5000\n",
      "134/134 [==============================] - 0s 341us/step - loss: 1664785.8386 - val_loss: 1945158.1716\n",
      "Epoch 1215/5000\n",
      "134/134 [==============================] - 0s 336us/step - loss: 1892206.3535 - val_loss: 1972041.9590\n",
      "Epoch 1216/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 1916496.9784 - val_loss: 1750359.2649\n",
      "Epoch 1217/5000\n",
      "134/134 [==============================] - 0s 355us/step - loss: 1768294.6785 - val_loss: 1661469.2425\n",
      "Epoch 1218/5000\n",
      "134/134 [==============================] - 0s 347us/step - loss: 1702320.6493 - val_loss: 1593229.1418\n",
      "Epoch 1219/5000\n",
      "134/134 [==============================] - 0s 319us/step - loss: 1669100.4868 - val_loss: 1667817.3097\n",
      "Epoch 1220/5000\n",
      "134/134 [==============================] - 0s 342us/step - loss: 1667451.9995 - val_loss: 1898347.6828\n",
      "Epoch 1221/5000\n",
      "134/134 [==============================] - 0s 352us/step - loss: 1887627.7697 - val_loss: 1712918.6007\n",
      "Epoch 1222/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 1854889.2034 - val_loss: 1633273.7164\n",
      "Epoch 1223/5000\n",
      "134/134 [==============================] - 0s 362us/step - loss: 1732002.9739 - val_loss: 1750083.7351\n",
      "Epoch 1224/5000\n",
      "134/134 [==============================] - 0s 362us/step - loss: 1809873.3165 - val_loss: 1762636.6866\n",
      "Epoch 1225/5000\n",
      "134/134 [==============================] - 0s 347us/step - loss: 1834242.8803 - val_loss: 1625917.4963\n",
      "Epoch 1226/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 1764896.9545 - val_loss: 1613339.8284\n",
      "Epoch 1227/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 1865427.8689 - val_loss: 1592501.0597\n",
      "Epoch 1228/5000\n",
      "134/134 [==============================] - 0s 266us/step - loss: 1754870.1123 - val_loss: 1778512.4254\n",
      "Epoch 1229/5000\n",
      "134/134 [==============================] - 0s 320us/step - loss: 1944711.5647 - val_loss: 1585992.6828\n",
      "Epoch 1230/5000\n",
      "134/134 [==============================] - 0s 315us/step - loss: 1625224.4436 - val_loss: 1571509.1007\n",
      "Epoch 1231/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 1727557.1925 - val_loss: 1573604.9216\n",
      "Epoch 1232/5000\n",
      "134/134 [==============================] - 0s 297us/step - loss: 1692851.7388 - val_loss: 1583217.2873\n",
      "Epoch 1233/5000\n",
      "134/134 [==============================] - 0s 283us/step - loss: 1807733.8638 - val_loss: 1566102.5373\n",
      "Epoch 1234/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 1781075.7365 - val_loss: 1976082.9739\n",
      "Epoch 1235/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 1879168.4212 - val_loss: 1563379.4851\n",
      "Epoch 1236/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 1664358.9871 - val_loss: 1590586.4440\n",
      "Epoch 1237/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 1699922.4465 - val_loss: 1619283.0485\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1238/5000\n",
      "134/134 [==============================] - 0s 315us/step - loss: 1732662.5417 - val_loss: 1560642.0634\n",
      "Epoch 1239/5000\n",
      "134/134 [==============================] - 0s 351us/step - loss: 1792325.4613 - val_loss: 1555706.8022\n",
      "Epoch 1240/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 1596034.3323 - val_loss: 1557152.2687\n",
      "Epoch 1241/5000\n",
      "134/134 [==============================] - 0s 329us/step - loss: 1733429.4923 - val_loss: 1561304.0672\n",
      "Epoch 1242/5000\n",
      "134/134 [==============================] - 0s 329us/step - loss: 1750779.5856 - val_loss: 1574130.1418\n",
      "Epoch 1243/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 1729554.6584 - val_loss: 1554695.2425\n",
      "Epoch 1244/5000\n",
      "134/134 [==============================] - 0s 282us/step - loss: 1674102.1623 - val_loss: 1638110.1119\n",
      "Epoch 1245/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 1638039.3358 - val_loss: 1616771.4776\n",
      "Epoch 1246/5000\n",
      "134/134 [==============================] - 0s 321us/step - loss: 1637225.6565 - val_loss: 1776350.2425\n",
      "Epoch 1247/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 1730025.1466 - val_loss: 1863939.2239\n",
      "Epoch 1248/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 1867464.1306 - val_loss: 1594857.3694\n",
      "Epoch 1249/5000\n",
      "134/134 [==============================] - 0s 254us/step - loss: 1670408.7692 - val_loss: 1629058.2687\n",
      "Epoch 1250/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 1772332.4528 - val_loss: 1535118.9030\n",
      "Epoch 1251/5000\n",
      "134/134 [==============================] - 0s 321us/step - loss: 1564971.7742 - val_loss: 1526303.1157\n",
      "Epoch 1252/5000\n",
      "134/134 [==============================] - 0s 290us/step - loss: 1721906.9818 - val_loss: 1518280.1642\n",
      "Epoch 1253/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 1695951.3844 - val_loss: 1540387.6605\n",
      "Epoch 1254/5000\n",
      "134/134 [==============================] - 0s 289us/step - loss: 1685099.3384 - val_loss: 1594518.0075\n",
      "Epoch 1255/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 1706300.3396 - val_loss: 1651801.6381\n",
      "Epoch 1256/5000\n",
      "134/134 [==============================] - 0s 329us/step - loss: 1700179.2957 - val_loss: 2243776.9478\n",
      "Epoch 1257/5000\n",
      "134/134 [==============================] - 0s 293us/step - loss: 1773809.6670 - val_loss: 1643119.8172\n",
      "Epoch 1258/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 1759164.5816 - val_loss: 1539074.0896\n",
      "Epoch 1259/5000\n",
      "134/134 [==============================] - 0s 294us/step - loss: 1667325.4030 - val_loss: 1509167.7500\n",
      "Epoch 1260/5000\n",
      "134/134 [==============================] - 0s 304us/step - loss: 1656686.7476 - val_loss: 1713351.1119\n",
      "Epoch 1261/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 1685482.5083 - val_loss: 2059746.3134\n",
      "Epoch 1262/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 1611978.6138 - val_loss: 2354605.4851\n",
      "Epoch 1263/5000\n",
      "134/134 [==============================] - 0s 323us/step - loss: 1796146.8762 - val_loss: 2142445.5037\n",
      "Epoch 1264/5000\n",
      "134/134 [==============================] - 0s 337us/step - loss: 1879851.4437 - val_loss: 1511185.0560\n",
      "Epoch 1265/5000\n",
      "134/134 [==============================] - 0s 304us/step - loss: 1625837.3381 - val_loss: 1520767.6530\n",
      "Epoch 1266/5000\n",
      "134/134 [==============================] - 0s 284us/step - loss: 1589062.3722 - val_loss: 1992800.4552\n",
      "Epoch 1267/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 1807071.0649 - val_loss: 1832963.3172\n",
      "Epoch 1268/5000\n",
      "134/134 [==============================] - 0s 293us/step - loss: 1937155.4445 - val_loss: 1554351.8582\n",
      "Epoch 1269/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 1636127.5549 - val_loss: 1502892.8433\n",
      "Epoch 1270/5000\n",
      "134/134 [==============================] - 0s 292us/step - loss: 1653671.4696 - val_loss: 1551795.4590\n",
      "Epoch 1271/5000\n",
      "134/134 [==============================] - 0s 283us/step - loss: 1538000.4328 - val_loss: 1530556.8172\n",
      "Epoch 1272/5000\n",
      "134/134 [==============================] - 0s 291us/step - loss: 1631131.0289 - val_loss: 1501727.7649\n",
      "Epoch 1273/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 1616160.1355 - val_loss: 1530544.3843\n",
      "Epoch 1274/5000\n",
      "134/134 [==============================] - 0s 361us/step - loss: 1632738.3239 - val_loss: 1492310.3507\n",
      "Epoch 1275/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 1551028.8690 - val_loss: 1498676.6530\n",
      "Epoch 1276/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 1696866.3753 - val_loss: 1563690.3694\n",
      "Epoch 1277/5000\n",
      "134/134 [==============================] - 0s 279us/step - loss: 1636425.9197 - val_loss: 1534265.7799\n",
      "Epoch 1278/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 1578808.2085 - val_loss: 1569690.5634\n",
      "Epoch 1279/5000\n",
      "134/134 [==============================] - 0s 298us/step - loss: 1659595.3800 - val_loss: 1583715.0746\n",
      "Epoch 1280/5000\n",
      "134/134 [==============================] - 0s 298us/step - loss: 1545065.8321 - val_loss: 1521587.9813\n",
      "Epoch 1281/5000\n",
      "134/134 [==============================] - 0s 290us/step - loss: 1561921.7632 - val_loss: 1468852.7127\n",
      "Epoch 1282/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 1770275.3692 - val_loss: 1474674.4664\n",
      "Epoch 1283/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 1505543.0911 - val_loss: 1619535.0522\n",
      "Epoch 1284/5000\n",
      "134/134 [==============================] - 0s 294us/step - loss: 1679746.9357 - val_loss: 1490410.2612\n",
      "Epoch 1285/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 1541369.0140 - val_loss: 1784186.1679\n",
      "Epoch 1286/5000\n",
      "134/134 [==============================] - 0s 321us/step - loss: 1525900.4669 - val_loss: 1667292.0560\n",
      "Epoch 1287/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 1634424.5472 - val_loss: 1456395.4664\n",
      "Epoch 1288/5000\n",
      "134/134 [==============================] - 0s 350us/step - loss: 1601795.4428 - val_loss: 1482857.5373\n",
      "Epoch 1289/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 1645233.7744 - val_loss: 1667339.9702\n",
      "Epoch 1290/5000\n",
      "134/134 [==============================] - 0s 353us/step - loss: 1649511.3510 - val_loss: 1455599.6903\n",
      "Epoch 1291/5000\n",
      "134/134 [==============================] - 0s 350us/step - loss: 1578085.4814 - val_loss: 1505009.1269\n",
      "Epoch 1292/5000\n",
      "134/134 [==============================] - 0s 335us/step - loss: 1619620.7853 - val_loss: 1469929.4328\n",
      "Epoch 1293/5000\n",
      "134/134 [==============================] - 0s 338us/step - loss: 1588824.3091 - val_loss: 1440859.3545\n",
      "Epoch 1294/5000\n",
      "134/134 [==============================] - 0s 345us/step - loss: 1503772.3446 - val_loss: 1513927.2612\n",
      "Epoch 1295/5000\n",
      "134/134 [==============================] - 0s 333us/step - loss: 1556411.6253 - val_loss: 1556345.0821\n",
      "Epoch 1296/5000\n",
      "134/134 [==============================] - 0s 330us/step - loss: 1568359.0276 - val_loss: 1432087.5075\n",
      "Epoch 1297/5000\n",
      "134/134 [==============================] - 0s 317us/step - loss: 1531567.5326 - val_loss: 2353544.0709\n",
      "Epoch 1298/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 2014463.0595 - val_loss: 1564348.4702\n",
      "Epoch 1299/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 1600274.4882 - val_loss: 1538703.9067\n",
      "Epoch 1300/5000\n",
      "134/134 [==============================] - 0s 321us/step - loss: 1487539.1557 - val_loss: 1424241.8284\n",
      "Epoch 1301/5000\n",
      "134/134 [==============================] - 0s 354us/step - loss: 1561703.8983 - val_loss: 1563004.4291\n",
      "Epoch 1302/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 1598118.7568 - val_loss: 1433095.6157\n",
      "Epoch 1303/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 1481148.9729 - val_loss: 1651701.7052\n",
      "Epoch 1304/5000\n",
      "134/134 [==============================] - 0s 287us/step - loss: 1478986.2233 - val_loss: 1443191.2687\n",
      "Epoch 1305/5000\n",
      "134/134 [==============================] - 0s 299us/step - loss: 1625072.5410 - val_loss: 1418549.4366\n",
      "Epoch 1306/5000\n",
      "134/134 [==============================] - 0s 324us/step - loss: 1578698.6360 - val_loss: 1399710.4216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1307/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 1540262.9660 - val_loss: 1647326.2836\n",
      "Epoch 1308/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 1620705.5878 - val_loss: 1474926.8918\n",
      "Epoch 1309/5000\n",
      "134/134 [==============================] - 0s 285us/step - loss: 1622709.1863 - val_loss: 1503332.6828\n",
      "Epoch 1310/5000\n",
      "134/134 [==============================] - 0s 311us/step - loss: 1497312.3652 - val_loss: 1481691.0261\n",
      "Epoch 1311/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 1554235.8204 - val_loss: 1428527.8172\n",
      "Epoch 1312/5000\n",
      "134/134 [==============================] - 0s 339us/step - loss: 1618913.1785 - val_loss: 1410510.9888\n",
      "Epoch 1313/5000\n",
      "134/134 [==============================] - 0s 355us/step - loss: 1631444.2615 - val_loss: 1461012.8955\n",
      "Epoch 1314/5000\n",
      "134/134 [==============================] - 0s 332us/step - loss: 1708811.9778 - val_loss: 1423827.5485\n",
      "Epoch 1315/5000\n",
      "134/134 [==============================] - 0s 367us/step - loss: 1585993.8583 - val_loss: 1378468.4515\n",
      "Epoch 1316/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 1706637.1649 - val_loss: 1454088.5858\n",
      "Epoch 1317/5000\n",
      "134/134 [==============================] - 0s 329us/step - loss: 1570056.9375 - val_loss: 2324772.7799\n",
      "Epoch 1318/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 1604617.2714 - val_loss: 1497751.0410\n",
      "Epoch 1319/5000\n",
      "134/134 [==============================] - 0s 330us/step - loss: 1473957.8094 - val_loss: 1452477.3097\n",
      "Epoch 1320/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 1432414.3122 - val_loss: 1514200.2127\n",
      "Epoch 1321/5000\n",
      "134/134 [==============================] - 0s 342us/step - loss: 1583883.4027 - val_loss: 1380301.1679\n",
      "Epoch 1322/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 1564693.9288 - val_loss: 1364900.2052\n",
      "Epoch 1323/5000\n",
      "134/134 [==============================] - 0s 299us/step - loss: 1492584.5522 - val_loss: 2183131.0821\n",
      "Epoch 1324/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 1778170.3614 - val_loss: 1553025.4067\n",
      "Epoch 1325/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 1567589.2648 - val_loss: 1419768.2276\n",
      "Epoch 1326/5000\n",
      "134/134 [==============================] - 0s 301us/step - loss: 1460422.7500 - val_loss: 1354919.0112\n",
      "Epoch 1327/5000\n",
      "134/134 [==============================] - 0s 311us/step - loss: 1527204.0504 - val_loss: 1360560.4851\n",
      "Epoch 1328/5000\n",
      "134/134 [==============================] - 0s 348us/step - loss: 1397390.9566 - val_loss: 1385410.7425\n",
      "Epoch 1329/5000\n",
      "134/134 [==============================] - 0s 369us/step - loss: 1373919.4476 - val_loss: 1435886.5149\n",
      "Epoch 1330/5000\n",
      "134/134 [==============================] - 0s 298us/step - loss: 1503527.8750 - val_loss: 1370958.2910\n",
      "Epoch 1331/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 1477662.0185 - val_loss: 1544889.3582\n",
      "Epoch 1332/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 1526816.8762 - val_loss: 1527233.9366\n",
      "Epoch 1333/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 1557895.1795 - val_loss: 1355250.9142\n",
      "Epoch 1334/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 1399510.2991 - val_loss: 1574287.8246\n",
      "Epoch 1335/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 1518052.1020 - val_loss: 1583154.5485\n",
      "Epoch 1336/5000\n",
      "134/134 [==============================] - 0s 293us/step - loss: 1456067.2845 - val_loss: 1354379.1306\n",
      "Epoch 1337/5000\n",
      "134/134 [==============================] - 0s 299us/step - loss: 1602397.7836 - val_loss: 1354996.4142\n",
      "Epoch 1338/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 1567619.2291 - val_loss: 1335644.5746\n",
      "Epoch 1339/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 1450145.1693 - val_loss: 1336383.6530\n",
      "Epoch 1340/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 1456335.9289 - val_loss: 1551691.5112\n",
      "Epoch 1341/5000\n",
      "134/134 [==============================] - 0s 293us/step - loss: 1387804.8814 - val_loss: 1361924.6493\n",
      "Epoch 1342/5000\n",
      "134/134 [==============================] - 0s 338us/step - loss: 1356929.5476 - val_loss: 1320895.0933\n",
      "Epoch 1343/5000\n",
      "134/134 [==============================] - 0s 284us/step - loss: 1364251.4597 - val_loss: 1320302.7313\n",
      "Epoch 1344/5000\n",
      "134/134 [==============================] - 0s 284us/step - loss: 1388708.9466 - val_loss: 1685360.9440\n",
      "Epoch 1345/5000\n",
      "134/134 [==============================] - 0s 330us/step - loss: 1606383.1059 - val_loss: 1340439.3022\n",
      "Epoch 1346/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 1422912.7966 - val_loss: 1380240.1343\n",
      "Epoch 1347/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 1630540.6407 - val_loss: 1357711.3918\n",
      "Epoch 1348/5000\n",
      "134/134 [==============================] - 0s 341us/step - loss: 1348282.7922 - val_loss: 1342353.3582\n",
      "Epoch 1349/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 1500741.0625 - val_loss: 1315294.4590\n",
      "Epoch 1350/5000\n",
      "134/134 [==============================] - 0s 325us/step - loss: 1425004.8696 - val_loss: 1357959.9552\n",
      "Epoch 1351/5000\n",
      "134/134 [==============================] - 0s 320us/step - loss: 1387956.9368 - val_loss: 2152998.6679\n",
      "Epoch 1352/5000\n",
      "134/134 [==============================] - 0s 276us/step - loss: 1784257.7975 - val_loss: 1366087.5597\n",
      "Epoch 1353/5000\n",
      "134/134 [==============================] - 0s 338us/step - loss: 1455285.7807 - val_loss: 1335790.7276\n",
      "Epoch 1354/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 1510624.0583 - val_loss: 1528311.4440\n",
      "Epoch 1355/5000\n",
      "134/134 [==============================] - 0s 311us/step - loss: 1572100.6974 - val_loss: 1339982.5373\n",
      "Epoch 1356/5000\n",
      "134/134 [==============================] - 0s 337us/step - loss: 1404630.8787 - val_loss: 1330440.4328\n",
      "Epoch 1357/5000\n",
      "134/134 [==============================] - 0s 295us/step - loss: 1507042.8333 - val_loss: 1322882.5000\n",
      "Epoch 1358/5000\n",
      "134/134 [==============================] - 0s 325us/step - loss: 1332263.2889 - val_loss: 1309896.2799\n",
      "Epoch 1359/5000\n",
      "134/134 [==============================] - 0s 274us/step - loss: 1403988.8153 - val_loss: 1934598.0709\n",
      "Epoch 1360/5000\n",
      "134/134 [==============================] - 0s 291us/step - loss: 1530315.1309 - val_loss: 1292218.5299\n",
      "Epoch 1361/5000\n",
      "134/134 [==============================] - 0s 291us/step - loss: 1376266.2159 - val_loss: 1423266.3881\n",
      "Epoch 1362/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 1446856.7663 - val_loss: 1965990.8470\n",
      "Epoch 1363/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 1415626.6068 - val_loss: 1539312.3619\n",
      "Epoch 1364/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 1527334.2599 - val_loss: 1327939.1866\n",
      "Epoch 1365/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 1407064.2594 - val_loss: 1865574.9590\n",
      "Epoch 1366/5000\n",
      "134/134 [==============================] - 0s 289us/step - loss: 1582016.7155 - val_loss: 1315099.7164\n",
      "Epoch 1367/5000\n",
      "134/134 [==============================] - 0s 292us/step - loss: 1388643.5989 - val_loss: 1881339.1772\n",
      "Epoch 1368/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 1591243.5668 - val_loss: 1382660.8470\n",
      "Epoch 1369/5000\n",
      "134/134 [==============================] - 0s 311us/step - loss: 1338503.0665 - val_loss: 1283790.6828\n",
      "Epoch 1370/5000\n",
      "134/134 [==============================] - 0s 417us/step - loss: 1354048.9294 - val_loss: 1297717.8284\n",
      "Epoch 1371/5000\n",
      "134/134 [==============================] - 0s 360us/step - loss: 1415035.0459 - val_loss: 1269324.1045\n",
      "Epoch 1372/5000\n",
      "134/134 [==============================] - 0s 320us/step - loss: 1325723.0091 - val_loss: 1855106.8302\n",
      "Epoch 1373/5000\n",
      "134/134 [==============================] - 0s 334us/step - loss: 1378027.6301 - val_loss: 1777980.0485\n",
      "Epoch 1374/5000\n",
      "134/134 [==============================] - 0s 374us/step - loss: 1511731.8085 - val_loss: 1342451.2388\n",
      "Epoch 1375/5000\n",
      "134/134 [==============================] - 0s 317us/step - loss: 1366997.8348 - val_loss: 1279567.8060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1376/5000\n",
      "134/134 [==============================] - 0s 364us/step - loss: 1411493.7108 - val_loss: 1257831.0299\n",
      "Epoch 1377/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 1385530.4368 - val_loss: 1408544.2948\n",
      "Epoch 1378/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 1353619.5669 - val_loss: 1289059.6007\n",
      "Epoch 1379/5000\n",
      "134/134 [==============================] - 0s 294us/step - loss: 1345060.6215 - val_loss: 1864330.3172\n",
      "Epoch 1380/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 1507852.9819 - val_loss: 1260533.0037\n",
      "Epoch 1381/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 1372410.2466 - val_loss: 1245716.4851\n",
      "Epoch 1382/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 1378068.3946 - val_loss: 1246390.4179\n",
      "Epoch 1383/5000\n",
      "134/134 [==============================] - 0s 311us/step - loss: 1414545.9183 - val_loss: 1318308.7500\n",
      "Epoch 1384/5000\n",
      "134/134 [==============================] - 0s 317us/step - loss: 1262317.9118 - val_loss: 1326099.5373\n",
      "Epoch 1385/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 1282354.5305 - val_loss: 1340081.7276\n",
      "Epoch 1386/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 1452628.6886 - val_loss: 1234116.1418\n",
      "Epoch 1387/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 1373780.6480 - val_loss: 1255258.7873\n",
      "Epoch 1388/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 1317265.6843 - val_loss: 1447140.0224\n",
      "Epoch 1389/5000\n",
      "134/134 [==============================] - 0s 288us/step - loss: 1400108.7404 - val_loss: 1275567.5410\n",
      "Epoch 1390/5000\n",
      "134/134 [==============================] - 0s 323us/step - loss: 1380706.4431 - val_loss: 1253940.0933\n",
      "Epoch 1391/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 1524080.1157 - val_loss: 1228109.3769\n",
      "Epoch 1392/5000\n",
      "134/134 [==============================] - 0s 343us/step - loss: 1302068.7112 - val_loss: 1342962.7239\n",
      "Epoch 1393/5000\n",
      "134/134 [==============================] - 0s 346us/step - loss: 1355318.5303 - val_loss: 1890981.3172\n",
      "Epoch 1394/5000\n",
      "134/134 [==============================] - 0s 341us/step - loss: 1557150.2959 - val_loss: 1274014.2799\n",
      "Epoch 1395/5000\n",
      "134/134 [==============================] - 0s 321us/step - loss: 1352260.8456 - val_loss: 1332924.8134\n",
      "Epoch 1396/5000\n",
      "134/134 [==============================] - 0s 346us/step - loss: 1384786.4478 - val_loss: 1324620.4813\n",
      "Epoch 1397/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 1345377.9841 - val_loss: 1295658.2388\n",
      "Epoch 1398/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 1328766.1306 - val_loss: 1225689.8918\n",
      "Epoch 1399/5000\n",
      "134/134 [==============================] - 0s 301us/step - loss: 1338908.2786 - val_loss: 1293166.0261\n",
      "Epoch 1400/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 1411017.5333 - val_loss: 1224471.7910\n",
      "Epoch 1401/5000\n",
      "134/134 [==============================] - 0s 319us/step - loss: 1385251.3287 - val_loss: 1232683.7351\n",
      "Epoch 1402/5000\n",
      "134/134 [==============================] - 0s 294us/step - loss: 1309285.1820 - val_loss: 1381771.3582\n",
      "Epoch 1403/5000\n",
      "134/134 [==============================] - 0s 297us/step - loss: 1295948.7637 - val_loss: 1239379.1642\n",
      "Epoch 1404/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 1370590.3568 - val_loss: 1260091.0410\n",
      "Epoch 1405/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 1386560.4892 - val_loss: 1278578.1828\n",
      "Epoch 1406/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 1544534.4940 - val_loss: 1385847.2388\n",
      "Epoch 1407/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 1327245.0234 - val_loss: 1376745.2948\n",
      "Epoch 1408/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 1489567.6525 - val_loss: 1221451.4888\n",
      "Epoch 1409/5000\n",
      "134/134 [==============================] - 0s 293us/step - loss: 1270909.2912 - val_loss: 1283242.9627\n",
      "Epoch 1410/5000\n",
      "134/134 [==============================] - 0s 348us/step - loss: 1234351.8777 - val_loss: 1317179.4515\n",
      "Epoch 1411/5000\n",
      "134/134 [==============================] - 0s 297us/step - loss: 1419273.7508 - val_loss: 1228618.4776\n",
      "Epoch 1412/5000\n",
      "134/134 [==============================] - 0s 300us/step - loss: 1260167.8872 - val_loss: 1182148.2127\n",
      "Epoch 1413/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 1388010.7217 - val_loss: 1219407.9515\n",
      "Epoch 1414/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 1335166.1542 - val_loss: 1188315.0896\n",
      "Epoch 1415/5000\n",
      "134/134 [==============================] - 0s 320us/step - loss: 1396332.6203 - val_loss: 1194900.6119\n",
      "Epoch 1416/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 1230690.6821 - val_loss: 1227759.3097\n",
      "Epoch 1417/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 1336172.3731 - val_loss: 1206528.3918\n",
      "Epoch 1418/5000\n",
      "134/134 [==============================] - 0s 338us/step - loss: 1273802.8891 - val_loss: 1401155.6045\n",
      "Epoch 1419/5000\n",
      "134/134 [==============================] - 0s 300us/step - loss: 1272202.5805 - val_loss: 1244456.5410\n",
      "Epoch 1420/5000\n",
      "134/134 [==============================] - 0s 300us/step - loss: 1296961.0240 - val_loss: 1240769.8246\n",
      "Epoch 1421/5000\n",
      "134/134 [==============================] - 0s 368us/step - loss: 1407136.8769 - val_loss: 1219136.4963\n",
      "Epoch 1422/5000\n",
      "134/134 [==============================] - 0s 364us/step - loss: 1332856.9230 - val_loss: 1309745.1231\n",
      "Epoch 1423/5000\n",
      "134/134 [==============================] - 0s 362us/step - loss: 1234721.9418 - val_loss: 1309363.6381\n",
      "Epoch 1424/5000\n",
      "134/134 [==============================] - 0s 405us/step - loss: 1296954.5496 - val_loss: 2090163.8769\n",
      "Epoch 1425/5000\n",
      "134/134 [==============================] - 0s 369us/step - loss: 1430102.3807 - val_loss: 1254232.7052\n",
      "Epoch 1426/5000\n",
      "134/134 [==============================] - 0s 363us/step - loss: 1402237.8545 - val_loss: 1218787.6082\n",
      "Epoch 1427/5000\n",
      "134/134 [==============================] - 0s 264us/step - loss: 1253553.2799 - val_loss: 1196559.0410\n",
      "Epoch 1428/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 1317122.3421 - val_loss: 1189456.1530\n",
      "Epoch 1429/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 1225962.0184 - val_loss: 1148124.5112\n",
      "Epoch 1430/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 1285130.5349 - val_loss: 1160137.6828\n",
      "Epoch 1431/5000\n",
      "134/134 [==============================] - 0s 315us/step - loss: 1390110.6025 - val_loss: 1280172.4328\n",
      "Epoch 1432/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 1205815.0318 - val_loss: 1869143.3993\n",
      "Epoch 1433/5000\n",
      "134/134 [==============================] - 0s 323us/step - loss: 1391574.3470 - val_loss: 1238276.3769\n",
      "Epoch 1434/5000\n",
      "134/134 [==============================] - 0s 311us/step - loss: 1349840.6997 - val_loss: 1161843.2127\n",
      "Epoch 1435/5000\n",
      "134/134 [==============================] - 0s 323us/step - loss: 1206363.6609 - val_loss: 1143485.3097\n",
      "Epoch 1436/5000\n",
      "134/134 [==============================] - 0s 286us/step - loss: 1341301.3127 - val_loss: 1147707.6306\n",
      "Epoch 1437/5000\n",
      "134/134 [==============================] - 0s 319us/step - loss: 1230625.8195 - val_loss: 1631233.6231\n",
      "Epoch 1438/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 1510882.2221 - val_loss: 1144513.3321\n",
      "Epoch 1439/5000\n",
      "134/134 [==============================] - 0s 321us/step - loss: 1196695.4501 - val_loss: 1192993.7799\n",
      "Epoch 1440/5000\n",
      "134/134 [==============================] - 0s 282us/step - loss: 1280403.3612 - val_loss: 1253438.0858\n",
      "Epoch 1441/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 1282964.5865 - val_loss: 1226038.6343\n",
      "Epoch 1442/5000\n",
      "134/134 [==============================] - 0s 334us/step - loss: 1179824.1150 - val_loss: 1124554.7276\n",
      "Epoch 1443/5000\n",
      "134/134 [==============================] - 0s 298us/step - loss: 1251130.7637 - val_loss: 1121459.5448\n",
      "Epoch 1444/5000\n",
      "134/134 [==============================] - 0s 294us/step - loss: 1202214.1075 - val_loss: 1582669.5933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1445/5000\n",
      "134/134 [==============================] - 0s 287us/step - loss: 1376356.8236 - val_loss: 1139449.9851\n",
      "Epoch 1446/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 1215224.6325 - val_loss: 1110859.8172\n",
      "Epoch 1447/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 1133672.0891 - val_loss: 1130705.6306\n",
      "Epoch 1448/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 1225654.5845 - val_loss: 1190294.7090\n",
      "Epoch 1449/5000\n",
      "134/134 [==============================] - 0s 323us/step - loss: 1150249.4795 - val_loss: 1108588.6007\n",
      "Epoch 1450/5000\n",
      "134/134 [==============================] - 0s 324us/step - loss: 1225382.4811 - val_loss: 1105371.4179\n",
      "Epoch 1451/5000\n",
      "134/134 [==============================] - 0s 323us/step - loss: 1247371.4801 - val_loss: 1123140.2239\n",
      "Epoch 1452/5000\n",
      "134/134 [==============================] - 0s 321us/step - loss: 1211654.0323 - val_loss: 1441306.3358\n",
      "Epoch 1453/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 1312801.3398 - val_loss: 1692388.0560\n",
      "Epoch 1454/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 1345452.9562 - val_loss: 1225758.8731\n",
      "Epoch 1455/5000\n",
      "134/134 [==============================] - 0s 263us/step - loss: 1310705.7218 - val_loss: 1107917.4067\n",
      "Epoch 1456/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 1222277.9599 - val_loss: 1102715.0933\n",
      "Epoch 1457/5000\n",
      "134/134 [==============================] - 0s 297us/step - loss: 1130399.2831 - val_loss: 1095940.3060\n",
      "Epoch 1458/5000\n",
      "134/134 [==============================] - 0s 293us/step - loss: 1260967.5686 - val_loss: 1120255.4851\n",
      "Epoch 1459/5000\n",
      "134/134 [==============================] - 0s 332us/step - loss: 1214700.5396 - val_loss: 1134240.3657\n",
      "Epoch 1460/5000\n",
      "134/134 [==============================] - 0s 319us/step - loss: 1302307.5989 - val_loss: 1121523.1493\n",
      "Epoch 1461/5000\n",
      "134/134 [==============================] - 0s 298us/step - loss: 1209177.0696 - val_loss: 1239354.0970\n",
      "Epoch 1462/5000\n",
      "134/134 [==============================] - 0s 329us/step - loss: 1373082.6048 - val_loss: 1096811.8881\n",
      "Epoch 1463/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 1217871.5798 - val_loss: 1103104.5858\n",
      "Epoch 1464/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 1268319.9572 - val_loss: 1215004.6530\n",
      "Epoch 1465/5000\n",
      "134/134 [==============================] - 0s 294us/step - loss: 1319191.9080 - val_loss: 1162149.8172\n",
      "Epoch 1466/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 1352319.4671 - val_loss: 1088888.9925\n",
      "Epoch 1467/5000\n",
      "134/134 [==============================] - 0s 320us/step - loss: 1214751.9684 - val_loss: 1147599.0187\n",
      "Epoch 1468/5000\n",
      "134/134 [==============================] - 0s 352us/step - loss: 1235153.0547 - val_loss: 1125694.0896\n",
      "Epoch 1469/5000\n",
      "134/134 [==============================] - 0s 345us/step - loss: 1272955.6687 - val_loss: 1124713.9664\n",
      "Epoch 1470/5000\n",
      "134/134 [==============================] - 0s 347us/step - loss: 1242516.7463 - val_loss: 1116542.8134\n",
      "Epoch 1471/5000\n",
      "134/134 [==============================] - 0s 345us/step - loss: 1120850.8270 - val_loss: 1177845.8619\n",
      "Epoch 1472/5000\n",
      "134/134 [==============================] - 0s 390us/step - loss: 1177619.0485 - val_loss: 1108618.4851\n",
      "Epoch 1473/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 1147667.6744 - val_loss: 1410528.8358\n",
      "Epoch 1474/5000\n",
      "134/134 [==============================] - 0s 344us/step - loss: 1315525.4007 - val_loss: 1086809.0522\n",
      "Epoch 1475/5000\n",
      "134/134 [==============================] - 0s 334us/step - loss: 1209630.0300 - val_loss: 1089072.0373\n",
      "Epoch 1476/5000\n",
      "134/134 [==============================] - 0s 358us/step - loss: 1148276.5312 - val_loss: 1386043.3172\n",
      "Epoch 1477/5000\n",
      "134/134 [==============================] - 0s 323us/step - loss: 1441421.9755 - val_loss: 1803700.7761\n",
      "Epoch 1478/5000\n",
      "134/134 [==============================] - 0s 304us/step - loss: 1314900.0560 - val_loss: 1073200.8993\n",
      "Epoch 1479/5000\n",
      "134/134 [==============================] - 0s 323us/step - loss: 1150015.4357 - val_loss: 1152649.1231\n",
      "Epoch 1480/5000\n",
      "134/134 [==============================] - 0s 311us/step - loss: 1179390.6973 - val_loss: 1181037.0075\n",
      "Epoch 1481/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 1189278.7928 - val_loss: 1126553.5485\n",
      "Epoch 1482/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 1163000.8017 - val_loss: 1192533.0037\n",
      "Epoch 1483/5000\n",
      "134/134 [==============================] - 0s 293us/step - loss: 1161846.6133 - val_loss: 1097731.8060\n",
      "Epoch 1484/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 1182996.6102 - val_loss: 1074218.1343\n",
      "Epoch 1485/5000\n",
      "134/134 [==============================] - 0s 297us/step - loss: 1097329.4627 - val_loss: 1666292.7948\n",
      "Epoch 1486/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 1395816.6046 - val_loss: 1192393.9776\n",
      "Epoch 1487/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 1182445.1310 - val_loss: 1096425.2202\n",
      "Epoch 1488/5000\n",
      "134/134 [==============================] - 0s 331us/step - loss: 1057251.5207 - val_loss: 1204007.2836\n",
      "Epoch 1489/5000\n",
      "134/134 [==============================] - 0s 299us/step - loss: 1184556.8987 - val_loss: 1551901.2164\n",
      "Epoch 1490/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 1144814.7372 - val_loss: 1218050.5075\n",
      "Epoch 1491/5000\n",
      "134/134 [==============================] - 0s 331us/step - loss: 1187641.9806 - val_loss: 1392477.8060\n",
      "Epoch 1492/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 1241607.8678 - val_loss: 1041727.3993\n",
      "Epoch 1493/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 1102438.7670 - val_loss: 1078891.9813\n",
      "Epoch 1494/5000\n",
      "134/134 [==============================] - 0s 299us/step - loss: 1092178.8209 - val_loss: 1041958.9590\n",
      "Epoch 1495/5000\n",
      "134/134 [==============================] - 0s 331us/step - loss: 1091362.1002 - val_loss: 1144481.3545\n",
      "Epoch 1496/5000\n",
      "134/134 [==============================] - 0s 325us/step - loss: 1132037.4672 - val_loss: 1021277.3134\n",
      "Epoch 1497/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 1131291.8662 - val_loss: 1047521.4067\n",
      "Epoch 1498/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 1119966.7441 - val_loss: 1356836.6082\n",
      "Epoch 1499/5000\n",
      "134/134 [==============================] - 0s 318us/step - loss: 1133575.0918 - val_loss: 1019826.2500\n",
      "Epoch 1500/5000\n",
      "134/134 [==============================] - 0s 356us/step - loss: 1079338.0278 - val_loss: 1017387.3769\n",
      "Epoch 1501/5000\n",
      "134/134 [==============================] - 0s 317us/step - loss: 1164240.8937 - val_loss: 1029381.9739\n",
      "Epoch 1502/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 1149333.6629 - val_loss: 1288968.3022\n",
      "Epoch 1503/5000\n",
      "134/134 [==============================] - 0s 351us/step - loss: 1122987.3424 - val_loss: 1014055.9515\n",
      "Epoch 1504/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 1099414.6586 - val_loss: 1605516.7127\n",
      "Epoch 1505/5000\n",
      "134/134 [==============================] - 0s 336us/step - loss: 1218642.2066 - val_loss: 1034247.2687\n",
      "Epoch 1506/5000\n",
      "134/134 [==============================] - 0s 297us/step - loss: 1050338.8452 - val_loss: 1050354.7351\n",
      "Epoch 1507/5000\n",
      "134/134 [==============================] - 0s 301us/step - loss: 1106319.0448 - val_loss: 1094666.2164\n",
      "Epoch 1508/5000\n",
      "134/134 [==============================] - 0s 263us/step - loss: 1137032.9554 - val_loss: 1029624.4105\n",
      "Epoch 1509/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 1094656.4422 - val_loss: 1065044.4478\n",
      "Epoch 1510/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 1051196.0819 - val_loss: 1119413.1940\n",
      "Epoch 1511/5000\n",
      "134/134 [==============================] - 0s 300us/step - loss: 1109545.3174 - val_loss: 1052792.6082\n",
      "Epoch 1512/5000\n",
      "134/134 [==============================] - 0s 266us/step - loss: 1116379.4551 - val_loss: 1027771.7463\n",
      "Epoch 1513/5000\n",
      "134/134 [==============================] - 0s 318us/step - loss: 1099395.4255 - val_loss: 1103549.7388\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1514/5000\n",
      "134/134 [==============================] - 0s 344us/step - loss: 1179525.9837 - val_loss: 1019468.0560\n",
      "Epoch 1515/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 1055603.7114 - val_loss: 986890.1194\n",
      "Epoch 1516/5000\n",
      "134/134 [==============================] - 0s 297us/step - loss: 1075945.0463 - val_loss: 1122096.3321\n",
      "Epoch 1517/5000\n",
      "134/134 [==============================] - 0s 323us/step - loss: 1024858.9644 - val_loss: 997568.8358\n",
      "Epoch 1518/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 1120559.4815 - val_loss: 1013888.9440\n",
      "Epoch 1519/5000\n",
      "134/134 [==============================] - 0s 317us/step - loss: 1034239.3308 - val_loss: 1043412.9291\n",
      "Epoch 1520/5000\n",
      "134/134 [==============================] - 0s 321us/step - loss: 1089324.6257 - val_loss: 1194485.5373\n",
      "Epoch 1521/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 1258233.4162 - val_loss: 1401122.3060\n",
      "Epoch 1522/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 1117836.2702 - val_loss: 1022691.3060\n",
      "Epoch 1523/5000\n",
      "134/134 [==============================] - 0s 323us/step - loss: 1105375.8309 - val_loss: 1000184.4813\n",
      "Epoch 1524/5000\n",
      "134/134 [==============================] - 0s 293us/step - loss: 1094403.1945 - val_loss: 1648901.2799\n",
      "Epoch 1525/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 1228315.7556 - val_loss: 972488.0522\n",
      "Epoch 1526/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 1007830.6144 - val_loss: 1543396.8955\n",
      "Epoch 1527/5000\n",
      "134/134 [==============================] - 0s 300us/step - loss: 1252035.7884 - val_loss: 983438.1530\n",
      "Epoch 1528/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 1050887.1549 - val_loss: 999138.8769\n",
      "Epoch 1529/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 1016542.0561 - val_loss: 961570.8993\n",
      "Epoch 1530/5000\n",
      "134/134 [==============================] - 0s 317us/step - loss: 975160.2327 - val_loss: 960169.4478\n",
      "Epoch 1531/5000\n",
      "134/134 [==============================] - 0s 297us/step - loss: 1092105.4548 - val_loss: 1290313.0224\n",
      "Epoch 1532/5000\n",
      "134/134 [==============================] - 0s 324us/step - loss: 1063913.6519 - val_loss: 981796.4440\n",
      "Epoch 1533/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 1062299.9729 - val_loss: 961773.2425\n",
      "Epoch 1534/5000\n",
      "134/134 [==============================] - 0s 299us/step - loss: 1014080.9365 - val_loss: 1037009.3843\n",
      "Epoch 1535/5000\n",
      "134/134 [==============================] - 0s 319us/step - loss: 1122333.2825 - val_loss: 959113.1754\n",
      "Epoch 1536/5000\n",
      "134/134 [==============================] - 0s 291us/step - loss: 1105303.5704 - val_loss: 983393.5187\n",
      "Epoch 1537/5000\n",
      "134/134 [==============================] - 0s 315us/step - loss: 1028720.2093 - val_loss: 963511.9254\n",
      "Epoch 1538/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 995425.7085 - val_loss: 1029956.6418\n",
      "Epoch 1539/5000\n",
      "134/134 [==============================] - 0s 301us/step - loss: 1098289.8057 - val_loss: 971360.4664\n",
      "Epoch 1540/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 1096393.4499 - val_loss: 956345.1231\n",
      "Epoch 1541/5000\n",
      "134/134 [==============================] - 0s 342us/step - loss: 1019186.8901 - val_loss: 1007467.0709\n",
      "Epoch 1542/5000\n",
      "134/134 [==============================] - 0s 304us/step - loss: 1125611.9130 - val_loss: 1007943.5149\n",
      "Epoch 1543/5000\n",
      "134/134 [==============================] - 0s 329us/step - loss: 1087339.0622 - val_loss: 951327.3806\n",
      "Epoch 1544/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 1045238.5584 - val_loss: 939869.8545\n",
      "Epoch 1545/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 1081301.9534 - val_loss: 1104275.5485\n",
      "Epoch 1546/5000\n",
      "134/134 [==============================] - 0s 319us/step - loss: 1140976.5970 - val_loss: 983013.0634\n",
      "Epoch 1547/5000\n",
      "134/134 [==============================] - 0s 294us/step - loss: 1063793.1753 - val_loss: 1185602.4702\n",
      "Epoch 1548/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 1012730.9606 - val_loss: 957787.8843\n",
      "Epoch 1549/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 1053199.5037 - val_loss: 989034.6418\n",
      "Epoch 1550/5000\n",
      "134/134 [==============================] - 0s 286us/step - loss: 1116719.3055 - val_loss: 976355.0224\n",
      "Epoch 1551/5000\n",
      "134/134 [==============================] - 0s 332us/step - loss: 1148764.3618 - val_loss: 1018279.5000\n",
      "Epoch 1552/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 1062477.2767 - val_loss: 1361603.1530\n",
      "Epoch 1553/5000\n",
      "134/134 [==============================] - 0s 317us/step - loss: 1088778.3512 - val_loss: 1175351.6381\n",
      "Epoch 1554/5000\n",
      "134/134 [==============================] - 0s 278us/step - loss: 1152125.9394 - val_loss: 1002486.2910\n",
      "Epoch 1555/5000\n",
      "134/134 [==============================] - 0s 338us/step - loss: 1055724.7452 - val_loss: 1155548.6679\n",
      "Epoch 1556/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 951513.2717 - val_loss: 1120960.6754\n",
      "Epoch 1557/5000\n",
      "134/134 [==============================] - 0s 323us/step - loss: 1194472.3890 - val_loss: 1240829.3769\n",
      "Epoch 1558/5000\n",
      "134/134 [==============================] - 0s 300us/step - loss: 1097745.0647 - val_loss: 952519.4851\n",
      "Epoch 1559/5000\n",
      "134/134 [==============================] - 0s 323us/step - loss: 1024019.5373 - val_loss: 936285.4403\n",
      "Epoch 1560/5000\n",
      "134/134 [==============================] - 0s 286us/step - loss: 998851.7024 - val_loss: 988127.1828\n",
      "Epoch 1561/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 1065858.5035 - val_loss: 915041.5746\n",
      "Epoch 1562/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 999094.3780 - val_loss: 916956.3881\n",
      "Epoch 1563/5000\n",
      "134/134 [==============================] - 0s 288us/step - loss: 1085950.8465 - val_loss: 917670.2799\n",
      "Epoch 1564/5000\n",
      "134/134 [==============================] - 0s 265us/step - loss: 1011573.8866 - val_loss: 1032914.7948\n",
      "Epoch 1565/5000\n",
      "134/134 [==============================] - 0s 321us/step - loss: 1054324.0238 - val_loss: 1112850.9664\n",
      "Epoch 1566/5000\n",
      "134/134 [==============================] - 0s 359us/step - loss: 1066234.1600 - val_loss: 1378305.1530\n",
      "Epoch 1567/5000\n",
      "134/134 [==============================] - 0s 299us/step - loss: 1090054.3988 - val_loss: 1013411.8172\n",
      "Epoch 1568/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 1062222.2051 - val_loss: 1035608.8097\n",
      "Epoch 1569/5000\n",
      "134/134 [==============================] - 0s 324us/step - loss: 967295.6634 - val_loss: 932545.0672\n",
      "Epoch 1570/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 1052734.7740 - val_loss: 932666.8769\n",
      "Epoch 1571/5000\n",
      "134/134 [==============================] - 0s 295us/step - loss: 935174.1716 - val_loss: 897760.2239\n",
      "Epoch 1572/5000\n",
      "134/134 [==============================] - 0s 315us/step - loss: 960690.2337 - val_loss: 1616092.9590\n",
      "Epoch 1573/5000\n",
      "134/134 [==============================] - 0s 334us/step - loss: 1147542.6878 - val_loss: 975885.1269\n",
      "Epoch 1574/5000\n",
      "134/134 [==============================] - 0s 283us/step - loss: 1041621.1496 - val_loss: 898507.8134\n",
      "Epoch 1575/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 903720.5243 - val_loss: 891902.9963\n",
      "Epoch 1576/5000\n",
      "134/134 [==============================] - 0s 323us/step - loss: 992713.3864 - val_loss: 965369.6231\n",
      "Epoch 1577/5000\n",
      "134/134 [==============================] - 0s 350us/step - loss: 998745.1975 - val_loss: 979606.9179\n",
      "Epoch 1578/5000\n",
      "134/134 [==============================] - 0s 377us/step - loss: 1044208.4947 - val_loss: 1327371.9067\n",
      "Epoch 1579/5000\n",
      "134/134 [==============================] - 0s 318us/step - loss: 1094619.2812 - val_loss: 887715.3134\n",
      "Epoch 1580/5000\n",
      "134/134 [==============================] - 0s 287us/step - loss: 972105.7267 - val_loss: 891734.5709\n",
      "Epoch 1581/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 983455.9894 - val_loss: 918835.6791\n",
      "Epoch 1582/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 984559.2458 - val_loss: 1215435.8545\n",
      "Epoch 1583/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 382us/step - loss: 1006750.3254 - val_loss: 977897.9963\n",
      "Epoch 1584/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 953214.2082 - val_loss: 1018071.4254\n",
      "Epoch 1585/5000\n",
      "134/134 [==============================] - 0s 288us/step - loss: 994631.6784 - val_loss: 888303.3321\n",
      "Epoch 1586/5000\n",
      "134/134 [==============================] - 0s 269us/step - loss: 981881.0265 - val_loss: 895075.9590\n",
      "Epoch 1587/5000\n",
      "134/134 [==============================] - 0s 291us/step - loss: 1050145.6894 - val_loss: 1058205.6007\n",
      "Epoch 1588/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 994490.9492 - val_loss: 1017913.0373\n",
      "Epoch 1589/5000\n",
      "134/134 [==============================] - 0s 282us/step - loss: 982530.1909 - val_loss: 870087.0336\n",
      "Epoch 1590/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 959689.2273 - val_loss: 932049.0336\n",
      "Epoch 1591/5000\n",
      "134/134 [==============================] - 0s 284us/step - loss: 915206.4256 - val_loss: 942978.7015\n",
      "Epoch 1592/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 1097277.9770 - val_loss: 889144.1045\n",
      "Epoch 1593/5000\n",
      "134/134 [==============================] - 0s 319us/step - loss: 924646.8910 - val_loss: 936290.3619\n",
      "Epoch 1594/5000\n",
      "134/134 [==============================] - 0s 272us/step - loss: 930983.4426 - val_loss: 893665.6940\n",
      "Epoch 1595/5000\n",
      "134/134 [==============================] - 0s 343us/step - loss: 893370.8876 - val_loss: 906246.5672\n",
      "Epoch 1596/5000\n",
      "134/134 [==============================] - 0s 329us/step - loss: 950291.8279 - val_loss: 1515613.7724\n",
      "Epoch 1597/5000\n",
      "134/134 [==============================] - 0s 315us/step - loss: 1026518.8281 - val_loss: 936967.7202\n",
      "Epoch 1598/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 978996.8806 - val_loss: 1479522.4478\n",
      "Epoch 1599/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 1144553.7947 - val_loss: 890478.0485\n",
      "Epoch 1600/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 937853.9075 - val_loss: 915332.5560\n",
      "Epoch 1601/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 878057.7808 - val_loss: 944409.3321\n",
      "Epoch 1602/5000\n",
      "134/134 [==============================] - 0s 337us/step - loss: 899882.7077 - val_loss: 892753.6157\n",
      "Epoch 1603/5000\n",
      "134/134 [==============================] - 0s 304us/step - loss: 974045.3580 - val_loss: 866416.1194\n",
      "Epoch 1604/5000\n",
      "134/134 [==============================] - 0s 279us/step - loss: 934031.2448 - val_loss: 896471.6045\n",
      "Epoch 1605/5000\n",
      "134/134 [==============================] - 0s 281us/step - loss: 985263.8668 - val_loss: 916128.4366\n",
      "Epoch 1606/5000\n",
      "134/134 [==============================] - 0s 284us/step - loss: 925786.7787 - val_loss: 976379.5522\n",
      "Epoch 1607/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 943045.6241 - val_loss: 1023654.8172\n",
      "Epoch 1608/5000\n",
      "134/134 [==============================] - 0s 325us/step - loss: 886340.5814 - val_loss: 1124235.6605\n",
      "Epoch 1609/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 920678.3018 - val_loss: 899746.0037\n",
      "Epoch 1610/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 1038662.0174 - val_loss: 847714.2425\n",
      "Epoch 1611/5000\n",
      "134/134 [==============================] - 0s 286us/step - loss: 868764.0707 - val_loss: 851152.2388\n",
      "Epoch 1612/5000\n",
      "134/134 [==============================] - 0s 300us/step - loss: 984568.3865 - val_loss: 918463.3918\n",
      "Epoch 1613/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 965167.4553 - val_loss: 1028446.5149\n",
      "Epoch 1614/5000\n",
      "134/134 [==============================] - 0s 329us/step - loss: 1122878.2320 - val_loss: 973497.2910\n",
      "Epoch 1615/5000\n",
      "134/134 [==============================] - 0s 341us/step - loss: 921773.1489 - val_loss: 951322.7575\n",
      "Epoch 1616/5000\n",
      "134/134 [==============================] - 0s 332us/step - loss: 1153374.2374 - val_loss: 888247.7239\n",
      "Epoch 1617/5000\n",
      "134/134 [==============================] - 0s 335us/step - loss: 895111.1751 - val_loss: 1091207.0858\n",
      "Epoch 1618/5000\n",
      "134/134 [==============================] - 0s 338us/step - loss: 994969.8057 - val_loss: 1492119.1231\n",
      "Epoch 1619/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 1091645.8356 - val_loss: 844530.7127\n",
      "Epoch 1620/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 944878.7498 - val_loss: 1383899.6194\n",
      "Epoch 1621/5000\n",
      "134/134 [==============================] - 0s 280us/step - loss: 985649.3700 - val_loss: 921606.7463\n",
      "Epoch 1622/5000\n",
      "134/134 [==============================] - 0s 318us/step - loss: 915867.4299 - val_loss: 866543.0616\n",
      "Epoch 1623/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 1021034.6713 - val_loss: 881788.8377\n",
      "Epoch 1624/5000\n",
      "134/134 [==============================] - 0s 319us/step - loss: 914737.2518 - val_loss: 951091.1418\n",
      "Epoch 1625/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 914418.9310 - val_loss: 1394118.3433\n",
      "Epoch 1626/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 1026363.0465 - val_loss: 843114.7836\n",
      "Epoch 1627/5000\n",
      "134/134 [==============================] - 0s 323us/step - loss: 892143.8933 - val_loss: 831494.1884\n",
      "Epoch 1628/5000\n",
      "134/134 [==============================] - 0s 297us/step - loss: 905408.0312 - val_loss: 906785.1269\n",
      "Epoch 1629/5000\n",
      "134/134 [==============================] - 0s 297us/step - loss: 926417.4972 - val_loss: 841628.4590\n",
      "Epoch 1630/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 956813.4740 - val_loss: 843773.4254\n",
      "Epoch 1631/5000\n",
      "134/134 [==============================] - 0s 301us/step - loss: 878901.1535 - val_loss: 863801.7910\n",
      "Epoch 1632/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 967312.5742 - val_loss: 870482.1231\n",
      "Epoch 1633/5000\n",
      "134/134 [==============================] - 0s 315us/step - loss: 912923.9528 - val_loss: 963098.2164\n",
      "Epoch 1634/5000\n",
      "134/134 [==============================] - 0s 300us/step - loss: 878875.7919 - val_loss: 983214.9664\n",
      "Epoch 1635/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 860743.6813 - val_loss: 821405.1157\n",
      "Epoch 1636/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 862893.7218 - val_loss: 1005062.3134\n",
      "Epoch 1637/5000\n",
      "134/134 [==============================] - 0s 280us/step - loss: 968177.4659 - val_loss: 854381.8507\n",
      "Epoch 1638/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 1055584.2581 - val_loss: 840572.9179\n",
      "Epoch 1639/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 973662.8183 - val_loss: 918714.6978\n",
      "Epoch 1640/5000\n",
      "134/134 [==============================] - 0s 317us/step - loss: 983220.5844 - val_loss: 875572.1231\n",
      "Epoch 1641/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 926160.8701 - val_loss: 966131.0821\n",
      "Epoch 1642/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 892433.0281 - val_loss: 1475009.4515\n",
      "Epoch 1643/5000\n",
      "134/134 [==============================] - 0s 339us/step - loss: 1117864.4875 - val_loss: 855663.6007\n",
      "Epoch 1644/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 950105.4354 - val_loss: 838142.4813\n",
      "Epoch 1645/5000\n",
      "134/134 [==============================] - 0s 268us/step - loss: 906942.9729 - val_loss: 837014.8284\n",
      "Epoch 1646/5000\n",
      "134/134 [==============================] - 0s 368us/step - loss: 916384.1733 - val_loss: 956239.2500\n",
      "Epoch 1647/5000\n",
      "134/134 [==============================] - 0s 394us/step - loss: 871406.8355 - val_loss: 819700.0373\n",
      "Epoch 1648/5000\n",
      "134/134 [==============================] - 0s 376us/step - loss: 875218.6819 - val_loss: 1180543.6231\n",
      "Epoch 1649/5000\n",
      "134/134 [==============================] - 0s 370us/step - loss: 961498.9260 - val_loss: 822722.2612\n",
      "Epoch 1650/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 825615.4677 - val_loss: 796175.5373\n",
      "Epoch 1651/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 921127.5958 - val_loss: 802540.0933\n",
      "Epoch 1652/5000\n",
      "134/134 [==============================] - 0s 343us/step - loss: 832434.7090 - val_loss: 814441.8041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1653/5000\n",
      "134/134 [==============================] - 0s 360us/step - loss: 889673.8885 - val_loss: 876104.1231\n",
      "Epoch 1654/5000\n",
      "134/134 [==============================] - 0s 336us/step - loss: 956823.7201 - val_loss: 1152228.4963\n",
      "Epoch 1655/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 996574.9286 - val_loss: 826735.7071\n",
      "Epoch 1656/5000\n",
      "134/134 [==============================] - 0s 324us/step - loss: 909168.1111 - val_loss: 801299.6269\n",
      "Epoch 1657/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 828206.1292 - val_loss: 991638.3022\n",
      "Epoch 1658/5000\n",
      "134/134 [==============================] - 0s 295us/step - loss: 976139.4602 - val_loss: 835280.3806\n",
      "Epoch 1659/5000\n",
      "134/134 [==============================] - 0s 311us/step - loss: 977028.5945 - val_loss: 836572.1119\n",
      "Epoch 1660/5000\n",
      "134/134 [==============================] - 0s 321us/step - loss: 927853.0794 - val_loss: 861367.9478\n",
      "Epoch 1661/5000\n",
      "134/134 [==============================] - 0s 311us/step - loss: 907725.3358 - val_loss: 873467.2276\n",
      "Epoch 1662/5000\n",
      "134/134 [==============================] - 0s 281us/step - loss: 950691.9293 - val_loss: 896516.4888\n",
      "Epoch 1663/5000\n",
      "134/134 [==============================] - 0s 298us/step - loss: 957522.8526 - val_loss: 1392613.1194\n",
      "Epoch 1664/5000\n",
      "134/134 [==============================] - 0s 292us/step - loss: 1033847.2876 - val_loss: 805425.0970\n",
      "Epoch 1665/5000\n",
      "134/134 [==============================] - 0s 301us/step - loss: 868104.0554 - val_loss: 808130.4272\n",
      "Epoch 1666/5000\n",
      "134/134 [==============================] - 0s 301us/step - loss: 854866.7252 - val_loss: 789019.2724\n",
      "Epoch 1667/5000\n",
      "134/134 [==============================] - 0s 329us/step - loss: 801002.4935 - val_loss: 786327.2519\n",
      "Epoch 1668/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 944470.7472 - val_loss: 794491.8862\n",
      "Epoch 1669/5000\n",
      "134/134 [==============================] - 0s 291us/step - loss: 807616.2882 - val_loss: 769512.4030\n",
      "Epoch 1670/5000\n",
      "134/134 [==============================] - 0s 304us/step - loss: 816344.9509 - val_loss: 1295817.1418\n",
      "Epoch 1671/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 940597.1421 - val_loss: 794521.7687\n",
      "Epoch 1672/5000\n",
      "134/134 [==============================] - 0s 284us/step - loss: 872049.3310 - val_loss: 816928.5541\n",
      "Epoch 1673/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 799941.9558 - val_loss: 772937.7052\n",
      "Epoch 1674/5000\n",
      "134/134 [==============================] - 0s 347us/step - loss: 846437.9938 - val_loss: 768938.2537\n",
      "Epoch 1675/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 830082.5662 - val_loss: 761014.2239\n",
      "Epoch 1676/5000\n",
      "134/134 [==============================] - 0s 315us/step - loss: 785398.3125 - val_loss: 794437.2257\n",
      "Epoch 1677/5000\n",
      "134/134 [==============================] - 0s 311us/step - loss: 855984.1859 - val_loss: 907691.7463\n",
      "Epoch 1678/5000\n",
      "134/134 [==============================] - 0s 319us/step - loss: 810321.4860 - val_loss: 851838.5578\n",
      "Epoch 1679/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 955571.9926 - val_loss: 779733.9515\n",
      "Epoch 1680/5000\n",
      "134/134 [==============================] - 0s 304us/step - loss: 996869.9889 - val_loss: 812801.4347\n",
      "Epoch 1681/5000\n",
      "134/134 [==============================] - 0s 294us/step - loss: 850705.1485 - val_loss: 762214.6922\n",
      "Epoch 1682/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 807532.4496 - val_loss: 1523755.3993\n",
      "Epoch 1683/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 1015919.9625 - val_loss: 762124.5168\n",
      "Epoch 1684/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 858550.0466 - val_loss: 875803.0112\n",
      "Epoch 1685/5000\n",
      "134/134 [==============================] - 0s 339us/step - loss: 871134.8556 - val_loss: 760092.9571\n",
      "Epoch 1686/5000\n",
      "134/134 [==============================] - 0s 342us/step - loss: 772294.9511 - val_loss: 792379.7873\n",
      "Epoch 1687/5000\n",
      "134/134 [==============================] - 0s 315us/step - loss: 763305.0258 - val_loss: 863516.5672\n",
      "Epoch 1688/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 1046870.4053 - val_loss: 763562.0914\n",
      "Epoch 1689/5000\n",
      "134/134 [==============================] - 0s 311us/step - loss: 827409.6149 - val_loss: 794026.9590\n",
      "Epoch 1690/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 872020.3132 - val_loss: 818037.3022\n",
      "Epoch 1691/5000\n",
      "134/134 [==============================] - 0s 315us/step - loss: 799234.2168 - val_loss: 754724.6978\n",
      "Epoch 1692/5000\n",
      "134/134 [==============================] - 0s 301us/step - loss: 804601.3475 - val_loss: 864735.5616\n",
      "Epoch 1693/5000\n",
      "134/134 [==============================] - 0s 300us/step - loss: 859616.4572 - val_loss: 1290943.7537\n",
      "Epoch 1694/5000\n",
      "134/134 [==============================] - 0s 297us/step - loss: 902067.6530 - val_loss: 749469.5746\n",
      "Epoch 1695/5000\n",
      "134/134 [==============================] - 0s 317us/step - loss: 846761.1095 - val_loss: 762698.3190\n",
      "Epoch 1696/5000\n",
      "134/134 [==============================] - 0s 329us/step - loss: 841111.5054 - val_loss: 852098.3731\n",
      "Epoch 1697/5000\n",
      "134/134 [==============================] - 0s 275us/step - loss: 840186.5634 - val_loss: 847170.6082\n",
      "Epoch 1698/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 797655.1301 - val_loss: 767460.2910\n",
      "Epoch 1699/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 776116.9787 - val_loss: 1163738.4888\n",
      "Epoch 1700/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 1043022.5450 - val_loss: 888703.2108\n",
      "Epoch 1701/5000\n",
      "134/134 [==============================] - 0s 319us/step - loss: 905805.3574 - val_loss: 795613.1772\n",
      "Epoch 1702/5000\n",
      "134/134 [==============================] - 0s 332us/step - loss: 871288.9704 - val_loss: 915039.6194\n",
      "Epoch 1703/5000\n",
      "134/134 [==============================] - 0s 329us/step - loss: 896506.9055 - val_loss: 1009350.2612\n",
      "Epoch 1704/5000\n",
      "134/134 [==============================] - 0s 333us/step - loss: 1039945.9855 - val_loss: 750017.7444\n",
      "Epoch 1705/5000\n",
      "134/134 [==============================] - 0s 323us/step - loss: 787930.6615 - val_loss: 962199.7724\n",
      "Epoch 1706/5000\n",
      "134/134 [==============================] - 0s 287us/step - loss: 927389.7698 - val_loss: 833706.2351\n",
      "Epoch 1707/5000\n",
      "134/134 [==============================] - 0s 334us/step - loss: 888302.9089 - val_loss: 829500.3078\n",
      "Epoch 1708/5000\n",
      "134/134 [==============================] - 0s 332us/step - loss: 844249.3918 - val_loss: 798348.7873\n",
      "Epoch 1709/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 813423.9415 - val_loss: 774358.8284\n",
      "Epoch 1710/5000\n",
      "134/134 [==============================] - 0s 350us/step - loss: 871943.0954 - val_loss: 1576704.2761\n",
      "Epoch 1711/5000\n",
      "134/134 [==============================] - 0s 321us/step - loss: 1064745.5189 - val_loss: 726405.3358\n",
      "Epoch 1712/5000\n",
      "134/134 [==============================] - 0s 321us/step - loss: 769360.4310 - val_loss: 743109.2034\n",
      "Epoch 1713/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 762888.9617 - val_loss: 746134.6922\n",
      "Epoch 1714/5000\n",
      "134/134 [==============================] - 0s 297us/step - loss: 737294.3906 - val_loss: 723011.6119\n",
      "Epoch 1715/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 776904.7623 - val_loss: 740356.0075\n",
      "Epoch 1716/5000\n",
      "134/134 [==============================] - 0s 330us/step - loss: 795557.9354 - val_loss: 805320.0970\n",
      "Epoch 1717/5000\n",
      "134/134 [==============================] - 0s 347us/step - loss: 774538.8422 - val_loss: 854999.5560\n",
      "Epoch 1718/5000\n",
      "134/134 [==============================] - 0s 276us/step - loss: 826149.3647 - val_loss: 740984.9440\n",
      "Epoch 1719/5000\n",
      "134/134 [==============================] - 0s 320us/step - loss: 821144.3870 - val_loss: 776789.2873\n",
      "Epoch 1720/5000\n",
      "134/134 [==============================] - 0s 263us/step - loss: 855460.5703 - val_loss: 790614.7575\n",
      "Epoch 1721/5000\n",
      "134/134 [==============================] - 0s 281us/step - loss: 812024.7770 - val_loss: 851298.9291\n",
      "Epoch 1722/5000\n",
      "134/134 [==============================] - 0s 269us/step - loss: 781774.2998 - val_loss: 1364499.1866\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1723/5000\n",
      "134/134 [==============================] - 0s 285us/step - loss: 1011674.5035 - val_loss: 737840.5802\n",
      "Epoch 1724/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 771984.8108 - val_loss: 1103880.0261\n",
      "Epoch 1725/5000\n",
      "134/134 [==============================] - 0s 298us/step - loss: 951256.0783 - val_loss: 719531.9860\n",
      "Epoch 1726/5000\n",
      "134/134 [==============================] - 0s 294us/step - loss: 726836.5128 - val_loss: 709590.1586\n",
      "Epoch 1727/5000\n",
      "134/134 [==============================] - 0s 292us/step - loss: 784580.9066 - val_loss: 715432.0392\n",
      "Epoch 1728/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 784231.9795 - val_loss: 748469.9011\n",
      "Epoch 1729/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 792297.4074 - val_loss: 731486.1996\n",
      "Epoch 1730/5000\n",
      "134/134 [==============================] - 0s 301us/step - loss: 744434.5630 - val_loss: 877642.4552\n",
      "Epoch 1731/5000\n",
      "134/134 [==============================] - 0s 320us/step - loss: 866373.7966 - val_loss: 722674.9944\n",
      "Epoch 1732/5000\n",
      "134/134 [==============================] - 0s 293us/step - loss: 820994.7589 - val_loss: 770289.3414\n",
      "Epoch 1733/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 825414.0880 - val_loss: 766274.2817\n",
      "Epoch 1734/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 733683.7383 - val_loss: 1204914.1306\n",
      "Epoch 1735/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 808729.5360 - val_loss: 1194326.5634\n",
      "Epoch 1736/5000\n",
      "134/134 [==============================] - 0s 330us/step - loss: 954408.7201 - val_loss: 704614.6418\n",
      "Epoch 1737/5000\n",
      "134/134 [==============================] - 0s 301us/step - loss: 773439.5789 - val_loss: 723675.8843\n",
      "Epoch 1738/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 775201.7885 - val_loss: 831043.8489\n",
      "Epoch 1739/5000\n",
      "134/134 [==============================] - 0s 285us/step - loss: 894357.4563 - val_loss: 753621.2500\n",
      "Epoch 1740/5000\n",
      "134/134 [==============================] - 0s 290us/step - loss: 796325.7803 - val_loss: 796919.4552\n",
      "Epoch 1741/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 880250.9503 - val_loss: 717475.2985\n",
      "Epoch 1742/5000\n",
      "134/134 [==============================] - 0s 278us/step - loss: 793651.9304 - val_loss: 719207.3694\n",
      "Epoch 1743/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 812191.0716 - val_loss: 743182.1269\n",
      "Epoch 1744/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 840393.4797 - val_loss: 712922.9664\n",
      "Epoch 1745/5000\n",
      "134/134 [==============================] - 0s 311us/step - loss: 861714.5159 - val_loss: 781449.5336\n",
      "Epoch 1746/5000\n",
      "134/134 [==============================] - 0s 295us/step - loss: 778095.5247 - val_loss: 1262773.0485\n",
      "Epoch 1747/5000\n",
      "134/134 [==============================] - 0s 295us/step - loss: 962828.8570 - val_loss: 721828.5093\n",
      "Epoch 1748/5000\n",
      "134/134 [==============================] - 0s 330us/step - loss: 820455.6529 - val_loss: 722015.9160\n",
      "Epoch 1749/5000\n",
      "134/134 [==============================] - 0s 331us/step - loss: 811392.8960 - val_loss: 712064.3610\n",
      "Epoch 1750/5000\n",
      "134/134 [==============================] - 0s 330us/step - loss: 790401.8012 - val_loss: 703051.3974\n",
      "Epoch 1751/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 772536.7405 - val_loss: 704296.3937\n",
      "Epoch 1752/5000\n",
      "134/134 [==============================] - 0s 333us/step - loss: 760605.4286 - val_loss: 868581.0933\n",
      "Epoch 1753/5000\n",
      "134/134 [==============================] - 0s 348us/step - loss: 750321.8429 - val_loss: 711671.4869\n",
      "Epoch 1754/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 745863.3525 - val_loss: 864313.1455\n",
      "Epoch 1755/5000\n",
      "134/134 [==============================] - 0s 289us/step - loss: 898157.9754 - val_loss: 730886.0317\n",
      "Epoch 1756/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 772082.8958 - val_loss: 691697.4683\n",
      "Epoch 1757/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 819809.9393 - val_loss: 705331.2463\n",
      "Epoch 1758/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 836724.2192 - val_loss: 698544.7575\n",
      "Epoch 1759/5000\n",
      "134/134 [==============================] - 0s 324us/step - loss: 774844.5758 - val_loss: 707921.8731\n",
      "Epoch 1760/5000\n",
      "134/134 [==============================] - 0s 277us/step - loss: 804221.7685 - val_loss: 788381.7537\n",
      "Epoch 1761/5000\n",
      "134/134 [==============================] - 0s 291us/step - loss: 801551.4566 - val_loss: 697296.0159\n",
      "Epoch 1762/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 729420.2141 - val_loss: 1341321.9739\n",
      "Epoch 1763/5000\n",
      "134/134 [==============================] - 0s 323us/step - loss: 874669.0956 - val_loss: 848929.4235\n",
      "Epoch 1764/5000\n",
      "134/134 [==============================] - 0s 297us/step - loss: 744887.5868 - val_loss: 1303775.4664\n",
      "Epoch 1765/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 858742.0849 - val_loss: 803493.2892\n",
      "Epoch 1766/5000\n",
      "134/134 [==============================] - 0s 280us/step - loss: 767370.4084 - val_loss: 772874.8713\n",
      "Epoch 1767/5000\n",
      "134/134 [==============================] - 0s 292us/step - loss: 765170.4277 - val_loss: 826200.2313\n",
      "Epoch 1768/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 788790.4146 - val_loss: 687441.7649\n",
      "Epoch 1769/5000\n",
      "134/134 [==============================] - 0s 300us/step - loss: 701826.6535 - val_loss: 697001.1530\n",
      "Epoch 1770/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 781812.3507 - val_loss: 707965.6054\n",
      "Epoch 1771/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 743319.5744 - val_loss: 887649.1642\n",
      "Epoch 1772/5000\n",
      "134/134 [==============================] - 0s 287us/step - loss: 883344.6308 - val_loss: 809750.6082\n",
      "Epoch 1773/5000\n",
      "134/134 [==============================] - 0s 292us/step - loss: 762126.2725 - val_loss: 758120.3899\n",
      "Epoch 1774/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 807959.3003 - val_loss: 684398.8778\n",
      "Epoch 1775/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 710910.3147 - val_loss: 806286.1866\n",
      "Epoch 1776/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 808755.2421 - val_loss: 691703.0970\n",
      "Epoch 1777/5000\n",
      "134/134 [==============================] - 0s 300us/step - loss: 698918.6174 - val_loss: 854257.9552\n",
      "Epoch 1778/5000\n",
      "134/134 [==============================] - 0s 329us/step - loss: 883501.8210 - val_loss: 716731.6940\n",
      "Epoch 1779/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 840951.6381 - val_loss: 715744.2892\n",
      "Epoch 1780/5000\n",
      "134/134 [==============================] - 0s 344us/step - loss: 724296.3330 - val_loss: 701113.9963\n",
      "Epoch 1781/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 804398.2876 - val_loss: 695967.2649\n",
      "Epoch 1782/5000\n",
      "134/134 [==============================] - 0s 281us/step - loss: 761536.9006 - val_loss: 693660.3629\n",
      "Epoch 1783/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 743312.7357 - val_loss: 706040.7612\n",
      "Epoch 1784/5000\n",
      "134/134 [==============================] - 0s 286us/step - loss: 773790.2327 - val_loss: 916386.9590\n",
      "Epoch 1785/5000\n",
      "134/134 [==============================] - 0s 365us/step - loss: 703759.4627 - val_loss: 686459.9188\n",
      "Epoch 1786/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 733804.9392 - val_loss: 692604.7705\n",
      "Epoch 1787/5000\n",
      "134/134 [==============================] - 0s 317us/step - loss: 858872.4728 - val_loss: 684896.3647\n",
      "Epoch 1788/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 775926.9121 - val_loss: 755994.3694\n",
      "Epoch 1789/5000\n",
      "134/134 [==============================] - 0s 317us/step - loss: 756705.4088 - val_loss: 710428.8647\n",
      "Epoch 1790/5000\n",
      "134/134 [==============================] - 0s 320us/step - loss: 849333.9027 - val_loss: 719772.1334\n",
      "Epoch 1791/5000\n",
      "134/134 [==============================] - 0s 298us/step - loss: 837816.5498 - val_loss: 757056.7780\n",
      "Epoch 1792/5000\n",
      "134/134 [==============================] - 0s 325us/step - loss: 748899.7191 - val_loss: 781722.3358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1793/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 724079.7332 - val_loss: 1446605.2463\n",
      "Epoch 1794/5000\n",
      "134/134 [==============================] - 0s 336us/step - loss: 926638.6625 - val_loss: 954474.9291\n",
      "Epoch 1795/5000\n",
      "134/134 [==============================] - 0s 294us/step - loss: 857400.6349 - val_loss: 748679.7285\n",
      "Epoch 1796/5000\n",
      "134/134 [==============================] - 0s 323us/step - loss: 805500.9753 - val_loss: 668608.5019\n",
      "Epoch 1797/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 680249.6221 - val_loss: 656697.2836\n",
      "Epoch 1798/5000\n",
      "134/134 [==============================] - 0s 324us/step - loss: 721900.6567 - val_loss: 832311.3078\n",
      "Epoch 1799/5000\n",
      "134/134 [==============================] - 0s 331us/step - loss: 925771.1898 - val_loss: 684984.5569\n",
      "Epoch 1800/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 788511.1624 - val_loss: 687748.2295\n",
      "Epoch 1801/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 740091.7801 - val_loss: 758762.6157\n",
      "Epoch 1802/5000\n",
      "134/134 [==============================] - 0s 324us/step - loss: 703258.5125 - val_loss: 847220.9384\n",
      "Epoch 1803/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 702251.6385 - val_loss: 876318.5448\n",
      "Epoch 1804/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 771364.2019 - val_loss: 686219.3097\n",
      "Epoch 1805/5000\n",
      "134/134 [==============================] - 0s 335us/step - loss: 731041.5942 - val_loss: 782692.9683\n",
      "Epoch 1806/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 779565.7156 - val_loss: 666832.4534\n",
      "Epoch 1807/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 829028.7404 - val_loss: 673478.3172\n",
      "Epoch 1808/5000\n",
      "134/134 [==============================] - 0s 323us/step - loss: 803898.4775 - val_loss: 750611.9123\n",
      "Epoch 1809/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 781952.6980 - val_loss: 870103.1213\n",
      "Epoch 1810/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 874069.8512 - val_loss: 672079.6045\n",
      "Epoch 1811/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 668454.9425 - val_loss: 785259.0690\n",
      "Epoch 1812/5000\n",
      "134/134 [==============================] - 0s 323us/step - loss: 724977.3893 - val_loss: 682268.5355\n",
      "Epoch 1813/5000\n",
      "134/134 [==============================] - 0s 304us/step - loss: 738061.2838 - val_loss: 1299666.9776\n",
      "Epoch 1814/5000\n",
      "134/134 [==============================] - 0s 311us/step - loss: 821168.5802 - val_loss: 656265.4664\n",
      "Epoch 1815/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 711026.6698 - val_loss: 811774.6605\n",
      "Epoch 1816/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 702228.5926 - val_loss: 833908.4683\n",
      "Epoch 1817/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 771737.0019 - val_loss: 661809.3433\n",
      "Epoch 1818/5000\n",
      "134/134 [==============================] - 0s 287us/step - loss: 761440.3659 - val_loss: 810273.7108\n",
      "Epoch 1819/5000\n",
      "134/134 [==============================] - 0s 271us/step - loss: 691405.5531 - val_loss: 717341.2771\n",
      "Epoch 1820/5000\n",
      "134/134 [==============================] - 0s 289us/step - loss: 745483.7957 - val_loss: 724055.1716\n",
      "Epoch 1821/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 763845.7938 - val_loss: 702389.2761\n",
      "Epoch 1822/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 766918.2438 - val_loss: 648174.5373\n",
      "Epoch 1823/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 764355.3631 - val_loss: 784755.5774\n",
      "Epoch 1824/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 686709.1079 - val_loss: 796137.0812\n",
      "Epoch 1825/5000\n",
      "134/134 [==============================] - 0s 321us/step - loss: 716427.6115 - val_loss: 929167.1455\n",
      "Epoch 1826/5000\n",
      "134/134 [==============================] - 0s 321us/step - loss: 731676.1715 - val_loss: 673771.0774\n",
      "Epoch 1827/5000\n",
      "134/134 [==============================] - 0s 334us/step - loss: 672659.7888 - val_loss: 637403.2519\n",
      "Epoch 1828/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 708907.6330 - val_loss: 702318.5616\n",
      "Epoch 1829/5000\n",
      "134/134 [==============================] - 0s 332us/step - loss: 729287.3396 - val_loss: 1014019.8116\n",
      "Epoch 1830/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 753845.9443 - val_loss: 814046.8545\n",
      "Epoch 1831/5000\n",
      "134/134 [==============================] - 0s 297us/step - loss: 742183.8583 - val_loss: 639921.7491\n",
      "Epoch 1832/5000\n",
      "134/134 [==============================] - 0s 329us/step - loss: 669239.3084 - val_loss: 642226.2593\n",
      "Epoch 1833/5000\n",
      "134/134 [==============================] - 0s 266us/step - loss: 660565.9877 - val_loss: 650043.7481\n",
      "Epoch 1834/5000\n",
      "134/134 [==============================] - 0s 320us/step - loss: 721939.1708 - val_loss: 658087.4356\n",
      "Epoch 1835/5000\n",
      "134/134 [==============================] - 0s 287us/step - loss: 707309.9150 - val_loss: 788587.7873\n",
      "Epoch 1836/5000\n",
      "134/134 [==============================] - 0s 311us/step - loss: 721725.6240 - val_loss: 648837.4319\n",
      "Epoch 1837/5000\n",
      "134/134 [==============================] - 0s 289us/step - loss: 686505.0357 - val_loss: 850621.9366\n",
      "Epoch 1838/5000\n",
      "134/134 [==============================] - 0s 324us/step - loss: 799067.1247 - val_loss: 679793.6241\n",
      "Epoch 1839/5000\n",
      "134/134 [==============================] - 0s 277us/step - loss: 709893.3572 - val_loss: 784651.6586\n",
      "Epoch 1840/5000\n",
      "134/134 [==============================] - 0s 292us/step - loss: 802031.5444 - val_loss: 698833.9039\n",
      "Epoch 1841/5000\n",
      "134/134 [==============================] - 0s 298us/step - loss: 701384.0762 - val_loss: 648417.0252\n",
      "Epoch 1842/5000\n",
      "134/134 [==============================] - 0s 311us/step - loss: 780710.6735 - val_loss: 711596.3675\n",
      "Epoch 1843/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 707967.2645 - val_loss: 632458.3675\n",
      "Epoch 1844/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 693291.1236 - val_loss: 795807.8470\n",
      "Epoch 1845/5000\n",
      "134/134 [==============================] - 0s 320us/step - loss: 804721.9988 - val_loss: 797196.2435\n",
      "Epoch 1846/5000\n",
      "134/134 [==============================] - 0s 293us/step - loss: 738677.6393 - val_loss: 826502.9646\n",
      "Epoch 1847/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 698435.2661 - val_loss: 862457.9851\n",
      "Epoch 1848/5000\n",
      "134/134 [==============================] - 0s 282us/step - loss: 735408.4469 - val_loss: 797932.9757\n",
      "Epoch 1849/5000\n",
      "134/134 [==============================] - 0s 295us/step - loss: 796312.9852 - val_loss: 795799.9123\n",
      "Epoch 1850/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 661560.2479 - val_loss: 790232.6306\n",
      "Epoch 1851/5000\n",
      "134/134 [==============================] - 0s 281us/step - loss: 695248.7703 - val_loss: 809261.6213\n",
      "Epoch 1852/5000\n",
      "134/134 [==============================] - 0s 276us/step - loss: 726350.6014 - val_loss: 808495.5952\n",
      "Epoch 1853/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 667941.3532 - val_loss: 666572.8069\n",
      "Epoch 1854/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 744404.5854 - val_loss: 968092.9216\n",
      "Epoch 1855/5000\n",
      "134/134 [==============================] - 0s 292us/step - loss: 770573.0768 - val_loss: 707840.7332\n",
      "Epoch 1856/5000\n",
      "134/134 [==============================] - 0s 294us/step - loss: 692825.8560 - val_loss: 836777.5933\n",
      "Epoch 1857/5000\n",
      "134/134 [==============================] - 0s 257us/step - loss: 749201.1932 - val_loss: 806791.2649\n",
      "Epoch 1858/5000\n",
      "134/134 [==============================] - 0s 318us/step - loss: 670874.2499 - val_loss: 709753.0168\n",
      "Epoch 1859/5000\n",
      "134/134 [==============================] - 0s 290us/step - loss: 741169.7887 - val_loss: 665451.5718\n",
      "Epoch 1860/5000\n",
      "134/134 [==============================] - 0s 323us/step - loss: 672384.6346 - val_loss: 613913.4524\n",
      "Epoch 1861/5000\n",
      "134/134 [==============================] - 0s 267us/step - loss: 685699.5628 - val_loss: 1043390.2202\n",
      "Epoch 1862/5000\n",
      "134/134 [==============================] - 0s 280us/step - loss: 853490.7731 - val_loss: 687009.6828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1863/5000\n",
      "134/134 [==============================] - 0s 333us/step - loss: 710721.1535 - val_loss: 648592.6073\n",
      "Epoch 1864/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 648173.0287 - val_loss: 667659.9403\n",
      "Epoch 1865/5000\n",
      "134/134 [==============================] - 0s 329us/step - loss: 724600.7006 - val_loss: 634093.2901\n",
      "Epoch 1866/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 651868.7239 - val_loss: 756664.9571\n",
      "Epoch 1867/5000\n",
      "134/134 [==============================] - 0s 325us/step - loss: 646397.0359 - val_loss: 680399.4702\n",
      "Epoch 1868/5000\n",
      "134/134 [==============================] - 0s 320us/step - loss: 726640.6235 - val_loss: 710585.1567\n",
      "Epoch 1869/5000\n",
      "134/134 [==============================] - 0s 324us/step - loss: 752599.4591 - val_loss: 645503.0532\n",
      "Epoch 1870/5000\n",
      "134/134 [==============================] - 0s 320us/step - loss: 685992.8053 - val_loss: 670547.5466\n",
      "Epoch 1871/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 693033.6833 - val_loss: 689117.1660\n",
      "Epoch 1872/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 700119.6928 - val_loss: 629725.2425\n",
      "Epoch 1873/5000\n",
      "134/134 [==============================] - 0s 301us/step - loss: 769091.4222 - val_loss: 684697.3274\n",
      "Epoch 1874/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 676739.0178 - val_loss: 740869.3116\n",
      "Epoch 1875/5000\n",
      "134/134 [==============================] - 0s 320us/step - loss: 726309.9830 - val_loss: 642001.8452\n",
      "Epoch 1876/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 697667.3002 - val_loss: 637389.4534\n",
      "Epoch 1877/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 641481.7365 - val_loss: 615272.4748\n",
      "Epoch 1878/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 701249.5979 - val_loss: 620428.1702\n",
      "Epoch 1879/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 712689.8821 - val_loss: 673779.3918\n",
      "Epoch 1880/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 659851.2672 - val_loss: 609899.2882\n",
      "Epoch 1881/5000\n",
      "134/134 [==============================] - 0s 341us/step - loss: 690552.5693 - val_loss: 665905.8293\n",
      "Epoch 1882/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 708346.9936 - val_loss: 667200.1987\n",
      "Epoch 1883/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 721206.5081 - val_loss: 667964.9925\n",
      "Epoch 1884/5000\n",
      "134/134 [==============================] - 0s 311us/step - loss: 710596.6139 - val_loss: 651424.6437\n",
      "Epoch 1885/5000\n",
      "134/134 [==============================] - 0s 315us/step - loss: 669779.0331 - val_loss: 740853.6474\n",
      "Epoch 1886/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 887272.8069 - val_loss: 658559.1577\n",
      "Epoch 1887/5000\n",
      "134/134 [==============================] - 0s 319us/step - loss: 723579.6285 - val_loss: 1007483.9254\n",
      "Epoch 1888/5000\n",
      "134/134 [==============================] - 0s 384us/step - loss: 870552.5933 - val_loss: 869011.6287\n",
      "Epoch 1889/5000\n",
      "134/134 [==============================] - 0s 382us/step - loss: 863729.0886 - val_loss: 777072.5019\n",
      "Epoch 1890/5000\n",
      "134/134 [==============================] - 0s 311us/step - loss: 677922.8481 - val_loss: 592848.3937\n",
      "Epoch 1891/5000\n",
      "134/134 [==============================] - 0s 402us/step - loss: 690208.4524 - val_loss: 646284.4748\n",
      "Epoch 1892/5000\n",
      "134/134 [==============================] - 0s 300us/step - loss: 750094.8913 - val_loss: 621346.4366\n",
      "Epoch 1893/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 686741.2617 - val_loss: 667079.9487\n",
      "Epoch 1894/5000\n",
      "134/134 [==============================] - 0s 323us/step - loss: 740703.3077 - val_loss: 708470.6521\n",
      "Epoch 1895/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 664065.4345 - val_loss: 1100663.7724\n",
      "Epoch 1896/5000\n",
      "134/134 [==============================] - 0s 294us/step - loss: 728680.5081 - val_loss: 758618.9086\n",
      "Epoch 1897/5000\n",
      "134/134 [==============================] - 0s 300us/step - loss: 671649.7200 - val_loss: 674631.7817\n",
      "Epoch 1898/5000\n",
      "134/134 [==============================] - 0s 372us/step - loss: 632662.9206 - val_loss: 625668.2523\n",
      "Epoch 1899/5000\n",
      "134/134 [==============================] - 0s 379us/step - loss: 624424.1872 - val_loss: 730785.4515\n",
      "Epoch 1900/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 660501.8047 - val_loss: 596124.1073\n",
      "Epoch 1901/5000\n",
      "134/134 [==============================] - 0s 279us/step - loss: 629948.8626 - val_loss: 688740.3554\n",
      "Epoch 1902/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 654203.9094 - val_loss: 687448.0355\n",
      "Epoch 1903/5000\n",
      "134/134 [==============================] - 0s 311us/step - loss: 631994.1874 - val_loss: 584227.5952\n",
      "Epoch 1904/5000\n",
      "134/134 [==============================] - 0s 300us/step - loss: 643702.4632 - val_loss: 807539.3116\n",
      "Epoch 1905/5000\n",
      "134/134 [==============================] - 0s 311us/step - loss: 725199.1933 - val_loss: 626590.3013\n",
      "Epoch 1906/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 698574.8790 - val_loss: 762127.2743\n",
      "Epoch 1907/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 691781.0814 - val_loss: 591217.1460\n",
      "Epoch 1908/5000\n",
      "134/134 [==============================] - 0s 323us/step - loss: 608110.2051 - val_loss: 1156796.7500\n",
      "Epoch 1909/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 814622.2320 - val_loss: 731864.6259\n",
      "Epoch 1910/5000\n",
      "134/134 [==============================] - 0s 299us/step - loss: 783937.4795 - val_loss: 717119.8657\n",
      "Epoch 1911/5000\n",
      "134/134 [==============================] - 0s 341us/step - loss: 653027.1486 - val_loss: 615640.0616\n",
      "Epoch 1912/5000\n",
      "134/134 [==============================] - 0s 299us/step - loss: 656290.0824 - val_loss: 607422.5793\n",
      "Epoch 1913/5000\n",
      "134/134 [==============================] - 0s 325us/step - loss: 716638.7878 - val_loss: 617672.1147\n",
      "Epoch 1914/5000\n",
      "134/134 [==============================] - 0s 320us/step - loss: 780651.4866 - val_loss: 754790.4879\n",
      "Epoch 1915/5000\n",
      "134/134 [==============================] - 0s 348us/step - loss: 624585.3299 - val_loss: 619136.7808\n",
      "Epoch 1916/5000\n",
      "134/134 [==============================] - 0s 304us/step - loss: 619114.8934 - val_loss: 589816.9025\n",
      "Epoch 1917/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 632144.1870 - val_loss: 680546.1740\n",
      "Epoch 1918/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 648910.0776 - val_loss: 1099103.9179\n",
      "Epoch 1919/5000\n",
      "134/134 [==============================] - 0s 304us/step - loss: 759374.1739 - val_loss: 611665.7388\n",
      "Epoch 1920/5000\n",
      "134/134 [==============================] - 0s 334us/step - loss: 699161.0209 - val_loss: 635952.7071\n",
      "Epoch 1921/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 604438.3490 - val_loss: 628416.8647\n",
      "Epoch 1922/5000\n",
      "134/134 [==============================] - 0s 276us/step - loss: 693053.1903 - val_loss: 596713.7724\n",
      "Epoch 1923/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 648590.8201 - val_loss: 628199.7696\n",
      "Epoch 1924/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 749099.8462 - val_loss: 580088.4170\n",
      "Epoch 1925/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 600404.8941 - val_loss: 579929.6390\n",
      "Epoch 1926/5000\n",
      "134/134 [==============================] - 0s 282us/step - loss: 618144.6090 - val_loss: 718593.6884\n",
      "Epoch 1927/5000\n",
      "134/134 [==============================] - 0s 265us/step - loss: 689267.7394 - val_loss: 685238.6908\n",
      "Epoch 1928/5000\n",
      "134/134 [==============================] - 0s 292us/step - loss: 726674.1074 - val_loss: 862938.1007\n",
      "Epoch 1929/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 919394.4870 - val_loss: 873071.1175\n",
      "Epoch 1930/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 712801.5934 - val_loss: 592451.8069\n",
      "Epoch 1931/5000\n",
      "134/134 [==============================] - 0s 319us/step - loss: 643820.6978 - val_loss: 575354.3228\n",
      "Epoch 1932/5000\n",
      "134/134 [==============================] - 0s 293us/step - loss: 621618.8380 - val_loss: 589299.7491\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1933/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 588976.9462 - val_loss: 565297.5574\n",
      "Epoch 1934/5000\n",
      "134/134 [==============================] - 0s 348us/step - loss: 594603.4778 - val_loss: 683197.2817\n",
      "Epoch 1935/5000\n",
      "134/134 [==============================] - 0s 342us/step - loss: 658233.3503 - val_loss: 583180.6898\n",
      "Epoch 1936/5000\n",
      "134/134 [==============================] - 0s 319us/step - loss: 586203.9627 - val_loss: 1161462.2500\n",
      "Epoch 1937/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 789586.9361 - val_loss: 604983.3088\n",
      "Epoch 1938/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 630230.9699 - val_loss: 605514.1852\n",
      "Epoch 1939/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 669440.5140 - val_loss: 591020.3237\n",
      "Epoch 1940/5000\n",
      "134/134 [==============================] - 0s 334us/step - loss: 613409.9072 - val_loss: 675132.2948\n",
      "Epoch 1941/5000\n",
      "134/134 [==============================] - 0s 372us/step - loss: 630136.7706 - val_loss: 581295.9226\n",
      "Epoch 1942/5000\n",
      "134/134 [==============================] - 0s 585us/step - loss: 625826.2847 - val_loss: 1058345.1642\n",
      "Epoch 1943/5000\n",
      "134/134 [==============================] - 0s 361us/step - loss: 689545.5034 - val_loss: 616411.0093\n",
      "Epoch 1944/5000\n",
      "134/134 [==============================] - 0s 362us/step - loss: 605514.5905 - val_loss: 647128.8759\n",
      "Epoch 1945/5000\n",
      "134/134 [==============================] - 0s 418us/step - loss: 602815.9676 - val_loss: 558539.4520\n",
      "Epoch 1946/5000\n",
      "134/134 [==============================] - 0s 375us/step - loss: 577899.4251 - val_loss: 883114.2649\n",
      "Epoch 1947/5000\n",
      "134/134 [==============================] - 0s 367us/step - loss: 818856.3461 - val_loss: 577271.8927\n",
      "Epoch 1948/5000\n",
      "134/134 [==============================] - 0s 294us/step - loss: 621681.2829 - val_loss: 558402.9324\n",
      "Epoch 1949/5000\n",
      "134/134 [==============================] - 0s 335us/step - loss: 600270.9058 - val_loss: 569919.7202\n",
      "Epoch 1950/5000\n",
      "134/134 [==============================] - 0s 364us/step - loss: 598173.4323 - val_loss: 556020.5299\n",
      "Epoch 1951/5000\n",
      "134/134 [==============================] - 0s 325us/step - loss: 600010.1111 - val_loss: 618325.5765\n",
      "Epoch 1952/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 626170.5032 - val_loss: 670072.2929\n",
      "Epoch 1953/5000\n",
      "134/134 [==============================] - 0s 330us/step - loss: 663342.8013 - val_loss: 1082225.5336\n",
      "Epoch 1954/5000\n",
      "134/134 [==============================] - 0s 325us/step - loss: 709570.2445 - val_loss: 762484.1269\n",
      "Epoch 1955/5000\n",
      "134/134 [==============================] - 0s 334us/step - loss: 647083.0709 - val_loss: 611203.2547\n",
      "Epoch 1956/5000\n",
      "134/134 [==============================] - 0s 333us/step - loss: 611648.7863 - val_loss: 562373.0410\n",
      "Epoch 1957/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 607794.2034 - val_loss: 571384.9188\n",
      "Epoch 1958/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 643563.6560 - val_loss: 794586.9328\n",
      "Epoch 1959/5000\n",
      "134/134 [==============================] - 0s 392us/step - loss: 642454.1942 - val_loss: 560392.5998\n",
      "Epoch 1960/5000\n",
      "134/134 [==============================] - 0s 409us/step - loss: 671320.0578 - val_loss: 571892.5229\n",
      "Epoch 1961/5000\n",
      "134/134 [==============================] - 0s 460us/step - loss: 592150.5578 - val_loss: 576068.9832\n",
      "Epoch 1962/5000\n",
      "134/134 [==============================] - 0s 376us/step - loss: 598400.5309 - val_loss: 567194.7001\n",
      "Epoch 1963/5000\n",
      "134/134 [==============================] - 0s 406us/step - loss: 549918.5230 - val_loss: 683871.5355\n",
      "Epoch 1964/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 572464.6086 - val_loss: 559613.9384\n",
      "Epoch 1965/5000\n",
      "134/134 [==============================] - 0s 287us/step - loss: 641431.8960 - val_loss: 670122.6828\n",
      "Epoch 1966/5000\n",
      "134/134 [==============================] - 0s 319us/step - loss: 628070.8434 - val_loss: 574614.6292\n",
      "Epoch 1967/5000\n",
      "134/134 [==============================] - 0s 331us/step - loss: 584538.3250 - val_loss: 681468.0709\n",
      "Epoch 1968/5000\n",
      "134/134 [==============================] - 0s 336us/step - loss: 646744.3433 - val_loss: 1066421.0784\n",
      "Epoch 1969/5000\n",
      "134/134 [==============================] - 0s 304us/step - loss: 749935.1866 - val_loss: 570184.5896\n",
      "Epoch 1970/5000\n",
      "134/134 [==============================] - 0s 304us/step - loss: 613226.8494 - val_loss: 571258.7836\n",
      "Epoch 1971/5000\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 602417.8288 - val_loss: 554964.4888\n",
      "Epoch 1972/5000\n",
      "134/134 [==============================] - 0s 630us/step - loss: 589041.6848 - val_loss: 570071.6651\n",
      "Epoch 1973/5000\n",
      "134/134 [==============================] - 0s 386us/step - loss: 557890.3633 - val_loss: 560352.2752\n",
      "Epoch 1974/5000\n",
      "134/134 [==============================] - 0s 466us/step - loss: 602615.7501 - val_loss: 593482.1688\n",
      "Epoch 1975/5000\n",
      "134/134 [==============================] - 0s 439us/step - loss: 603363.2458 - val_loss: 900599.3685\n",
      "Epoch 1976/5000\n",
      "134/134 [==============================] - 0s 419us/step - loss: 620618.5805 - val_loss: 700393.5840\n",
      "Epoch 1977/5000\n",
      "134/134 [==============================] - 0s 377us/step - loss: 592525.9691 - val_loss: 622214.9440\n",
      "Epoch 1978/5000\n",
      "134/134 [==============================] - 0s 299us/step - loss: 601459.9356 - val_loss: 832136.2071\n",
      "Epoch 1979/5000\n",
      "134/134 [==============================] - 0s 285us/step - loss: 707112.0921 - val_loss: 561415.2155\n",
      "Epoch 1980/5000\n",
      "134/134 [==============================] - 0s 258us/step - loss: 606445.2512 - val_loss: 631448.5616\n",
      "Epoch 1981/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 626996.6119 - val_loss: 540641.9347\n",
      "Epoch 1982/5000\n",
      "134/134 [==============================] - 0s 359us/step - loss: 575711.1256 - val_loss: 566523.9389\n",
      "Epoch 1983/5000\n",
      "134/134 [==============================] - 0s 474us/step - loss: 587003.0052 - val_loss: 549001.1996\n",
      "Epoch 1984/5000\n",
      "134/134 [==============================] - 0s 534us/step - loss: 612906.4033 - val_loss: 557126.6017\n",
      "Epoch 1985/5000\n",
      "134/134 [==============================] - 0s 655us/step - loss: 606640.7015 - val_loss: 615490.6838\n",
      "Epoch 1986/5000\n",
      "134/134 [==============================] - 0s 584us/step - loss: 610428.5778 - val_loss: 576802.4058\n",
      "Epoch 1987/5000\n",
      "134/134 [==============================] - 0s 947us/step - loss: 763953.6689 - val_loss: 569350.8610\n",
      "Epoch 1988/5000\n",
      "134/134 [==============================] - 0s 474us/step - loss: 685084.0221 - val_loss: 730867.7006\n",
      "Epoch 1989/5000\n",
      "134/134 [==============================] - 0s 300us/step - loss: 712528.2376 - val_loss: 551266.5429\n",
      "Epoch 1990/5000\n",
      "134/134 [==============================] - 0s 333us/step - loss: 573678.0641 - val_loss: 561693.7407\n",
      "Epoch 1991/5000\n",
      "134/134 [==============================] - 0s 588us/step - loss: 671170.1650 - val_loss: 579516.4105\n",
      "Epoch 1992/5000\n",
      "134/134 [==============================] - 0s 705us/step - loss: 608473.6124 - val_loss: 1461159.8694\n",
      "Epoch 1993/5000\n",
      "134/134 [==============================] - 0s 401us/step - loss: 706105.9370 - val_loss: 1215455.0858\n",
      "Epoch 1994/5000\n",
      "134/134 [==============================] - 0s 385us/step - loss: 706024.5087 - val_loss: 568738.7938\n",
      "Epoch 1995/5000\n",
      "134/134 [==============================] - 0s 447us/step - loss: 572231.5310 - val_loss: 960716.2724\n",
      "Epoch 1996/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 626004.4841 - val_loss: 584253.9692\n",
      "Epoch 1997/5000\n",
      "134/134 [==============================] - 0s 293us/step - loss: 556826.5324 - val_loss: 597822.5196\n",
      "Epoch 1998/5000\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 575494.3368 - val_loss: 534202.2864\n",
      "Epoch 1999/5000\n",
      "134/134 [==============================] - 0s 487us/step - loss: 578166.0444 - val_loss: 574084.6138\n",
      "Epoch 2000/5000\n",
      "134/134 [==============================] - 0s 604us/step - loss: 557447.4100 - val_loss: 552946.8563\n",
      "Epoch 2001/5000\n",
      "134/134 [==============================] - 0s 525us/step - loss: 563342.2668 - val_loss: 578183.4160\n",
      "Epoch 2002/5000\n",
      "134/134 [==============================] - 0s 422us/step - loss: 633012.7640 - val_loss: 553161.0947\n",
      "Epoch 2003/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 295us/step - loss: 564635.1496 - val_loss: 551330.1842\n",
      "Epoch 2004/5000\n",
      "134/134 [==============================] - 0s 315us/step - loss: 551972.2285 - val_loss: 570743.6950\n",
      "Epoch 2005/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 607455.2878 - val_loss: 553180.7388\n",
      "Epoch 2006/5000\n",
      "134/134 [==============================] - 0s 359us/step - loss: 598627.6905 - val_loss: 619828.1978\n",
      "Epoch 2007/5000\n",
      "134/134 [==============================] - 0s 833us/step - loss: 618543.3305 - val_loss: 684335.5905\n",
      "Epoch 2008/5000\n",
      "134/134 [==============================] - 0s 440us/step - loss: 553691.3043 - val_loss: 555018.5149\n",
      "Epoch 2009/5000\n",
      "134/134 [==============================] - 0s 528us/step - loss: 563165.4481 - val_loss: 1122858.4440\n",
      "Epoch 2010/5000\n",
      "134/134 [==============================] - 0s 758us/step - loss: 657975.0824 - val_loss: 712142.4851\n",
      "Epoch 2011/5000\n",
      "134/134 [==============================] - 0s 495us/step - loss: 639552.7885 - val_loss: 647183.6978\n",
      "Epoch 2012/5000\n",
      "134/134 [==============================] - 0s 431us/step - loss: 626845.1455 - val_loss: 745814.8918\n",
      "Epoch 2013/5000\n",
      "134/134 [==============================] - 0s 1ms/step - loss: 649359.4625 - val_loss: 571244.2938\n",
      "Epoch 2014/5000\n",
      "134/134 [==============================] - 0s 439us/step - loss: 694134.4720 - val_loss: 764020.1045\n",
      "Epoch 2015/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 582094.8094 - val_loss: 710268.3312\n",
      "Epoch 2016/5000\n",
      "134/134 [==============================] - 0s 393us/step - loss: 594774.3721 - val_loss: 555019.6007\n",
      "Epoch 2017/5000\n",
      "134/134 [==============================] - 0s 275us/step - loss: 639122.3183 - val_loss: 792584.6605\n",
      "Epoch 2018/5000\n",
      "134/134 [==============================] - 0s 286us/step - loss: 706668.0139 - val_loss: 597325.2029\n",
      "Epoch 2019/5000\n",
      "134/134 [==============================] - 0s 377us/step - loss: 585380.7910 - val_loss: 651309.9552\n",
      "Epoch 2020/5000\n",
      "134/134 [==============================] - 0s 388us/step - loss: 564881.9908 - val_loss: 538822.3862\n",
      "Epoch 2021/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 607389.0931 - val_loss: 773561.4646\n",
      "Epoch 2022/5000\n",
      "134/134 [==============================] - 0s 331us/step - loss: 619702.7453 - val_loss: 1061315.5858\n",
      "Epoch 2023/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 750790.8993 - val_loss: 661674.3274\n",
      "Epoch 2024/5000\n",
      "134/134 [==============================] - 0s 281us/step - loss: 577740.7071 - val_loss: 558927.7234\n",
      "Epoch 2025/5000\n",
      "134/134 [==============================] - 0s 271us/step - loss: 587399.1870 - val_loss: 563064.0051\n",
      "Epoch 2026/5000\n",
      "134/134 [==============================] - 0s 294us/step - loss: 586278.6442 - val_loss: 610767.4981\n",
      "Epoch 2027/5000\n",
      "134/134 [==============================] - 0s 300us/step - loss: 548444.9014 - val_loss: 524337.3484\n",
      "Epoch 2028/5000\n",
      "134/134 [==============================] - 0s 287us/step - loss: 586603.6046 - val_loss: 571933.2621\n",
      "Epoch 2029/5000\n",
      "134/134 [==============================] - 0s 412us/step - loss: 618218.9089 - val_loss: 759016.4179\n",
      "Epoch 2030/5000\n",
      "134/134 [==============================] - 0s 596us/step - loss: 628848.8178 - val_loss: 594480.4562\n",
      "Epoch 2031/5000\n",
      "134/134 [==============================] - 0s 525us/step - loss: 566254.3749 - val_loss: 733034.6521\n",
      "Epoch 2032/5000\n",
      "134/134 [==============================] - 0s 611us/step - loss: 663711.3608 - val_loss: 574207.6493\n",
      "Epoch 2033/5000\n",
      "134/134 [==============================] - 0s 498us/step - loss: 601412.2238 - val_loss: 521929.2626\n",
      "Epoch 2034/5000\n",
      "134/134 [==============================] - 0s 528us/step - loss: 617233.0362 - val_loss: 530007.6381\n",
      "Epoch 2035/5000\n",
      "134/134 [==============================] - 0s 688us/step - loss: 562536.0230 - val_loss: 541007.6665\n",
      "Epoch 2036/5000\n",
      "134/134 [==============================] - 0s 393us/step - loss: 566166.3008 - val_loss: 529647.7864\n",
      "Epoch 2037/5000\n",
      "134/134 [==============================] - ETA: 0s - loss: 2136444.500 - 0s 370us/step - loss: 604883.1807 - val_loss: 824279.0840\n",
      "Epoch 2038/5000\n",
      "134/134 [==============================] - 0s 399us/step - loss: 611315.0426 - val_loss: 532421.8703\n",
      "Epoch 2039/5000\n",
      "134/134 [==============================] - 0s 287us/step - loss: 557113.9999 - val_loss: 578847.4450\n",
      "Epoch 2040/5000\n",
      "134/134 [==============================] - 0s 293us/step - loss: 621303.1536 - val_loss: 618054.4291\n",
      "Epoch 2041/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 670389.3671 - val_loss: 569175.9235\n",
      "Epoch 2042/5000\n",
      "134/134 [==============================] - 0s 293us/step - loss: 532547.6334 - val_loss: 1068269.3396\n",
      "Epoch 2043/5000\n",
      "134/134 [==============================] - 0s 343us/step - loss: 650640.1464 - val_loss: 702518.0816\n",
      "Epoch 2044/5000\n",
      "134/134 [==============================] - 0s 370us/step - loss: 686447.0571 - val_loss: 619759.9240\n",
      "Epoch 2045/5000\n",
      "134/134 [==============================] - 0s 438us/step - loss: 606943.8148 - val_loss: 633364.0616\n",
      "Epoch 2046/5000\n",
      "134/134 [==============================] - 0s 338us/step - loss: 549936.8319 - val_loss: 528839.3060\n",
      "Epoch 2047/5000\n",
      "134/134 [==============================] - 0s 361us/step - loss: 619188.8472 - val_loss: 505296.3358\n",
      "Epoch 2048/5000\n",
      "134/134 [==============================] - 0s 349us/step - loss: 536855.7985 - val_loss: 536736.7337\n",
      "Epoch 2049/5000\n",
      "134/134 [==============================] - 0s 281us/step - loss: 562580.8555 - val_loss: 529950.0452\n",
      "Epoch 2050/5000\n",
      "134/134 [==============================] - 0s 355us/step - loss: 554190.1182 - val_loss: 540848.6507\n",
      "Epoch 2051/5000\n",
      "134/134 [==============================] - 0s 287us/step - loss: 589384.7949 - val_loss: 527549.7626\n",
      "Epoch 2052/5000\n",
      "134/134 [==============================] - 0s 289us/step - loss: 544704.8224 - val_loss: 660996.3097\n",
      "Epoch 2053/5000\n",
      "134/134 [==============================] - 0s 286us/step - loss: 558412.8689 - val_loss: 850732.9030\n",
      "Epoch 2054/5000\n",
      "134/134 [==============================] - 0s 318us/step - loss: 596652.5938 - val_loss: 519550.1833\n",
      "Epoch 2055/5000\n",
      "134/134 [==============================] - 0s 360us/step - loss: 625209.4033 - val_loss: 678682.9776\n",
      "Epoch 2056/5000\n",
      "134/134 [==============================] - 0s 339us/step - loss: 704636.3256 - val_loss: 563451.8885\n",
      "Epoch 2057/5000\n",
      "134/134 [==============================] - 0s 292us/step - loss: 729265.7648 - val_loss: 658523.9123\n",
      "Epoch 2058/5000\n",
      "134/134 [==============================] - 0s 281us/step - loss: 635622.6157 - val_loss: 578523.1833\n",
      "Epoch 2059/5000\n",
      "134/134 [==============================] - 0s 254us/step - loss: 611571.6972 - val_loss: 526807.2453\n",
      "Epoch 2060/5000\n",
      "134/134 [==============================] - 0s 279us/step - loss: 550709.1516 - val_loss: 517644.8181\n",
      "Epoch 2061/5000\n",
      "134/134 [==============================] - 0s 277us/step - loss: 582229.4347 - val_loss: 614583.6073\n",
      "Epoch 2062/5000\n",
      "134/134 [==============================] - 0s 290us/step - loss: 561592.9938 - val_loss: 570074.1437\n",
      "Epoch 2063/5000\n",
      "134/134 [==============================] - 0s 301us/step - loss: 551654.7149 - val_loss: 601626.8713\n",
      "Epoch 2064/5000\n",
      "134/134 [==============================] - 0s 273us/step - loss: 563725.4565 - val_loss: 624367.5410\n",
      "Epoch 2065/5000\n",
      "134/134 [==============================] - 0s 293us/step - loss: 686435.1238 - val_loss: 523865.4188\n",
      "Epoch 2066/5000\n",
      "134/134 [==============================] - 0s 272us/step - loss: 552973.5424 - val_loss: 604083.9524\n",
      "Epoch 2067/5000\n",
      "134/134 [==============================] - 0s 335us/step - loss: 543364.8090 - val_loss: 625312.3708\n",
      "Epoch 2068/5000\n",
      "134/134 [==============================] - 0s 280us/step - loss: 588688.8207 - val_loss: 507918.1632\n",
      "Epoch 2069/5000\n",
      "134/134 [==============================] - 0s 295us/step - loss: 564750.0940 - val_loss: 526198.0093\n",
      "Epoch 2070/5000\n",
      "134/134 [==============================] - 0s 281us/step - loss: 563431.5834 - val_loss: 512897.6772\n",
      "Epoch 2071/5000\n",
      "134/134 [==============================] - 0s 289us/step - loss: 557191.1827 - val_loss: 524764.3759\n",
      "Epoch 2072/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 639381.2207 - val_loss: 522423.5821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2073/5000\n",
      "134/134 [==============================] - 0s 334us/step - loss: 527094.2059 - val_loss: 518427.4883\n",
      "Epoch 2074/5000\n",
      "134/134 [==============================] - 0s 323us/step - loss: 526152.5139 - val_loss: 1112665.9030\n",
      "Epoch 2075/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 739568.5901 - val_loss: 507742.4958\n",
      "Epoch 2076/5000\n",
      "134/134 [==============================] - 0s 471us/step - loss: 514430.5140 - val_loss: 500326.9412\n",
      "Epoch 2077/5000\n",
      "134/134 [==============================] - 0s 456us/step - loss: 516954.5717 - val_loss: 575934.7705\n",
      "Epoch 2078/5000\n",
      "134/134 [==============================] - 0s 408us/step - loss: 536672.6213 - val_loss: 575500.3363\n",
      "Epoch 2079/5000\n",
      "134/134 [==============================] - 0s 354us/step - loss: 559237.4354 - val_loss: 1115270.1791\n",
      "Epoch 2080/5000\n",
      "134/134 [==============================] - 0s 397us/step - loss: 698087.2618 - val_loss: 510145.5019\n",
      "Epoch 2081/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 517579.6213 - val_loss: 492251.0438\n",
      "Epoch 2082/5000\n",
      "134/134 [==============================] - 0s 338us/step - loss: 503160.7570 - val_loss: 504998.2285\n",
      "Epoch 2083/5000\n",
      "134/134 [==============================] - 0s 317us/step - loss: 527666.2759 - val_loss: 585364.7491\n",
      "Epoch 2084/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 557491.3154 - val_loss: 491381.0984\n",
      "Epoch 2085/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 503953.4942 - val_loss: 592503.2006\n",
      "Epoch 2086/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 508288.5148 - val_loss: 512427.7444\n",
      "Epoch 2087/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 503684.7227 - val_loss: 538442.8825\n",
      "Epoch 2088/5000\n",
      "134/134 [==============================] - 0s 343us/step - loss: 560702.2338 - val_loss: 536932.6334\n",
      "Epoch 2089/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 527080.2146 - val_loss: 845738.2948\n",
      "Epoch 2090/5000\n",
      "134/134 [==============================] - 0s 336us/step - loss: 615976.2211 - val_loss: 536340.6306\n",
      "Epoch 2091/5000\n",
      "134/134 [==============================] - 0s 295us/step - loss: 553803.5335 - val_loss: 549362.0355\n",
      "Epoch 2092/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 663617.7932 - val_loss: 499260.8554\n",
      "Epoch 2093/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 533606.7793 - val_loss: 487362.2332\n",
      "Epoch 2094/5000\n",
      "134/134 [==============================] - 0s 287us/step - loss: 520776.8938 - val_loss: 524979.3284\n",
      "Epoch 2095/5000\n",
      "134/134 [==============================] - 0s 295us/step - loss: 561511.5278 - val_loss: 507934.9534\n",
      "Epoch 2096/5000\n",
      "134/134 [==============================] - 0s 304us/step - loss: 519859.6634 - val_loss: 1053700.9925\n",
      "Epoch 2097/5000\n",
      "134/134 [==============================] - 0s 271us/step - loss: 568468.2313 - val_loss: 741724.6754\n",
      "Epoch 2098/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 606739.2873 - val_loss: 586365.7211\n",
      "Epoch 2099/5000\n",
      "134/134 [==============================] - 0s 287us/step - loss: 709640.4846 - val_loss: 504627.5812\n",
      "Epoch 2100/5000\n",
      "134/134 [==============================] - 0s 535us/step - loss: 511329.9720 - val_loss: 568723.6931\n",
      "Epoch 2101/5000\n",
      "134/134 [==============================] - 0s 775us/step - loss: 556197.9381 - val_loss: 555745.1325\n",
      "Epoch 2102/5000\n",
      "134/134 [==============================] - 0s 422us/step - loss: 619930.0889 - val_loss: 605266.5900\n",
      "Epoch 2103/5000\n",
      "134/134 [==============================] - 0s 961us/step - loss: 563025.0659 - val_loss: 515038.0732\n",
      "Epoch 2104/5000\n",
      "134/134 [==============================] - 0s 404us/step - loss: 529030.3802 - val_loss: 509392.1329\n",
      "Epoch 2105/5000\n",
      "134/134 [==============================] - 0s 299us/step - loss: 520426.0093 - val_loss: 926198.7705\n",
      "Epoch 2106/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 635479.7656 - val_loss: 528411.2257\n",
      "Epoch 2107/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 509941.1735 - val_loss: 490279.3293\n",
      "Epoch 2108/5000\n",
      "134/134 [==============================] - 0s 276us/step - loss: 508084.8347 - val_loss: 505629.3452\n",
      "Epoch 2109/5000\n",
      "134/134 [==============================] - 0s 268us/step - loss: 549016.9842 - val_loss: 503841.5975\n",
      "Epoch 2110/5000\n",
      "134/134 [==============================] - 0s 269us/step - loss: 513715.7337 - val_loss: 517594.0126\n",
      "Epoch 2111/5000\n",
      "134/134 [==============================] - 0s 286us/step - loss: 560927.2220 - val_loss: 539968.3843\n",
      "Epoch 2112/5000\n",
      "134/134 [==============================] - 0s 285us/step - loss: 585821.2856 - val_loss: 494020.9716\n",
      "Epoch 2113/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 525862.2235 - val_loss: 502251.3722\n",
      "Epoch 2114/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 517745.3172 - val_loss: 495890.9599\n",
      "Epoch 2115/5000\n",
      "134/134 [==============================] - 0s 368us/step - loss: 503222.4062 - val_loss: 492994.3661\n",
      "Epoch 2116/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 528837.1273 - val_loss: 556531.5821\n",
      "Epoch 2117/5000\n",
      "134/134 [==============================] - 0s 391us/step - loss: 555925.8931 - val_loss: 689543.3438\n",
      "Epoch 2118/5000\n",
      "134/134 [==============================] - 0s 424us/step - loss: 704234.8412 - val_loss: 503947.8983\n",
      "Epoch 2119/5000\n",
      "134/134 [==============================] - 0s 402us/step - loss: 510037.3125 - val_loss: 578581.7938\n",
      "Epoch 2120/5000\n",
      "134/134 [==============================] - 0s 381us/step - loss: 615632.8722 - val_loss: 499015.8018\n",
      "Epoch 2121/5000\n",
      "134/134 [==============================] - 0s 298us/step - loss: 534501.4042 - val_loss: 509001.4981\n",
      "Epoch 2122/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 506096.4133 - val_loss: 531774.1320\n",
      "Epoch 2123/5000\n",
      "134/134 [==============================] - 0s 457us/step - loss: 535115.4412 - val_loss: 494994.3741\n",
      "Epoch 2124/5000\n",
      "134/134 [==============================] - 0s 400us/step - loss: 542057.1735 - val_loss: 485030.7990\n",
      "Epoch 2125/5000\n",
      "134/134 [==============================] - 0s 324us/step - loss: 513102.0289 - val_loss: 477788.5588\n",
      "Epoch 2126/5000\n",
      "134/134 [==============================] - 0s 409us/step - loss: 522173.9935 - val_loss: 938068.2407\n",
      "Epoch 2127/5000\n",
      "134/134 [==============================] - 0s 339us/step - loss: 568104.3489 - val_loss: 767889.5485\n",
      "Epoch 2128/5000\n",
      "134/134 [==============================] - 0s 385us/step - loss: 676104.9062 - val_loss: 724935.5746\n",
      "Epoch 2129/5000\n",
      "134/134 [==============================] - 0s 389us/step - loss: 675512.1101 - val_loss: 514156.6446\n",
      "Epoch 2130/5000\n",
      "134/134 [==============================] - 0s 495us/step - loss: 537441.9996 - val_loss: 588005.4776\n",
      "Epoch 2131/5000\n",
      "134/134 [==============================] - 0s 267us/step - loss: 610396.4038 - val_loss: 504883.5075\n",
      "Epoch 2132/5000\n",
      "134/134 [==============================] - 0s 264us/step - loss: 488265.5726 - val_loss: 481193.3232\n",
      "Epoch 2133/5000\n",
      "134/134 [==============================] - 0s 252us/step - loss: 485792.5078 - val_loss: 480989.8699\n",
      "Epoch 2134/5000\n",
      "134/134 [==============================] - 0s 271us/step - loss: 503541.5176 - val_loss: 663948.5522\n",
      "Epoch 2135/5000\n",
      "134/134 [==============================] - 0s 274us/step - loss: 520401.7909 - val_loss: 708266.2929\n",
      "Epoch 2136/5000\n",
      "134/134 [==============================] - 0s 252us/step - loss: 518027.4336 - val_loss: 479916.6059\n",
      "Epoch 2137/5000\n",
      "134/134 [==============================] - 0s 253us/step - loss: 487169.9689 - val_loss: 767554.8675\n",
      "Epoch 2138/5000\n",
      "134/134 [==============================] - 0s 269us/step - loss: 633494.3563 - val_loss: 501341.5574\n",
      "Epoch 2139/5000\n",
      "134/134 [==============================] - 0s 229us/step - loss: 504901.9012 - val_loss: 499938.5037\n",
      "Epoch 2140/5000\n",
      "134/134 [==============================] - 0s 243us/step - loss: 532748.6958 - val_loss: 490017.5522\n",
      "Epoch 2141/5000\n",
      "134/134 [==============================] - 0s 277us/step - loss: 524795.6052 - val_loss: 561081.0541\n",
      "Epoch 2142/5000\n",
      "134/134 [==============================] - 0s 223us/step - loss: 494626.6146 - val_loss: 577820.9002\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2143/5000\n",
      "134/134 [==============================] - 0s 250us/step - loss: 620330.2484 - val_loss: 510012.8806\n",
      "Epoch 2144/5000\n",
      "134/134 [==============================] - 0s 231us/step - loss: 504858.9554 - val_loss: 478143.6133\n",
      "Epoch 2145/5000\n",
      "134/134 [==============================] - 0s 234us/step - loss: 520951.6651 - val_loss: 592691.5476\n",
      "Epoch 2146/5000\n",
      "134/134 [==============================] - 0s 334us/step - loss: 583500.1985 - val_loss: 1145280.3452\n",
      "Epoch 2147/5000\n",
      "134/134 [==============================] - 0s 425us/step - loss: 625622.2509 - val_loss: 475287.7290\n",
      "Epoch 2148/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 489255.4362 - val_loss: 489359.1157\n",
      "Epoch 2149/5000\n",
      "134/134 [==============================] - 0s 301us/step - loss: 480410.6723 - val_loss: 475737.4333\n",
      "Epoch 2150/5000\n",
      "134/134 [==============================] - 0s 279us/step - loss: 509586.6813 - val_loss: 489023.6423\n",
      "Epoch 2151/5000\n",
      "134/134 [==============================] - 0s 272us/step - loss: 503010.3895 - val_loss: 524835.8260\n",
      "Epoch 2152/5000\n",
      "134/134 [==============================] - 0s 244us/step - loss: 566109.1384 - val_loss: 630467.8713\n",
      "Epoch 2153/5000\n",
      "134/134 [==============================] - 0s 277us/step - loss: 614086.6992 - val_loss: 499003.9506\n",
      "Epoch 2154/5000\n",
      "134/134 [==============================] - 0s 273us/step - loss: 483079.2443 - val_loss: 471759.0429\n",
      "Epoch 2155/5000\n",
      "134/134 [==============================] - 0s 344us/step - loss: 525058.4585 - val_loss: 621501.3041\n",
      "Epoch 2156/5000\n",
      "134/134 [==============================] - 0s 333us/step - loss: 564239.0444 - val_loss: 471962.3176\n",
      "Epoch 2157/5000\n",
      "134/134 [==============================] - 0s 256us/step - loss: 494546.8527 - val_loss: 476232.0742\n",
      "Epoch 2158/5000\n",
      "134/134 [==============================] - 0s 264us/step - loss: 484779.0347 - val_loss: 558962.1045\n",
      "Epoch 2159/5000\n",
      "134/134 [==============================] - 0s 282us/step - loss: 646948.4608 - val_loss: 499285.5247\n",
      "Epoch 2160/5000\n",
      "134/134 [==============================] - 0s 255us/step - loss: 494635.9547 - val_loss: 466177.3288\n",
      "Epoch 2161/5000\n",
      "134/134 [==============================] - 0s 274us/step - loss: 504544.2824 - val_loss: 655761.1987\n",
      "Epoch 2162/5000\n",
      "134/134 [==============================] - 0s 275us/step - loss: 545755.1144 - val_loss: 481811.7146\n",
      "Epoch 2163/5000\n",
      "134/134 [==============================] - 0s 320us/step - loss: 526754.2136 - val_loss: 586282.8545\n",
      "Epoch 2164/5000\n",
      "134/134 [==============================] - 0s 293us/step - loss: 574011.6709 - val_loss: 486021.6320\n",
      "Epoch 2165/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 517379.7763 - val_loss: 475780.3284\n",
      "Epoch 2166/5000\n",
      "134/134 [==============================] - 0s 273us/step - loss: 482773.5587 - val_loss: 522306.9468\n",
      "Epoch 2167/5000\n",
      "134/134 [==============================] - 0s 261us/step - loss: 561985.2587 - val_loss: 502979.9436\n",
      "Epoch 2168/5000\n",
      "134/134 [==============================] - 0s 286us/step - loss: 496424.1200 - val_loss: 459974.8923\n",
      "Epoch 2169/5000\n",
      "134/134 [==============================] - 0s 301us/step - loss: 481412.5246 - val_loss: 473168.5546\n",
      "Epoch 2170/5000\n",
      "134/134 [==============================] - ETA: 0s - loss: 141989.14 - 0s 299us/step - loss: 488004.5195 - val_loss: 475859.6213\n",
      "Epoch 2171/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 507310.4124 - val_loss: 605211.9086\n",
      "Epoch 2172/5000\n",
      "134/134 [==============================] - 0s 281us/step - loss: 586956.5718 - val_loss: 461238.4874\n",
      "Epoch 2173/5000\n",
      "134/134 [==============================] - 0s 283us/step - loss: 489602.2901 - val_loss: 464329.8792\n",
      "Epoch 2174/5000\n",
      "134/134 [==============================] - 0s 280us/step - loss: 478005.1025 - val_loss: 513842.3699\n",
      "Epoch 2175/5000\n",
      "134/134 [==============================] - 0s 267us/step - loss: 479710.2028 - val_loss: 481212.1329\n",
      "Epoch 2176/5000\n",
      "134/134 [==============================] - 0s 283us/step - loss: 540113.8214 - val_loss: 639539.8386\n",
      "Epoch 2177/5000\n",
      "134/134 [==============================] - 0s 271us/step - loss: 546808.1443 - val_loss: 722729.3507\n",
      "Epoch 2178/5000\n",
      "134/134 [==============================] - 0s 286us/step - loss: 588913.4531 - val_loss: 520733.6777\n",
      "Epoch 2179/5000\n",
      "134/134 [==============================] - 0s 292us/step - loss: 500197.0388 - val_loss: 505591.8256\n",
      "Epoch 2180/5000\n",
      "134/134 [==============================] - 0s 264us/step - loss: 475803.6763 - val_loss: 553626.1978\n",
      "Epoch 2181/5000\n",
      "134/134 [==============================] - 0s 268us/step - loss: 514130.6502 - val_loss: 512927.0854\n",
      "Epoch 2182/5000\n",
      "134/134 [==============================] - 0s 273us/step - loss: 552614.5076 - val_loss: 485120.2966\n",
      "Epoch 2183/5000\n",
      "134/134 [==============================] - 0s 268us/step - loss: 498821.2988 - val_loss: 497251.1852\n",
      "Epoch 2184/5000\n",
      "134/134 [==============================] - 0s 279us/step - loss: 499464.8268 - val_loss: 477546.0840\n",
      "Epoch 2185/5000\n",
      "134/134 [==============================] - 0s 279us/step - loss: 508026.2668 - val_loss: 545955.5952\n",
      "Epoch 2186/5000\n",
      "134/134 [==============================] - 0s 257us/step - loss: 657247.1723 - val_loss: 876754.2687\n",
      "Epoch 2187/5000\n",
      "134/134 [==============================] - 0s 264us/step - loss: 558793.0714 - val_loss: 473022.1423\n",
      "Epoch 2188/5000\n",
      "134/134 [==============================] - 0s 266us/step - loss: 522542.7208 - val_loss: 469042.5345\n",
      "Epoch 2189/5000\n",
      "134/134 [==============================] - 0s 267us/step - loss: 494638.5763 - val_loss: 467050.9417\n",
      "Epoch 2190/5000\n",
      "134/134 [==============================] - 0s 271us/step - loss: 574763.0201 - val_loss: 485654.3965\n",
      "Epoch 2191/5000\n",
      "134/134 [==============================] - 0s 258us/step - loss: 549875.5286 - val_loss: 472812.2202\n",
      "Epoch 2192/5000\n",
      "134/134 [==============================] - 0s 260us/step - loss: 482876.0952 - val_loss: 506479.1968\n",
      "Epoch 2193/5000\n",
      "134/134 [==============================] - 0s 264us/step - loss: 503442.4699 - val_loss: 648150.4142\n",
      "Epoch 2194/5000\n",
      "134/134 [==============================] - 0s 272us/step - loss: 582248.4588 - val_loss: 496533.5420\n",
      "Epoch 2195/5000\n",
      "134/134 [==============================] - 0s 273us/step - loss: 534248.4084 - val_loss: 755589.1399\n",
      "Epoch 2196/5000\n",
      "134/134 [==============================] - 0s 426us/step - loss: 680044.3438 - val_loss: 535227.2360\n",
      "Epoch 2197/5000\n",
      "134/134 [==============================] - 0s 375us/step - loss: 503011.5638 - val_loss: 536911.2509\n",
      "Epoch 2198/5000\n",
      "134/134 [==============================] - 0s 339us/step - loss: 537863.5196 - val_loss: 471059.2966\n",
      "Epoch 2199/5000\n",
      "134/134 [==============================] - 0s 374us/step - loss: 491714.3545 - val_loss: 448742.8032\n",
      "Epoch 2200/5000\n",
      "134/134 [==============================] - 0s 372us/step - loss: 463390.4955 - val_loss: 582725.2090\n",
      "Epoch 2201/5000\n",
      "134/134 [==============================] - 0s 330us/step - loss: 487838.2211 - val_loss: 571664.5131\n",
      "Epoch 2202/5000\n",
      "134/134 [==============================] - 0s 341us/step - loss: 516656.1105 - val_loss: 476304.2565\n",
      "Epoch 2203/5000\n",
      "134/134 [==============================] - 0s 354us/step - loss: 547420.9914 - val_loss: 494799.2341\n",
      "Epoch 2204/5000\n",
      "134/134 [==============================] - 0s 930us/step - loss: 462428.2043 - val_loss: 494578.8591\n",
      "Epoch 2205/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 481896.6551 - val_loss: 462694.9226\n",
      "Epoch 2206/5000\n",
      "134/134 [==============================] - 0s 301us/step - loss: 469116.4776 - val_loss: 481742.8997\n",
      "Epoch 2207/5000\n",
      "134/134 [==============================] - 0s 404us/step - loss: 477851.0690 - val_loss: 470752.0746\n",
      "Epoch 2208/5000\n",
      "134/134 [==============================] - 0s 384us/step - loss: 503329.6842 - val_loss: 468586.4781\n",
      "Epoch 2209/5000\n",
      "134/134 [==============================] - 0s 351us/step - loss: 480865.5532 - val_loss: 580980.3610\n",
      "Epoch 2210/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 570259.1931 - val_loss: 464371.1399\n",
      "Epoch 2211/5000\n",
      "134/134 [==============================] - 0s 387us/step - loss: 504767.5480 - val_loss: 483967.4128\n",
      "Epoch 2212/5000\n",
      "134/134 [==============================] - 0s 329us/step - loss: 545866.9832 - val_loss: 550654.1269\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2213/5000\n",
      "134/134 [==============================] - 0s 394us/step - loss: 520869.3280 - val_loss: 516849.4795\n",
      "Epoch 2214/5000\n",
      "134/134 [==============================] - 0s 357us/step - loss: 462444.1460 - val_loss: 487449.3489\n",
      "Epoch 2215/5000\n",
      "134/134 [==============================] - 0s 339us/step - loss: 471318.9640 - val_loss: 537739.9314\n",
      "Epoch 2216/5000\n",
      "134/134 [==============================] - 0s 286us/step - loss: 472278.9104 - val_loss: 499510.7771\n",
      "Epoch 2217/5000\n",
      "134/134 [==============================] - 0s 301us/step - loss: 468131.7509 - val_loss: 532713.4972\n",
      "Epoch 2218/5000\n",
      "134/134 [==============================] - 0s 393us/step - loss: 527243.6447 - val_loss: 457535.6978\n",
      "Epoch 2219/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 490399.7317 - val_loss: 497874.7001\n",
      "Epoch 2220/5000\n",
      "134/134 [==============================] - 0s 471us/step - loss: 641997.3819 - val_loss: 472298.3685\n",
      "Epoch 2221/5000\n",
      "134/134 [==============================] - 0s 516us/step - loss: 475487.4942 - val_loss: 459838.6101\n",
      "Epoch 2222/5000\n",
      "134/134 [==============================] - 0s 379us/step - loss: 456023.1152 - val_loss: 450225.9618\n",
      "Epoch 2223/5000\n",
      "134/134 [==============================] - 0s 469us/step - loss: 468787.6240 - val_loss: 464629.2467\n",
      "Epoch 2224/5000\n",
      "134/134 [==============================] - 0s 431us/step - loss: 491416.0037 - val_loss: 634600.0597\n",
      "Epoch 2225/5000\n",
      "134/134 [==============================] - 0s 530us/step - loss: 809804.9077 - val_loss: 451141.6325\n",
      "Epoch 2226/5000\n",
      "134/134 [==============================] - 0s 548us/step - loss: 481301.2890 - val_loss: 446595.7183\n",
      "Epoch 2227/5000\n",
      "134/134 [==============================] - 0s 443us/step - loss: 461614.9591 - val_loss: 460978.9039\n",
      "Epoch 2228/5000\n",
      "134/134 [==============================] - 0s 415us/step - loss: 465539.1172 - val_loss: 445466.0289\n",
      "Epoch 2229/5000\n",
      "134/134 [==============================] - 0s 494us/step - loss: 497633.6013 - val_loss: 445885.1772\n",
      "Epoch 2230/5000\n",
      "134/134 [==============================] - 0s 591us/step - loss: 484841.9825 - val_loss: 442055.4184\n",
      "Epoch 2231/5000\n",
      "134/134 [==============================] - 0s 521us/step - loss: 474944.8088 - val_loss: 499158.2230\n",
      "Epoch 2232/5000\n",
      "134/134 [==============================] - 0s 382us/step - loss: 466855.6643 - val_loss: 689059.3396\n",
      "Epoch 2233/5000\n",
      "134/134 [==============================] - 0s 321us/step - loss: 482305.7898 - val_loss: 444819.3680\n",
      "Epoch 2234/5000\n",
      "134/134 [==============================] - 0s 235us/step - loss: 451703.2624 - val_loss: 498526.1119\n",
      "Epoch 2235/5000\n",
      "134/134 [==============================] - 0s 283us/step - loss: 498579.9571 - val_loss: 1045364.6045\n",
      "Epoch 2236/5000\n",
      "134/134 [==============================] - 0s 260us/step - loss: 639621.1604 - val_loss: 579797.9501\n",
      "Epoch 2237/5000\n",
      "134/134 [==============================] - ETA: 0s - loss: 350521.03 - 0s 299us/step - loss: 478900.9266 - val_loss: 450150.0159\n",
      "Epoch 2238/5000\n",
      "134/134 [==============================] - 0s 363us/step - loss: 464603.5460 - val_loss: 433116.2878\n",
      "Epoch 2239/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 452642.1955 - val_loss: 429839.0303\n",
      "Epoch 2240/5000\n",
      "134/134 [==============================] - 0s 297us/step - loss: 463944.1681 - val_loss: 446290.4545\n",
      "Epoch 2241/5000\n",
      "134/134 [==============================] - 0s 285us/step - loss: 465135.5070 - val_loss: 503933.8596\n",
      "Epoch 2242/5000\n",
      "134/134 [==============================] - 0s 298us/step - loss: 495308.3820 - val_loss: 431394.5914\n",
      "Epoch 2243/5000\n",
      "134/134 [==============================] - 0s 246us/step - loss: 471759.5924 - val_loss: 492800.0877\n",
      "Epoch 2244/5000\n",
      "134/134 [==============================] - 0s 264us/step - loss: 455806.7731 - val_loss: 786004.5093\n",
      "Epoch 2245/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 650539.0893 - val_loss: 451715.0480\n",
      "Epoch 2246/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 466097.3619 - val_loss: 464182.8088\n",
      "Epoch 2247/5000\n",
      "134/134 [==============================] - 0s 360us/step - loss: 443995.8131 - val_loss: 436136.5434\n",
      "Epoch 2248/5000\n",
      "134/134 [==============================] - 0s 394us/step - loss: 473056.8664 - val_loss: 655250.2248\n",
      "Epoch 2249/5000\n",
      "134/134 [==============================] - 0s 387us/step - loss: 554858.6716 - val_loss: 431543.1091\n",
      "Epoch 2250/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 443097.2325 - val_loss: 428395.3204\n",
      "Epoch 2251/5000\n",
      "134/134 [==============================] - 0s 273us/step - loss: 438230.1936 - val_loss: 674779.9534\n",
      "Epoch 2252/5000\n",
      "134/134 [==============================] - 0s 263us/step - loss: 582376.7626 - val_loss: 534099.6054\n",
      "Epoch 2253/5000\n",
      "134/134 [==============================] - 0s 279us/step - loss: 483249.7661 - val_loss: 442385.3256\n",
      "Epoch 2254/5000\n",
      "134/134 [==============================] - 0s 251us/step - loss: 440589.1262 - val_loss: 458138.4286\n",
      "Epoch 2255/5000\n",
      "134/134 [==============================] - 0s 258us/step - loss: 438496.3776 - val_loss: 478666.5476\n",
      "Epoch 2256/5000\n",
      "134/134 [==============================] - 0s 278us/step - loss: 460980.1005 - val_loss: 436103.6161\n",
      "Epoch 2257/5000\n",
      "134/134 [==============================] - 0s 276us/step - loss: 446089.9333 - val_loss: 436781.1679\n",
      "Epoch 2258/5000\n",
      "134/134 [==============================] - 0s 319us/step - loss: 481929.4028 - val_loss: 426642.9678\n",
      "Epoch 2259/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 447750.8660 - val_loss: 495658.5644\n",
      "Epoch 2260/5000\n",
      "134/134 [==============================] - 0s 275us/step - loss: 460067.0065 - val_loss: 445840.0014\n",
      "Epoch 2261/5000\n",
      "134/134 [==============================] - 0s 285us/step - loss: 439042.7360 - val_loss: 468963.8540\n",
      "Epoch 2262/5000\n",
      "134/134 [==============================] - 0s 287us/step - loss: 475784.0166 - val_loss: 477727.5163\n",
      "Epoch 2263/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 476757.9667 - val_loss: 570230.2957\n",
      "Epoch 2264/5000\n",
      "134/134 [==============================] - 0s 345us/step - loss: 627859.7003 - val_loss: 563865.4702\n",
      "Epoch 2265/5000\n",
      "134/134 [==============================] - 0s 352us/step - loss: 449539.9780 - val_loss: 448460.1754\n",
      "Epoch 2266/5000\n",
      "134/134 [==============================] - 0s 317us/step - loss: 441314.6546 - val_loss: 431210.7379\n",
      "Epoch 2267/5000\n",
      "134/134 [==============================] - 0s 279us/step - loss: 449809.0205 - val_loss: 493771.1432\n",
      "Epoch 2268/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 482926.2023 - val_loss: 442858.7715\n",
      "Epoch 2269/5000\n",
      "134/134 [==============================] - 0s 295us/step - loss: 445211.7966 - val_loss: 633007.0392\n",
      "Epoch 2270/5000\n",
      "134/134 [==============================] - 0s 359us/step - loss: 493489.7728 - val_loss: 506648.4114\n",
      "Epoch 2271/5000\n",
      "134/134 [==============================] - 0s 379us/step - loss: 468703.7394 - val_loss: 498913.6819\n",
      "Epoch 2272/5000\n",
      "134/134 [==============================] - 0s 332us/step - loss: 452872.8252 - val_loss: 459983.0131\n",
      "Epoch 2273/5000\n",
      "134/134 [==============================] - 0s 368us/step - loss: 502783.7221 - val_loss: 514196.1642\n",
      "Epoch 2274/5000\n",
      "134/134 [==============================] - 0s 343us/step - loss: 574314.1758 - val_loss: 649902.4963\n",
      "Epoch 2275/5000\n",
      "134/134 [==============================] - 0s 295us/step - loss: 467756.6321 - val_loss: 842018.5196\n",
      "Epoch 2276/5000\n",
      "134/134 [==============================] - 0s 257us/step - loss: 513718.1296 - val_loss: 822342.4366\n",
      "Epoch 2277/5000\n",
      "134/134 [==============================] - 0s 279us/step - loss: 526815.9501 - val_loss: 437139.0364\n",
      "Epoch 2278/5000\n",
      "134/134 [==============================] - 0s 262us/step - loss: 449410.6325 - val_loss: 522166.0205\n",
      "Epoch 2279/5000\n",
      "134/134 [==============================] - 0s 287us/step - loss: 517559.7198 - val_loss: 524982.0289\n",
      "Epoch 2280/5000\n",
      "134/134 [==============================] - 0s 263us/step - loss: 535661.3769 - val_loss: 438626.7216\n",
      "Epoch 2281/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 431521.7234 - val_loss: 415981.1040\n",
      "Epoch 2282/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 438274.8900 - val_loss: 550597.7743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2283/5000\n",
      "134/134 [==============================] - 0s 288us/step - loss: 449092.8725 - val_loss: 531027.0159\n",
      "Epoch 2284/5000\n",
      "134/134 [==============================] - 0s 334us/step - loss: 444070.1237 - val_loss: 420056.2785\n",
      "Epoch 2285/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 437271.7192 - val_loss: 419941.7388\n",
      "Epoch 2286/5000\n",
      "134/134 [==============================] - 0s 280us/step - loss: 460749.6039 - val_loss: 464174.5452\n",
      "Epoch 2287/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 432657.1735 - val_loss: 800269.2211\n",
      "Epoch 2288/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 473036.6439 - val_loss: 528206.1861\n",
      "Epoch 2289/5000\n",
      "134/134 [==============================] - 0s 330us/step - loss: 488522.5803 - val_loss: 960807.4534\n",
      "Epoch 2290/5000\n",
      "134/134 [==============================] - 0s 369us/step - loss: 599916.0100 - val_loss: 464589.3825\n",
      "Epoch 2291/5000\n",
      "134/134 [==============================] - 0s 377us/step - loss: 488907.2222 - val_loss: 428280.9277\n",
      "Epoch 2292/5000\n",
      "134/134 [==============================] - 0s 323us/step - loss: 423259.6492 - val_loss: 419545.7397\n",
      "Epoch 2293/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 447362.1164 - val_loss: 443702.2677\n",
      "Epoch 2294/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 509966.2086 - val_loss: 544059.3302\n",
      "Epoch 2295/5000\n",
      "134/134 [==============================] - 0s 281us/step - loss: 513568.4841 - val_loss: 447534.0196\n",
      "Epoch 2296/5000\n",
      "134/134 [==============================] - 0s 329us/step - loss: 442313.5433 - val_loss: 514006.9632\n",
      "Epoch 2297/5000\n",
      "134/134 [==============================] - 0s 300us/step - loss: 678969.2490 - val_loss: 528759.4748\n",
      "Epoch 2298/5000\n",
      "134/134 [==============================] - 0s 274us/step - loss: 490717.6258 - val_loss: 423240.2682\n",
      "Epoch 2299/5000\n",
      "134/134 [==============================] - 0s 267us/step - loss: 433271.9005 - val_loss: 476248.8685\n",
      "Epoch 2300/5000\n",
      "134/134 [==============================] - 0s 266us/step - loss: 555980.9349 - val_loss: 409961.5709\n",
      "Epoch 2301/5000\n",
      "134/134 [==============================] - 0s 263us/step - loss: 434943.9879 - val_loss: 456341.8368\n",
      "Epoch 2302/5000\n",
      "134/134 [==============================] - 0s 272us/step - loss: 431304.8619 - val_loss: 446875.3358\n",
      "Epoch 2303/5000\n",
      "134/134 [==============================] - 0s 297us/step - loss: 451402.9580 - val_loss: 528302.6716\n",
      "Epoch 2304/5000\n",
      "134/134 [==============================] - 0s 304us/step - loss: 449938.0243 - val_loss: 409014.3470\n",
      "Epoch 2305/5000\n",
      "134/134 [==============================] - 0s 486us/step - loss: 414953.0745 - val_loss: 518941.5177\n",
      "Epoch 2306/5000\n",
      "134/134 [==============================] - 0s 338us/step - loss: 431711.3931 - val_loss: 419040.0457\n",
      "Epoch 2307/5000\n",
      "134/134 [==============================] - 0s 361us/step - loss: 436104.8545 - val_loss: 442199.1605\n",
      "Epoch 2308/5000\n",
      "134/134 [==============================] - 0s 678us/step - loss: 443836.4521 - val_loss: 564047.6250\n",
      "Epoch 2309/5000\n",
      "134/134 [==============================] - 0s 432us/step - loss: 439730.3227 - val_loss: 405915.2192\n",
      "Epoch 2310/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 425080.8055 - val_loss: 405137.2230\n",
      "Epoch 2311/5000\n",
      "134/134 [==============================] - 0s 396us/step - loss: 428335.6004 - val_loss: 621304.9757\n",
      "Epoch 2312/5000\n",
      "134/134 [==============================] - 0s 394us/step - loss: 481402.1605 - val_loss: 478396.5784\n",
      "Epoch 2313/5000\n",
      "134/134 [==============================] - 0s 409us/step - loss: 430865.6649 - val_loss: 519874.5019\n",
      "Epoch 2314/5000\n",
      "134/134 [==============================] - 0s 460us/step - loss: 559235.3049 - val_loss: 560705.6586\n",
      "Epoch 2315/5000\n",
      "134/134 [==============================] - 0s 395us/step - loss: 563614.3446 - val_loss: 555596.2495\n",
      "Epoch 2316/5000\n",
      "134/134 [==============================] - 0s 347us/step - loss: 463917.9277 - val_loss: 444807.1203\n",
      "Epoch 2317/5000\n",
      "134/134 [==============================] - 0s 365us/step - loss: 477372.1819 - val_loss: 413800.4333\n",
      "Epoch 2318/5000\n",
      "134/134 [==============================] - 0s 391us/step - loss: 433779.5285 - val_loss: 409434.3549\n",
      "Epoch 2319/5000\n",
      "134/134 [==============================] - 0s 304us/step - loss: 435701.2897 - val_loss: 445723.4188\n",
      "Epoch 2320/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 437197.7396 - val_loss: 451154.0168\n",
      "Epoch 2321/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 422663.1224 - val_loss: 488728.1707\n",
      "Epoch 2322/5000\n",
      "134/134 [==============================] - 0s 459us/step - loss: 436245.9944 - val_loss: 596023.0914\n",
      "Epoch 2323/5000\n",
      "134/134 [==============================] - 0s 486us/step - loss: 467668.4650 - val_loss: 406512.0210\n",
      "Epoch 2324/5000\n",
      "134/134 [==============================] - 0s 348us/step - loss: 417239.3606 - val_loss: 509655.1828\n",
      "Epoch 2325/5000\n",
      "134/134 [==============================] - 0s 400us/step - loss: 465176.6060 - val_loss: 411722.3685\n",
      "Epoch 2326/5000\n",
      "134/134 [==============================] - 0s 318us/step - loss: 495168.9076 - val_loss: 435844.8526\n",
      "Epoch 2327/5000\n",
      "134/134 [==============================] - 0s 323us/step - loss: 421914.3068 - val_loss: 401994.6642\n",
      "Epoch 2328/5000\n",
      "134/134 [==============================] - 0s 442us/step - loss: 419661.1244 - val_loss: 526356.6772\n",
      "Epoch 2329/5000\n",
      "134/134 [==============================] - 0s 279us/step - loss: 435620.3652 - val_loss: 403902.9827\n",
      "Epoch 2330/5000\n",
      "134/134 [==============================] - 0s 350us/step - loss: 406705.5918 - val_loss: 397902.7397\n",
      "Epoch 2331/5000\n",
      "134/134 [==============================] - 0s 379us/step - loss: 407140.6818 - val_loss: 425568.0676\n",
      "Epoch 2332/5000\n",
      "134/134 [==============================] - 0s 488us/step - loss: 482876.3431 - val_loss: 569525.0317\n",
      "Epoch 2333/5000\n",
      "134/134 [==============================] - 0s 379us/step - loss: 548163.5969 - val_loss: 426769.8344\n",
      "Epoch 2334/5000\n",
      "134/134 [==============================] - 0s 419us/step - loss: 421175.4010 - val_loss: 567575.6511\n",
      "Epoch 2335/5000\n",
      "134/134 [==============================] - 0s 370us/step - loss: 442004.9552 - val_loss: 565190.6866\n",
      "Epoch 2336/5000\n",
      "134/134 [==============================] - 0s 435us/step - loss: 433981.4042 - val_loss: 428189.0686\n",
      "Epoch 2337/5000\n",
      "134/134 [==============================] - 0s 395us/step - loss: 426010.4436 - val_loss: 604241.0858\n",
      "Epoch 2338/5000\n",
      "134/134 [==============================] - 0s 325us/step - loss: 441774.6576 - val_loss: 512107.1063\n",
      "Epoch 2339/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 500233.8891 - val_loss: 442276.0513\n",
      "Epoch 2340/5000\n",
      "134/134 [==============================] - 0s 337us/step - loss: 433480.4609 - val_loss: 419308.1987\n",
      "Epoch 2341/5000\n",
      "134/134 [==============================] - 0s 382us/step - loss: 402990.4906 - val_loss: 529051.8899\n",
      "Epoch 2342/5000\n",
      "134/134 [==============================] - 0s 293us/step - loss: 422467.6033 - val_loss: 924407.0019\n",
      "Epoch 2343/5000\n",
      "134/134 [==============================] - 0s 264us/step - loss: 510663.4098 - val_loss: 458411.2920\n",
      "Epoch 2344/5000\n",
      "134/134 [==============================] - 0s 291us/step - loss: 520426.3582 - val_loss: 454503.9702\n",
      "Epoch 2345/5000\n",
      "134/134 [==============================] - 0s 318us/step - loss: 468171.9908 - val_loss: 390643.5980\n",
      "Epoch 2346/5000\n",
      "134/134 [==============================] - 0s 274us/step - loss: 429273.9516 - val_loss: 421037.4310\n",
      "Epoch 2347/5000\n",
      "134/134 [==============================] - 0s 272us/step - loss: 415423.0840 - val_loss: 473970.8153\n",
      "Epoch 2348/5000\n",
      "134/134 [==============================] - 0s 260us/step - loss: 469304.7239 - val_loss: 398790.1213\n",
      "Epoch 2349/5000\n",
      "134/134 [==============================] - 0s 273us/step - loss: 437420.9149 - val_loss: 404830.8927\n",
      "Epoch 2350/5000\n",
      "134/134 [==============================] - 0s 274us/step - loss: 422335.9866 - val_loss: 391884.5187\n",
      "Epoch 2351/5000\n",
      "134/134 [==============================] - 0s 260us/step - loss: 408435.9697 - val_loss: 396822.5341\n",
      "Epoch 2352/5000\n",
      "134/134 [==============================] - 0s 276us/step - loss: 393567.3368 - val_loss: 384280.0056\n",
      "Epoch 2353/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 265us/step - loss: 393917.9481 - val_loss: 389153.4272\n",
      "Epoch 2354/5000\n",
      "134/134 [==============================] - ETA: 0s - loss: 905652.31 - 0s 369us/step - loss: 473012.3085 - val_loss: 486114.9179\n",
      "Epoch 2355/5000\n",
      "134/134 [==============================] - 0s 487us/step - loss: 451207.9136 - val_loss: 763287.0896\n",
      "Epoch 2356/5000\n",
      "134/134 [==============================] - 0s 393us/step - loss: 643023.1121 - val_loss: 477982.9422\n",
      "Epoch 2357/5000\n",
      "134/134 [==============================] - 0s 600us/step - loss: 578864.3014 - val_loss: 622785.0093\n",
      "Epoch 2358/5000\n",
      "134/134 [==============================] - 0s 448us/step - loss: 457224.0499 - val_loss: 390537.3610\n",
      "Epoch 2359/5000\n",
      "134/134 [==============================] - 0s 273us/step - loss: 416194.9439 - val_loss: 459300.3881\n",
      "Epoch 2360/5000\n",
      "134/134 [==============================] - 0s 290us/step - loss: 520128.6041 - val_loss: 480419.3274\n",
      "Epoch 2361/5000\n",
      "134/134 [==============================] - 0s 360us/step - loss: 481573.3488 - val_loss: 384442.6245\n",
      "Epoch 2362/5000\n",
      "134/134 [==============================] - 0s 318us/step - loss: 415644.1474 - val_loss: 584113.7332\n",
      "Epoch 2363/5000\n",
      "134/134 [==============================] - 0s 280us/step - loss: 617609.7103 - val_loss: 392072.3568\n",
      "Epoch 2364/5000\n",
      "134/134 [==============================] - 0s 266us/step - loss: 414731.4145 - val_loss: 496916.9580\n",
      "Epoch 2365/5000\n",
      "134/134 [==============================] - 0s 338us/step - loss: 506660.1965 - val_loss: 419633.9767\n",
      "Epoch 2366/5000\n",
      "134/134 [==============================] - 0s 288us/step - loss: 425506.0833 - val_loss: 403527.8563\n",
      "Epoch 2367/5000\n",
      "134/134 [==============================] - 0s 269us/step - loss: 449177.2451 - val_loss: 428932.7985\n",
      "Epoch 2368/5000\n",
      "134/134 [==============================] - 0s 317us/step - loss: 440705.5029 - val_loss: 388900.8167\n",
      "Epoch 2369/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 473058.5512 - val_loss: 418725.4207\n",
      "Epoch 2370/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 436787.4355 - val_loss: 383261.1297\n",
      "Epoch 2371/5000\n",
      "134/134 [==============================] - 0s 394us/step - loss: 395613.7621 - val_loss: 379466.7150\n",
      "Epoch 2372/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 395374.6675 - val_loss: 428965.9123\n",
      "Epoch 2373/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 418374.3661 - val_loss: 391218.4142\n",
      "Epoch 2374/5000\n",
      "134/134 [==============================] - 0s 534us/step - loss: 402172.5351 - val_loss: 403974.6367\n",
      "Epoch 2375/5000\n",
      "134/134 [==============================] - 0s 397us/step - loss: 457212.9270 - val_loss: 460725.1567\n",
      "Epoch 2376/5000\n",
      "134/134 [==============================] - 0s 466us/step - loss: 420231.7246 - val_loss: 402039.6021\n",
      "Epoch 2377/5000\n",
      "134/134 [==============================] - 0s 533us/step - loss: 422787.9296 - val_loss: 604845.0616\n",
      "Epoch 2378/5000\n",
      "134/134 [==============================] - 0s 486us/step - loss: 626430.7103 - val_loss: 403445.0205\n",
      "Epoch 2379/5000\n",
      "134/134 [==============================] - 0s 521us/step - loss: 399202.2882 - val_loss: 375939.0396\n",
      "Epoch 2380/5000\n",
      "134/134 [==============================] - 0s 392us/step - loss: 388755.3037 - val_loss: 394559.3223\n",
      "Epoch 2381/5000\n",
      "134/134 [==============================] - 0s 365us/step - loss: 419414.1543 - val_loss: 381651.4188\n",
      "Epoch 2382/5000\n",
      "134/134 [==============================] - 0s 385us/step - loss: 377706.9444 - val_loss: 452863.4949\n",
      "Epoch 2383/5000\n",
      "134/134 [==============================] - 0s 325us/step - loss: 414772.0508 - val_loss: 389379.0434\n",
      "Epoch 2384/5000\n",
      "134/134 [==============================] - 0s 498us/step - loss: 384076.1760 - val_loss: 374276.5821\n",
      "Epoch 2385/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 420446.1072 - val_loss: 595228.7892\n",
      "Epoch 2386/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 450143.8134 - val_loss: 393575.4058\n",
      "Epoch 2387/5000\n",
      "134/134 [==============================] - 0s 293us/step - loss: 382258.3977 - val_loss: 413408.6264\n",
      "Epoch 2388/5000\n",
      "134/134 [==============================] - 0s 315us/step - loss: 394147.0703 - val_loss: 405933.2715\n",
      "Epoch 2389/5000\n",
      "134/134 [==============================] - 0s 324us/step - loss: 455154.2999 - val_loss: 448979.7906\n",
      "Epoch 2390/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 454482.6144 - val_loss: 410788.6479\n",
      "Epoch 2391/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 477008.2944 - val_loss: 437573.3596\n",
      "Epoch 2392/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 447454.3644 - val_loss: 418905.9576\n",
      "Epoch 2393/5000\n",
      "134/134 [==============================] - 0s 334us/step - loss: 457123.2167 - val_loss: 404383.9002\n",
      "Epoch 2394/5000\n",
      "134/134 [==============================] - 0s 267us/step - loss: 405151.2588 - val_loss: 371863.4356\n",
      "Epoch 2395/5000\n",
      "134/134 [==============================] - 0s 264us/step - loss: 375616.2771 - val_loss: 366053.4921\n",
      "Epoch 2396/5000\n",
      "134/134 [==============================] - 0s 304us/step - loss: 378705.1691 - val_loss: 411861.7724\n",
      "Epoch 2397/5000\n",
      "134/134 [==============================] - 0s 263us/step - loss: 437356.1793 - val_loss: 384958.5448\n",
      "Epoch 2398/5000\n",
      "134/134 [==============================] - 0s 279us/step - loss: 421292.0975 - val_loss: 406138.5289\n",
      "Epoch 2399/5000\n",
      "134/134 [==============================] - 0s 290us/step - loss: 492065.1448 - val_loss: 675106.9049\n",
      "Epoch 2400/5000\n",
      "134/134 [==============================] - 0s 264us/step - loss: 420147.8324 - val_loss: 361595.0760\n",
      "Epoch 2401/5000\n",
      "134/134 [==============================] - 0s 260us/step - loss: 374703.8593 - val_loss: 363698.9711\n",
      "Epoch 2402/5000\n",
      "134/134 [==============================] - 0s 263us/step - loss: 391243.7090 - val_loss: 390950.2164\n",
      "Epoch 2403/5000\n",
      "134/134 [==============================] - 0s 256us/step - loss: 416247.2804 - val_loss: 436280.2043\n",
      "Epoch 2404/5000\n",
      "134/134 [==============================] - 0s 267us/step - loss: 420957.2534 - val_loss: 391981.7379\n",
      "Epoch 2405/5000\n",
      "134/134 [==============================] - 0s 275us/step - loss: 451051.9622 - val_loss: 376641.5980\n",
      "Epoch 2406/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 467961.6311 - val_loss: 395643.8386\n",
      "Epoch 2407/5000\n",
      "134/134 [==============================] - 0s 369us/step - loss: 394115.8584 - val_loss: 535342.3713\n",
      "Epoch 2408/5000\n",
      "134/134 [==============================] - 0s 365us/step - loss: 412648.4918 - val_loss: 379802.8904\n",
      "Epoch 2409/5000\n",
      "134/134 [==============================] - 0s 347us/step - loss: 382579.8293 - val_loss: 570666.5168\n",
      "Epoch 2410/5000\n",
      "134/134 [==============================] - 0s 346us/step - loss: 519678.0292 - val_loss: 393946.4734\n",
      "Epoch 2411/5000\n",
      "134/134 [==============================] - 0s 331us/step - loss: 421421.7093 - val_loss: 440487.2733\n",
      "Epoch 2412/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 403729.7338 - val_loss: 388131.6609\n",
      "Epoch 2413/5000\n",
      "134/134 [==============================] - 0s 295us/step - loss: 382313.9616 - val_loss: 396144.7202\n",
      "Epoch 2414/5000\n",
      "134/134 [==============================] - 0s 287us/step - loss: 400242.2115 - val_loss: 483908.8209\n",
      "Epoch 2415/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 426126.0646 - val_loss: 367487.2766\n",
      "Epoch 2416/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 379029.9394 - val_loss: 414070.7015\n",
      "Epoch 2417/5000\n",
      "134/134 [==============================] - 0s 318us/step - loss: 381103.9409 - val_loss: 525763.1810\n",
      "Epoch 2418/5000\n",
      "134/134 [==============================] - 0s 342us/step - loss: 405412.9220 - val_loss: 381203.0126\n",
      "Epoch 2419/5000\n",
      "134/134 [==============================] - 0s 358us/step - loss: 403778.0034 - val_loss: 453203.9981\n",
      "Epoch 2420/5000\n",
      "134/134 [==============================] - 0s 274us/step - loss: 473034.3847 - val_loss: 389406.3633\n",
      "Epoch 2421/5000\n",
      "134/134 [==============================] - 0s 292us/step - loss: 540217.6503 - val_loss: 1075124.1157\n",
      "Epoch 2422/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 586436.5728 - val_loss: 435089.9226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2423/5000\n",
      "134/134 [==============================] - 0s 278us/step - loss: 383955.0412 - val_loss: 353667.4664\n",
      "Epoch 2424/5000\n",
      "134/134 [==============================] - 0s 280us/step - loss: 371657.2738 - val_loss: 362064.3689\n",
      "Epoch 2425/5000\n",
      "134/134 [==============================] - 0s 291us/step - loss: 366641.4739 - val_loss: 351802.0406\n",
      "Epoch 2426/5000\n",
      "134/134 [==============================] - 0s 346us/step - loss: 356465.1257 - val_loss: 368223.1945\n",
      "Epoch 2427/5000\n",
      "134/134 [==============================] - 0s 324us/step - loss: 359924.4928 - val_loss: 380629.4571\n",
      "Epoch 2428/5000\n",
      "134/134 [==============================] - 0s 342us/step - loss: 365144.1068 - val_loss: 355198.6124\n",
      "Epoch 2429/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 367996.1269 - val_loss: 350995.3731\n",
      "Epoch 2430/5000\n",
      "134/134 [==============================] - 0s 281us/step - loss: 364070.8149 - val_loss: 359299.1404\n",
      "Epoch 2431/5000\n",
      "134/134 [==============================] - 0s 272us/step - loss: 366758.8256 - val_loss: 363631.9109\n",
      "Epoch 2432/5000\n",
      "134/134 [==============================] - 0s 280us/step - loss: 401279.9984 - val_loss: 550787.4655\n",
      "Epoch 2433/5000\n",
      "134/134 [==============================] - 0s 261us/step - loss: 384290.0431 - val_loss: 400992.5798\n",
      "Epoch 2434/5000\n",
      "134/134 [==============================] - 0s 273us/step - loss: 410724.6350 - val_loss: 398325.2383\n",
      "Epoch 2435/5000\n",
      "134/134 [==============================] - 0s 276us/step - loss: 426569.0238 - val_loss: 361544.3405\n",
      "Epoch 2436/5000\n",
      "134/134 [==============================] - 0s 279us/step - loss: 366726.7098 - val_loss: 588367.2220\n",
      "Epoch 2437/5000\n",
      "134/134 [==============================] - 0s 299us/step - loss: 469848.4707 - val_loss: 373959.7365\n",
      "Epoch 2438/5000\n",
      "134/134 [==============================] - 0s 347us/step - loss: 395027.9606 - val_loss: 372777.7453\n",
      "Epoch 2439/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 394720.9922 - val_loss: 362195.7481\n",
      "Epoch 2440/5000\n",
      "134/134 [==============================] - 0s 272us/step - loss: 363549.8520 - val_loss: 377771.9622\n",
      "Epoch 2441/5000\n",
      "134/134 [==============================] - 0s 300us/step - loss: 373976.5872 - val_loss: 519635.5970\n",
      "Epoch 2442/5000\n",
      "134/134 [==============================] - 0s 323us/step - loss: 396881.0889 - val_loss: 750261.3172\n",
      "Epoch 2443/5000\n",
      "134/134 [==============================] - 0s 330us/step - loss: 542268.9879 - val_loss: 430252.1026\n",
      "Epoch 2444/5000\n",
      "134/134 [==============================] - 0s 304us/step - loss: 436724.4621 - val_loss: 581935.0606\n",
      "Epoch 2445/5000\n",
      "134/134 [==============================] - 0s 276us/step - loss: 472730.3387 - val_loss: 367671.9356\n",
      "Epoch 2446/5000\n",
      "134/134 [==============================] - 0s 270us/step - loss: 392435.0280 - val_loss: 357680.5914\n",
      "Epoch 2447/5000\n",
      "134/134 [==============================] - 0s 288us/step - loss: 359169.9963 - val_loss: 383177.7528\n",
      "Epoch 2448/5000\n",
      "134/134 [==============================] - 0s 266us/step - loss: 348825.2573 - val_loss: 346663.0644\n",
      "Epoch 2449/5000\n",
      "134/134 [==============================] - 0s 271us/step - loss: 357731.0965 - val_loss: 358891.8890\n",
      "Epoch 2450/5000\n",
      "134/134 [==============================] - 0s 262us/step - loss: 362898.3155 - val_loss: 356546.9305\n",
      "Epoch 2451/5000\n",
      "134/134 [==============================] - 0s 696us/step - loss: 361599.0965 - val_loss: 439177.5462\n",
      "Epoch 2452/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 373807.5253 - val_loss: 354416.6054\n",
      "Epoch 2453/5000\n",
      "134/134 [==============================] - 0s 263us/step - loss: 437222.8717 - val_loss: 398836.4282\n",
      "Epoch 2454/5000\n",
      "134/134 [==============================] - 0s 253us/step - loss: 532884.3083 - val_loss: 418978.4296\n",
      "Epoch 2455/5000\n",
      "134/134 [==============================] - 0s 279us/step - loss: 392301.6476 - val_loss: 471937.6446\n",
      "Epoch 2456/5000\n",
      "134/134 [==============================] - 0s 266us/step - loss: 387798.3099 - val_loss: 403079.5252\n",
      "Epoch 2457/5000\n",
      "134/134 [==============================] - 0s 272us/step - loss: 437779.1466 - val_loss: 395373.7225\n",
      "Epoch 2458/5000\n",
      "134/134 [==============================] - 0s 273us/step - loss: 410662.4506 - val_loss: 393508.8125\n",
      "Epoch 2459/5000\n",
      "134/134 [==============================] - 0s 269us/step - loss: 405118.4583 - val_loss: 361375.1077\n",
      "Epoch 2460/5000\n",
      "134/134 [==============================] - 0s 282us/step - loss: 358591.4435 - val_loss: 398884.4198\n",
      "Epoch 2461/5000\n",
      "134/134 [==============================] - 0s 274us/step - loss: 376574.1936 - val_loss: 351763.6110\n",
      "Epoch 2462/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 357714.9783 - val_loss: 713520.9049\n",
      "Epoch 2463/5000\n",
      "134/134 [==============================] - 0s 337us/step - loss: 393111.3879 - val_loss: 417811.0317\n",
      "Epoch 2464/5000\n",
      "134/134 [==============================] - 0s 410us/step - loss: 379418.0910 - val_loss: 452482.9459\n",
      "Epoch 2465/5000\n",
      "134/134 [==============================] - 0s 384us/step - loss: 355811.2161 - val_loss: 338908.2523\n",
      "Epoch 2466/5000\n",
      "134/134 [==============================] - 0s 353us/step - loss: 371139.6269 - val_loss: 356943.9216\n",
      "Epoch 2467/5000\n",
      "134/134 [==============================] - 0s 356us/step - loss: 351793.9290 - val_loss: 345121.7593\n",
      "Epoch 2468/5000\n",
      "134/134 [==============================] - 0s 342us/step - loss: 368721.4278 - val_loss: 385869.2146\n",
      "Epoch 2469/5000\n",
      "134/134 [==============================] - 0s 315us/step - loss: 363823.3489 - val_loss: 364236.3806\n",
      "Epoch 2470/5000\n",
      "134/134 [==============================] - 0s 288us/step - loss: 498242.7205 - val_loss: 399858.3778\n",
      "Epoch 2471/5000\n",
      "134/134 [==============================] - 0s 281us/step - loss: 418834.1467 - val_loss: 447433.7202\n",
      "Epoch 2472/5000\n",
      "134/134 [==============================] - 0s 275us/step - loss: 405756.7456 - val_loss: 1046777.9702\n",
      "Epoch 2473/5000\n",
      "134/134 [==============================] - 0s 266us/step - loss: 418449.6721 - val_loss: 368511.5233\n",
      "Epoch 2474/5000\n",
      "134/134 [==============================] - 0s 274us/step - loss: 439736.1201 - val_loss: 492053.2444\n",
      "Epoch 2475/5000\n",
      "134/134 [==============================] - 0s 264us/step - loss: 440602.5575 - val_loss: 340144.8232\n",
      "Epoch 2476/5000\n",
      "134/134 [==============================] - 0s 276us/step - loss: 405292.5273 - val_loss: 352098.6469\n",
      "Epoch 2477/5000\n",
      "134/134 [==============================] - 0s 273us/step - loss: 456464.4357 - val_loss: 495814.1716\n",
      "Epoch 2478/5000\n",
      "134/134 [==============================] - 0s 266us/step - loss: 388315.0583 - val_loss: 380199.3554\n",
      "Epoch 2479/5000\n",
      "134/134 [==============================] - 0s 265us/step - loss: 391100.1594 - val_loss: 441966.1791\n",
      "Epoch 2480/5000\n",
      "134/134 [==============================] - 0s 261us/step - loss: 351526.4720 - val_loss: 327200.0131\n",
      "Epoch 2481/5000\n",
      "134/134 [==============================] - 0s 293us/step - loss: 345432.9906 - val_loss: 323951.8969\n",
      "Epoch 2482/5000\n",
      "134/134 [==============================] - 0s 278us/step - loss: 342930.9893 - val_loss: 351740.5550\n",
      "Epoch 2483/5000\n",
      "134/134 [==============================] - 0s 268us/step - loss: 362551.0264 - val_loss: 334160.6021\n",
      "Epoch 2484/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 347931.3753 - val_loss: 394285.2659\n",
      "Epoch 2485/5000\n",
      "134/134 [==============================] - 0s 284us/step - loss: 400554.2660 - val_loss: 705266.2966\n",
      "Epoch 2486/5000\n",
      "134/134 [==============================] - 0s 292us/step - loss: 420158.5882 - val_loss: 454078.0382\n",
      "Epoch 2487/5000\n",
      "134/134 [==============================] - 0s 301us/step - loss: 358723.6653 - val_loss: 327644.2878\n",
      "Epoch 2488/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 333799.3273 - val_loss: 318097.7500\n",
      "Epoch 2489/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 326499.9960 - val_loss: 345348.0131\n",
      "Epoch 2490/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 332273.3946 - val_loss: 447772.6437\n",
      "Epoch 2491/5000\n",
      "134/134 [==============================] - 0s 325us/step - loss: 440714.7295 - val_loss: 419036.0802\n",
      "Epoch 2492/5000\n",
      "134/134 [==============================] - 0s 271us/step - loss: 379876.0958 - val_loss: 410952.1189\n",
      "Epoch 2493/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 286us/step - loss: 380268.7873 - val_loss: 320668.0933\n",
      "Epoch 2494/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 359220.9774 - val_loss: 329263.7845\n",
      "Epoch 2495/5000\n",
      "134/134 [==============================] - 0s 304us/step - loss: 343567.0662 - val_loss: 419936.3713\n",
      "Epoch 2496/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 444469.3617 - val_loss: 370490.6516\n",
      "Epoch 2497/5000\n",
      "134/134 [==============================] - 0s 263us/step - loss: 389984.2046 - val_loss: 334086.4664\n",
      "Epoch 2498/5000\n",
      "134/134 [==============================] - 0s 266us/step - loss: 336240.4982 - val_loss: 348033.4916\n",
      "Epoch 2499/5000\n",
      "134/134 [==============================] - 0s 276us/step - loss: 355776.4963 - val_loss: 335076.5910\n",
      "Epoch 2500/5000\n",
      "134/134 [==============================] - 0s 259us/step - loss: 398790.2171 - val_loss: 379996.9007\n",
      "Epoch 2501/5000\n",
      "134/134 [==============================] - 0s 278us/step - loss: 353926.5997 - val_loss: 399690.4571\n",
      "Epoch 2502/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 345182.9054 - val_loss: 356597.6259\n",
      "Epoch 2503/5000\n",
      "134/134 [==============================] - 0s 276us/step - loss: 386011.7013 - val_loss: 346389.2952\n",
      "Epoch 2504/5000\n",
      "134/134 [==============================] - 0s 294us/step - loss: 346786.3148 - val_loss: 327056.2952\n",
      "Epoch 2505/5000\n",
      "134/134 [==============================] - 0s 259us/step - loss: 334783.4797 - val_loss: 325970.4594\n",
      "Epoch 2506/5000\n",
      "134/134 [==============================] - 0s 258us/step - loss: 351046.0480 - val_loss: 346301.0396\n",
      "Epoch 2507/5000\n",
      "134/134 [==============================] - 0s 270us/step - loss: 347997.8424 - val_loss: 378298.6819\n",
      "Epoch 2508/5000\n",
      "134/134 [==============================] - 0s 260us/step - loss: 554581.7691 - val_loss: 674500.5280\n",
      "Epoch 2509/5000\n",
      "134/134 [==============================] - 0s 277us/step - loss: 523833.0839 - val_loss: 641561.9935\n",
      "Epoch 2510/5000\n",
      "134/134 [==============================] - 0s 261us/step - loss: 452491.7310 - val_loss: 461534.3759\n",
      "Epoch 2511/5000\n",
      "134/134 [==============================] - 0s 256us/step - loss: 391415.8124 - val_loss: 490517.7090\n",
      "Epoch 2512/5000\n",
      "134/134 [==============================] - 0s 278us/step - loss: 429269.3815 - val_loss: 340633.4692\n",
      "Epoch 2513/5000\n",
      "134/134 [==============================] - 0s 259us/step - loss: 340684.5515 - val_loss: 352008.7309\n",
      "Epoch 2514/5000\n",
      "134/134 [==============================] - 0s 253us/step - loss: 340700.7959 - val_loss: 570616.7855\n",
      "Epoch 2515/5000\n",
      "134/134 [==============================] - 0s 240us/step - loss: 375483.6370 - val_loss: 365056.3526\n",
      "Epoch 2516/5000\n",
      "134/134 [==============================] - 0s 231us/step - loss: 370656.3629 - val_loss: 467964.5313\n",
      "Epoch 2517/5000\n",
      "134/134 [==============================] - 0s 265us/step - loss: 391697.6238 - val_loss: 320670.9035\n",
      "Epoch 2518/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 327795.7634 - val_loss: 502819.0345\n",
      "Epoch 2519/5000\n",
      "134/134 [==============================] - 0s 272us/step - loss: 348341.9529 - val_loss: 322391.2192\n",
      "Epoch 2520/5000\n",
      "134/134 [==============================] - 0s 253us/step - loss: 327855.9272 - val_loss: 344156.0849\n",
      "Epoch 2521/5000\n",
      "134/134 [==============================] - 0s 267us/step - loss: 316852.9729 - val_loss: 444524.6418\n",
      "Epoch 2522/5000\n",
      "134/134 [==============================] - 0s 277us/step - loss: 344627.9453 - val_loss: 335068.6544\n",
      "Epoch 2523/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 328469.9036 - val_loss: 305130.9543\n",
      "Epoch 2524/5000\n",
      "134/134 [==============================] - 0s 264us/step - loss: 513164.9979 - val_loss: 350957.7192\n",
      "Epoch 2525/5000\n",
      "134/134 [==============================] - 0s 291us/step - loss: 368009.5960 - val_loss: 325462.4897\n",
      "Epoch 2526/5000\n",
      "134/134 [==============================] - 0s 266us/step - loss: 315800.6345 - val_loss: 308348.6241\n",
      "Epoch 2527/5000\n",
      "134/134 [==============================] - 0s 270us/step - loss: 301167.4669 - val_loss: 328933.5014\n",
      "Epoch 2528/5000\n",
      "134/134 [==============================] - 0s 292us/step - loss: 369639.9037 - val_loss: 354303.3587\n",
      "Epoch 2529/5000\n",
      "134/134 [==============================] - 0s 287us/step - loss: 343030.9590 - val_loss: 340363.9487\n",
      "Epoch 2530/5000\n",
      "134/134 [==============================] - 0s 277us/step - loss: 376393.5159 - val_loss: 338220.6213\n",
      "Epoch 2531/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 358613.3249 - val_loss: 314622.7612\n",
      "Epoch 2532/5000\n",
      "134/134 [==============================] - 0s 272us/step - loss: 318603.4260 - val_loss: 347459.8727\n",
      "Epoch 2533/5000\n",
      "134/134 [==============================] - 0s 278us/step - loss: 438798.6693 - val_loss: 332754.2027\n",
      "Epoch 2534/5000\n",
      "134/134 [==============================] - 0s 269us/step - loss: 346247.0984 - val_loss: 388397.9692\n",
      "Epoch 2535/5000\n",
      "134/134 [==============================] - 0s 262us/step - loss: 329047.1408 - val_loss: 424675.7761\n",
      "Epoch 2536/5000\n",
      "134/134 [==============================] - 0s 266us/step - loss: 343817.4925 - val_loss: 317671.4105\n",
      "Epoch 2537/5000\n",
      "134/134 [==============================] - 0s 271us/step - loss: 340485.0175 - val_loss: 305419.6213\n",
      "Epoch 2538/5000\n",
      "134/134 [==============================] - 0s 270us/step - loss: 317380.1143 - val_loss: 309270.3946\n",
      "Epoch 2539/5000\n",
      "134/134 [==============================] - 0s 260us/step - loss: 304407.5822 - val_loss: 301229.4753\n",
      "Epoch 2540/5000\n",
      "134/134 [==============================] - 0s 268us/step - loss: 305911.2967 - val_loss: 357436.3321\n",
      "Epoch 2541/5000\n",
      "134/134 [==============================] - 0s 277us/step - loss: 322983.2430 - val_loss: 319261.5401\n",
      "Epoch 2542/5000\n",
      "134/134 [==============================] - 0s 261us/step - loss: 393165.2882 - val_loss: 307397.8452\n",
      "Epoch 2543/5000\n",
      "134/134 [==============================] - 0s 266us/step - loss: 330136.1102 - val_loss: 351436.3647\n",
      "Epoch 2544/5000\n",
      "134/134 [==============================] - 0s 290us/step - loss: 331230.6201 - val_loss: 378504.0942\n",
      "Epoch 2545/5000\n",
      "134/134 [==============================] - 0s 254us/step - loss: 450986.1210 - val_loss: 570880.7430\n",
      "Epoch 2546/5000\n",
      "134/134 [==============================] - 0s 259us/step - loss: 462489.2952 - val_loss: 1100348.9646\n",
      "Epoch 2547/5000\n",
      "134/134 [==============================] - 0s 269us/step - loss: 537228.8598 - val_loss: 368279.7948\n",
      "Epoch 2548/5000\n",
      "134/134 [==============================] - 0s 266us/step - loss: 352830.6151 - val_loss: 451856.9431\n",
      "Epoch 2549/5000\n",
      "134/134 [==============================] - 0s 283us/step - loss: 539662.9665 - val_loss: 443666.9263\n",
      "Epoch 2550/5000\n",
      "134/134 [==============================] - 0s 268us/step - loss: 379223.5535 - val_loss: 880345.8638\n",
      "Epoch 2551/5000\n",
      "134/134 [==============================] - 0s 278us/step - loss: 479923.8181 - val_loss: 300434.0616\n",
      "Epoch 2552/5000\n",
      "134/134 [==============================] - 0s 277us/step - loss: 300315.5310 - val_loss: 294872.2855\n",
      "Epoch 2553/5000\n",
      "134/134 [==============================] - 0s 269us/step - loss: 304112.0371 - val_loss: 293492.8125\n",
      "Epoch 2554/5000\n",
      "134/134 [==============================] - 0s 282us/step - loss: 327605.9326 - val_loss: 316711.1427\n",
      "Epoch 2555/5000\n",
      "134/134 [==============================] - 0s 277us/step - loss: 308503.8284 - val_loss: 287338.6581\n",
      "Epoch 2556/5000\n",
      "134/134 [==============================] - 0s 265us/step - loss: 295419.5122 - val_loss: 329756.4487\n",
      "Epoch 2557/5000\n",
      "134/134 [==============================] - 0s 278us/step - loss: 318894.5839 - val_loss: 344437.1521\n",
      "Epoch 2558/5000\n",
      "134/134 [==============================] - 0s 273us/step - loss: 342879.4808 - val_loss: 299391.7673\n",
      "Epoch 2559/5000\n",
      "134/134 [==============================] - 0s 260us/step - loss: 346964.7035 - val_loss: 301215.9627\n",
      "Epoch 2560/5000\n",
      "134/134 [==============================] - 0s 270us/step - loss: 364608.1446 - val_loss: 402863.9445\n",
      "Epoch 2561/5000\n",
      "134/134 [==============================] - 0s 267us/step - loss: 386637.5978 - val_loss: 330821.6119\n",
      "Epoch 2562/5000\n",
      "134/134 [==============================] - 0s 270us/step - loss: 379586.1934 - val_loss: 319930.5285\n",
      "Epoch 2563/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 278us/step - loss: 385386.9878 - val_loss: 335306.1353\n",
      "Epoch 2564/5000\n",
      "134/134 [==============================] - 0s 266us/step - loss: 403941.9906 - val_loss: 367060.1674\n",
      "Epoch 2565/5000\n",
      "134/134 [==============================] - 0s 275us/step - loss: 363059.1252 - val_loss: 280167.5714\n",
      "Epoch 2566/5000\n",
      "134/134 [==============================] - 0s 275us/step - loss: 295486.6861 - val_loss: 301804.1835\n",
      "Epoch 2567/5000\n",
      "134/134 [==============================] - 0s 287us/step - loss: 303008.3818 - val_loss: 370913.4422\n",
      "Epoch 2568/5000\n",
      "134/134 [==============================] - 0s 267us/step - loss: 337425.6082 - val_loss: 579554.3731\n",
      "Epoch 2569/5000\n",
      "134/134 [==============================] - 0s 261us/step - loss: 419693.0237 - val_loss: 346520.3139\n",
      "Epoch 2570/5000\n",
      "134/134 [==============================] - 0s 264us/step - loss: 354538.6971 - val_loss: 264954.8088\n",
      "Epoch 2571/5000\n",
      "134/134 [==============================] - 0s 270us/step - loss: 272974.4148 - val_loss: 271566.9356\n",
      "Epoch 2572/5000\n",
      "134/134 [==============================] - 0s 257us/step - loss: 267981.4456 - val_loss: 266586.6819\n",
      "Epoch 2573/5000\n",
      "134/134 [==============================] - 0s 261us/step - loss: 294202.2941 - val_loss: 363865.3139\n",
      "Epoch 2574/5000\n",
      "134/134 [==============================] - 0s 258us/step - loss: 268782.0301 - val_loss: 258647.7687\n",
      "Epoch 2575/5000\n",
      "134/134 [==============================] - 0s 266us/step - loss: 267187.5339 - val_loss: 284592.2551\n",
      "Epoch 2576/5000\n",
      "134/134 [==============================] - 0s 276us/step - loss: 279327.9598 - val_loss: 357954.6101\n",
      "Epoch 2577/5000\n",
      "134/134 [==============================] - 0s 257us/step - loss: 310546.9973 - val_loss: 276179.4361\n",
      "Epoch 2578/5000\n",
      "134/134 [==============================] - 0s 264us/step - loss: 362383.7711 - val_loss: 353007.9785\n",
      "Epoch 2579/5000\n",
      "134/134 [==============================] - 0s 268us/step - loss: 331296.4953 - val_loss: 289590.8750\n",
      "Epoch 2580/5000\n",
      "134/134 [==============================] - 0s 257us/step - loss: 350171.6994 - val_loss: 602484.2108\n",
      "Epoch 2581/5000\n",
      "134/134 [==============================] - 0s 259us/step - loss: 391693.0835 - val_loss: 519875.1968\n",
      "Epoch 2582/5000\n",
      "134/134 [==============================] - 0s 271us/step - loss: 314083.1142 - val_loss: 299726.4725\n",
      "Epoch 2583/5000\n",
      "134/134 [==============================] - 0s 264us/step - loss: 609454.9705 - val_loss: 361694.2271\n",
      "Epoch 2584/5000\n",
      "134/134 [==============================] - 0s 262us/step - loss: 282102.2514 - val_loss: 292613.5550\n",
      "Epoch 2585/5000\n",
      "134/134 [==============================] - 0s 279us/step - loss: 290244.7819 - val_loss: 288352.3671\n",
      "Epoch 2586/5000\n",
      "134/134 [==============================] - 0s 273us/step - loss: 264458.5255 - val_loss: 249785.5998\n",
      "Epoch 2587/5000\n",
      "134/134 [==============================] - 0s 274us/step - loss: 296003.7246 - val_loss: 398897.9925\n",
      "Epoch 2588/5000\n",
      "134/134 [==============================] - 0s 271us/step - loss: 317601.5239 - val_loss: 244456.0625\n",
      "Epoch 2589/5000\n",
      "134/134 [==============================] - 0s 263us/step - loss: 277194.5262 - val_loss: 242880.5765\n",
      "Epoch 2590/5000\n",
      "134/134 [==============================] - 0s 287us/step - loss: 259245.7270 - val_loss: 237286.2827\n",
      "Epoch 2591/5000\n",
      "134/134 [==============================] - 0s 275us/step - loss: 275239.1356 - val_loss: 265705.6926\n",
      "Epoch 2592/5000\n",
      "134/134 [==============================] - 0s 274us/step - loss: 308022.0700 - val_loss: 293522.5709\n",
      "Epoch 2593/5000\n",
      "134/134 [==============================] - 0s 283us/step - loss: 358066.1886 - val_loss: 311996.7696\n",
      "Epoch 2594/5000\n",
      "134/134 [==============================] - 0s 274us/step - loss: 270043.2472 - val_loss: 249649.6353\n",
      "Epoch 2595/5000\n",
      "134/134 [==============================] - 0s 262us/step - loss: 275677.0655 - val_loss: 257021.9151\n",
      "Epoch 2596/5000\n",
      "134/134 [==============================] - 0s 261us/step - loss: 241739.5223 - val_loss: 249944.5749\n",
      "Epoch 2597/5000\n",
      "134/134 [==============================] - 0s 271us/step - loss: 243484.0437 - val_loss: 237053.8368\n",
      "Epoch 2598/5000\n",
      "134/134 [==============================] - 0s 269us/step - loss: 245334.7456 - val_loss: 253027.9716\n",
      "Epoch 2599/5000\n",
      "134/134 [==============================] - 0s 275us/step - loss: 256801.0573 - val_loss: 276505.4548\n",
      "Epoch 2600/5000\n",
      "134/134 [==============================] - 0s 261us/step - loss: 276346.1449 - val_loss: 258030.1432\n",
      "Epoch 2601/5000\n",
      "134/134 [==============================] - 0s 270us/step - loss: 290510.9664 - val_loss: 250380.8610\n",
      "Epoch 2602/5000\n",
      "134/134 [==============================] - 0s 264us/step - loss: 258265.2182 - val_loss: 293987.3708\n",
      "Epoch 2603/5000\n",
      "134/134 [==============================] - 0s 275us/step - loss: 434561.1786 - val_loss: 274972.1936\n",
      "Epoch 2604/5000\n",
      "134/134 [==============================] - 0s 284us/step - loss: 372620.7027 - val_loss: 273414.3638\n",
      "Epoch 2605/5000\n",
      "134/134 [==============================] - 0s 261us/step - loss: 281292.8505 - val_loss: 244853.1996\n",
      "Epoch 2606/5000\n",
      "134/134 [==============================] - 0s 267us/step - loss: 249260.2113 - val_loss: 394875.7915\n",
      "Epoch 2607/5000\n",
      "134/134 [==============================] - 0s 251us/step - loss: 384342.5527 - val_loss: 512629.3405\n",
      "Epoch 2608/5000\n",
      "134/134 [==============================] - 0s 262us/step - loss: 292996.5851 - val_loss: 245117.6551\n",
      "Epoch 2609/5000\n",
      "134/134 [==============================] - 0s 284us/step - loss: 234392.4156 - val_loss: 230031.1821\n",
      "Epoch 2610/5000\n",
      "134/134 [==============================] - 0s 264us/step - loss: 230629.4882 - val_loss: 222753.9515\n",
      "Epoch 2611/5000\n",
      "134/134 [==============================] - 0s 269us/step - loss: 225869.8853 - val_loss: 240533.9576\n",
      "Epoch 2612/5000\n",
      "134/134 [==============================] - 0s 269us/step - loss: 305415.7574 - val_loss: 241634.0273\n",
      "Epoch 2613/5000\n",
      "134/134 [==============================] - 0s 258us/step - loss: 229396.0068 - val_loss: 339780.6213\n",
      "Epoch 2614/5000\n",
      "134/134 [==============================] - 0s 265us/step - loss: 295388.1535 - val_loss: 236615.4963\n",
      "Epoch 2615/5000\n",
      "134/134 [==============================] - 0s 259us/step - loss: 250116.0378 - val_loss: 282397.4235\n",
      "Epoch 2616/5000\n",
      "134/134 [==============================] - 0s 297us/step - loss: 291212.1761 - val_loss: 297152.7444\n",
      "Epoch 2617/5000\n",
      "134/134 [==============================] - 0s 272us/step - loss: 244819.3438 - val_loss: 584819.7176\n",
      "Epoch 2618/5000\n",
      "134/134 [==============================] - 0s 294us/step - loss: 397641.1166 - val_loss: 277907.6493\n",
      "Epoch 2619/5000\n",
      "134/134 [==============================] - 0s 383us/step - loss: 265426.8371 - val_loss: 244838.6660\n",
      "Epoch 2620/5000\n",
      "134/134 [==============================] - 0s 366us/step - loss: 272233.1216 - val_loss: 239031.0480\n",
      "Epoch 2621/5000\n",
      "134/134 [==============================] - 0s 353us/step - loss: 238952.0401 - val_loss: 431971.0672\n",
      "Epoch 2622/5000\n",
      "134/134 [==============================] - 0s 332us/step - loss: 283125.5857 - val_loss: 253553.4272\n",
      "Epoch 2623/5000\n",
      "134/134 [==============================] - 0s 292us/step - loss: 275070.9017 - val_loss: 236024.3666\n",
      "Epoch 2624/5000\n",
      "134/134 [==============================] - 0s 292us/step - loss: 232758.1327 - val_loss: 218223.0294\n",
      "Epoch 2625/5000\n",
      "134/134 [==============================] - 0s 258us/step - loss: 247505.3605 - val_loss: 245486.5483\n",
      "Epoch 2626/5000\n",
      "134/134 [==============================] - 0s 267us/step - loss: 248200.7071 - val_loss: 288164.4860\n",
      "Epoch 2627/5000\n",
      "134/134 [==============================] - 0s 265us/step - loss: 285176.3728 - val_loss: 237381.8811\n",
      "Epoch 2628/5000\n",
      "134/134 [==============================] - 0s 255us/step - loss: 237741.8855 - val_loss: 255530.7304\n",
      "Epoch 2629/5000\n",
      "134/134 [==============================] - 0s 270us/step - loss: 242824.8824 - val_loss: 267813.4324\n",
      "Epoch 2630/5000\n",
      "134/134 [==============================] - 0s 262us/step - loss: 319584.2417 - val_loss: 292365.7463\n",
      "Epoch 2631/5000\n",
      "134/134 [==============================] - 0s 263us/step - loss: 292769.2423 - val_loss: 255655.6196\n",
      "Epoch 2632/5000\n",
      "134/134 [==============================] - 0s 260us/step - loss: 328231.0885 - val_loss: 263434.1283\n",
      "Epoch 2633/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 278us/step - loss: 269328.0675 - val_loss: 226135.9077\n",
      "Epoch 2634/5000\n",
      "134/134 [==============================] - 0s 279us/step - loss: 259769.7114 - val_loss: 237941.4212\n",
      "Epoch 2635/5000\n",
      "134/134 [==============================] - 0s 260us/step - loss: 272925.4645 - val_loss: 249191.3577\n",
      "Epoch 2636/5000\n",
      "134/134 [==============================] - 0s 267us/step - loss: 235629.2724 - val_loss: 272178.8125\n",
      "Epoch 2637/5000\n",
      "134/134 [==============================] - 0s 299us/step - loss: 236070.9416 - val_loss: 251971.9907\n",
      "Epoch 2638/5000\n",
      "134/134 [==============================] - 0s 276us/step - loss: 274704.3251 - val_loss: 251357.3960\n",
      "Epoch 2639/5000\n",
      "134/134 [==============================] - 0s 275us/step - loss: 338637.5065 - val_loss: 258044.7085\n",
      "Epoch 2640/5000\n",
      "134/134 [==============================] - 0s 265us/step - loss: 322953.1608 - val_loss: 306091.0135\n",
      "Epoch 2641/5000\n",
      "134/134 [==============================] - 0s 266us/step - loss: 279857.6294 - val_loss: 363472.5065\n",
      "Epoch 2642/5000\n",
      "134/134 [==============================] - 0s 270us/step - loss: 507945.3324 - val_loss: 228175.3596\n",
      "Epoch 2643/5000\n",
      "134/134 [==============================] - 0s 272us/step - loss: 236773.5308 - val_loss: 387290.6385\n",
      "Epoch 2644/5000\n",
      "134/134 [==============================] - 0s 279us/step - loss: 355078.1574 - val_loss: 344648.9935\n",
      "Epoch 2645/5000\n",
      "134/134 [==============================] - 0s 293us/step - loss: 253319.2029 - val_loss: 224282.6180\n",
      "Epoch 2646/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 240858.4158 - val_loss: 211923.1602\n",
      "Epoch 2647/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 221374.2321 - val_loss: 217534.5569\n",
      "Epoch 2648/5000\n",
      "134/134 [==============================] - 0s 289us/step - loss: 210478.6672 - val_loss: 252474.1553\n",
      "Epoch 2649/5000\n",
      "134/134 [==============================] - 0s 284us/step - loss: 267286.9715 - val_loss: 220644.2717\n",
      "Epoch 2650/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 272382.3903 - val_loss: 386994.0942\n",
      "Epoch 2651/5000\n",
      "134/134 [==============================] - 0s 304us/step - loss: 303872.1306 - val_loss: 296201.6077\n",
      "Epoch 2652/5000\n",
      "134/134 [==============================] - 0s 283us/step - loss: 267940.6729 - val_loss: 206032.8069\n",
      "Epoch 2653/5000\n",
      "134/134 [==============================] - 0s 288us/step - loss: 226300.5166 - val_loss: 232204.4039\n",
      "Epoch 2654/5000\n",
      "134/134 [==============================] - 0s 279us/step - loss: 228322.6634 - val_loss: 212561.2766\n",
      "Epoch 2655/5000\n",
      "134/134 [==============================] - 0s 299us/step - loss: 212539.1207 - val_loss: 239208.0555\n",
      "Epoch 2656/5000\n",
      "134/134 [==============================] - 0s 294us/step - loss: 241583.6013 - val_loss: 221870.8013\n",
      "Epoch 2657/5000\n",
      "134/134 [==============================] - 0s 276us/step - loss: 256513.1114 - val_loss: 494913.9165\n",
      "Epoch 2658/5000\n",
      "134/134 [==============================] - 0s 251us/step - loss: 305085.5546 - val_loss: 273763.3312\n",
      "Epoch 2659/5000\n",
      "134/134 [==============================] - 0s 275us/step - loss: 259275.3029 - val_loss: 441374.3396\n",
      "Epoch 2660/5000\n",
      "134/134 [==============================] - 0s 267us/step - loss: 357534.9323 - val_loss: 232363.5369\n",
      "Epoch 2661/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 252168.2378 - val_loss: 293038.3200\n",
      "Epoch 2662/5000\n",
      "134/134 [==============================] - 0s 336us/step - loss: 224487.5928 - val_loss: 234506.3036\n",
      "Epoch 2663/5000\n",
      "134/134 [==============================] - 0s 353us/step - loss: 213897.8859 - val_loss: 226706.0854\n",
      "Epoch 2664/5000\n",
      "134/134 [==============================] - 0s 344us/step - loss: 226377.7974 - val_loss: 219656.4132\n",
      "Epoch 2665/5000\n",
      "134/134 [==============================] - 0s 335us/step - loss: 216142.3093 - val_loss: 281756.1819\n",
      "Epoch 2666/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 277073.5231 - val_loss: 254799.4354\n",
      "Epoch 2667/5000\n",
      "134/134 [==============================] - 0s 289us/step - loss: 349939.0860 - val_loss: 303707.2239\n",
      "Epoch 2668/5000\n",
      "134/134 [==============================] - 0s 260us/step - loss: 385194.3813 - val_loss: 361324.8890\n",
      "Epoch 2669/5000\n",
      "134/134 [==============================] - 0s 273us/step - loss: 358804.5512 - val_loss: 281969.1465\n",
      "Epoch 2670/5000\n",
      "134/134 [==============================] - 0s 261us/step - loss: 365255.3554 - val_loss: 266437.5597\n",
      "Epoch 2671/5000\n",
      "134/134 [==============================] - 0s 281us/step - loss: 245143.0473 - val_loss: 210786.0471\n",
      "Epoch 2672/5000\n",
      "134/134 [==============================] - 0s 262us/step - loss: 226365.9958 - val_loss: 257844.6623\n",
      "Epoch 2673/5000\n",
      "134/134 [==============================] - 0s 260us/step - loss: 247274.5855 - val_loss: 249360.7920\n",
      "Epoch 2674/5000\n",
      "134/134 [==============================] - 0s 265us/step - loss: 243384.0132 - val_loss: 584763.1091\n",
      "Epoch 2675/5000\n",
      "134/134 [==============================] - 0s 268us/step - loss: 335329.5142 - val_loss: 551810.0886\n",
      "Epoch 2676/5000\n",
      "134/134 [==============================] - 0s 266us/step - loss: 389802.7539 - val_loss: 250918.9319\n",
      "Epoch 2677/5000\n",
      "134/134 [==============================] - 0s 282us/step - loss: 254329.4844 - val_loss: 403684.6175\n",
      "Epoch 2678/5000\n",
      "134/134 [==============================] - 0s 261us/step - loss: 290442.1764 - val_loss: 208990.8673\n",
      "Epoch 2679/5000\n",
      "134/134 [==============================] - 0s 265us/step - loss: 223008.4328 - val_loss: 203499.5695\n",
      "Epoch 2680/5000\n",
      "134/134 [==============================] - 0s 285us/step - loss: 211351.3277 - val_loss: 215686.5382\n",
      "Epoch 2681/5000\n",
      "134/134 [==============================] - 0s 285us/step - loss: 221256.8231 - val_loss: 200605.8487\n",
      "Epoch 2682/5000\n",
      "134/134 [==============================] - 0s 298us/step - loss: 224290.2183 - val_loss: 243776.7920\n",
      "Epoch 2683/5000\n",
      "134/134 [==============================] - 0s 291us/step - loss: 245643.4906 - val_loss: 232605.8186\n",
      "Epoch 2684/5000\n",
      "134/134 [==============================] - 0s 283us/step - loss: 216780.2520 - val_loss: 261781.7565\n",
      "Epoch 2685/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 208543.5571 - val_loss: 204462.3109\n",
      "Epoch 2686/5000\n",
      "134/134 [==============================] - 0s 293us/step - loss: 409356.8815 - val_loss: 254336.1814\n",
      "Epoch 2687/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 264399.8872 - val_loss: 328398.9249\n",
      "Epoch 2688/5000\n",
      "134/134 [==============================] - 0s 266us/step - loss: 270346.3245 - val_loss: 250097.8473\n",
      "Epoch 2689/5000\n",
      "134/134 [==============================] - 0s 262us/step - loss: 228992.1932 - val_loss: 262975.7906\n",
      "Epoch 2690/5000\n",
      "134/134 [==============================] - 0s 270us/step - loss: 227938.8303 - val_loss: 226275.0410\n",
      "Epoch 2691/5000\n",
      "134/134 [==============================] - 0s 266us/step - loss: 220085.5826 - val_loss: 199849.6712\n",
      "Epoch 2692/5000\n",
      "134/134 [==============================] - 0s 281us/step - loss: 200505.1743 - val_loss: 210528.6793\n",
      "Epoch 2693/5000\n",
      "134/134 [==============================] - 0s 274us/step - loss: 199512.9538 - val_loss: 196915.7223\n",
      "Epoch 2694/5000\n",
      "134/134 [==============================] - 0s 266us/step - loss: 208993.1528 - val_loss: 204949.3540\n",
      "Epoch 2695/5000\n",
      "134/134 [==============================] - 0s 271us/step - loss: 229986.4972 - val_loss: 438304.6800\n",
      "Epoch 2696/5000\n",
      "134/134 [==============================] - 0s 279us/step - loss: 277183.5800 - val_loss: 226626.7687\n",
      "Epoch 2697/5000\n",
      "134/134 [==============================] - 0s 264us/step - loss: 250283.1816 - val_loss: 231904.6591\n",
      "Epoch 2698/5000\n",
      "134/134 [==============================] - 0s 318us/step - loss: 245649.3612 - val_loss: 244047.1215\n",
      "Epoch 2699/5000\n",
      "134/134 [==============================] - 0s 362us/step - loss: 288735.9229 - val_loss: 263371.5170\n",
      "Epoch 2700/5000\n",
      "134/134 [==============================] - 0s 321us/step - loss: 428323.4522 - val_loss: 658030.7444\n",
      "Epoch 2701/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 408512.5182 - val_loss: 808465.4832\n",
      "Epoch 2702/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 291658.5712 - val_loss: 288197.4291\n",
      "Epoch 2703/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 293us/step - loss: 238011.4667 - val_loss: 313083.4450\n",
      "Epoch 2704/5000\n",
      "134/134 [==============================] - 0s 292us/step - loss: 239857.5714 - val_loss: 208113.3312\n",
      "Epoch 2705/5000\n",
      "134/134 [==============================] - 0s 284us/step - loss: 218737.1677 - val_loss: 209305.8983\n",
      "Epoch 2706/5000\n",
      "134/134 [==============================] - 0s 248us/step - loss: 221335.6902 - val_loss: 223922.2104\n",
      "Epoch 2707/5000\n",
      "134/134 [==============================] - 0s 557us/step - loss: 222743.1687 - val_loss: 200894.5420\n",
      "Epoch 2708/5000\n",
      "134/134 [==============================] - 0s 398us/step - loss: 201551.9500 - val_loss: 276200.7985\n",
      "Epoch 2709/5000\n",
      "134/134 [==============================] - 0s 280us/step - loss: 217925.5531 - val_loss: 193434.8118\n",
      "Epoch 2710/5000\n",
      "134/134 [==============================] - 0s 269us/step - loss: 205527.0764 - val_loss: 208171.2183\n",
      "Epoch 2711/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 208526.1374 - val_loss: 205689.0191\n",
      "Epoch 2712/5000\n",
      "134/134 [==============================] - 0s 273us/step - loss: 242948.5082 - val_loss: 204409.8074\n",
      "Epoch 2713/5000\n",
      "134/134 [==============================] - 0s 230us/step - loss: 227712.0910 - val_loss: 312273.3871\n",
      "Epoch 2714/5000\n",
      "134/134 [==============================] - 0s 237us/step - loss: 409084.1852 - val_loss: 826323.1716\n",
      "Epoch 2715/5000\n",
      "134/134 [==============================] - 0s 243us/step - loss: 417506.5398 - val_loss: 223506.0466\n",
      "Epoch 2716/5000\n",
      "134/134 [==============================] - 0s 257us/step - loss: 245123.3828 - val_loss: 197167.6772\n",
      "Epoch 2717/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 195864.8861 - val_loss: 189150.4925\n",
      "Epoch 2718/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 197309.8112 - val_loss: 238308.1842\n",
      "Epoch 2719/5000\n",
      "134/134 [==============================] - 0s 349us/step - loss: 208527.2055 - val_loss: 221975.8876\n",
      "Epoch 2720/5000\n",
      "134/134 [==============================] - 0s 321us/step - loss: 210812.4748 - val_loss: 230366.4641\n",
      "Epoch 2721/5000\n",
      "134/134 [==============================] - 0s 277us/step - loss: 234092.2263 - val_loss: 433014.2155\n",
      "Epoch 2722/5000\n",
      "134/134 [==============================] - 0s 264us/step - loss: 324385.0501 - val_loss: 346554.4534\n",
      "Epoch 2723/5000\n",
      "134/134 [==============================] - 0s 260us/step - loss: 239643.8237 - val_loss: 204461.5618\n",
      "Epoch 2724/5000\n",
      "134/134 [==============================] - 0s 287us/step - loss: 206366.6672 - val_loss: 204980.9709\n",
      "Epoch 2725/5000\n",
      "134/134 [==============================] - 0s 297us/step - loss: 197620.8783 - val_loss: 194827.6455\n",
      "Epoch 2726/5000\n",
      "134/134 [==============================] - 0s 263us/step - loss: 206793.5292 - val_loss: 331075.8302\n",
      "Epoch 2727/5000\n",
      "134/134 [==============================] - 0s 276us/step - loss: 237435.7761 - val_loss: 216940.5009\n",
      "Epoch 2728/5000\n",
      "134/134 [==============================] - 0s 272us/step - loss: 245152.6271 - val_loss: 484466.2010\n",
      "Epoch 2729/5000\n",
      "134/134 [==============================] - 0s 282us/step - loss: 310284.0883 - val_loss: 236279.6385\n",
      "Epoch 2730/5000\n",
      "134/134 [==============================] - 0s 284us/step - loss: 231054.2492 - val_loss: 208683.2458\n",
      "Epoch 2731/5000\n",
      "134/134 [==============================] - 0s 270us/step - loss: 213119.9960 - val_loss: 233213.4249\n",
      "Epoch 2732/5000\n",
      "134/134 [==============================] - 0s 269us/step - loss: 214639.4599 - val_loss: 240132.8232\n",
      "Epoch 2733/5000\n",
      "134/134 [==============================] - 0s 264us/step - loss: 218114.9067 - val_loss: 201695.6975\n",
      "Epoch 2734/5000\n",
      "134/134 [==============================] - 0s 300us/step - loss: 205908.6322 - val_loss: 205103.3389\n",
      "Epoch 2735/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 227143.8019 - val_loss: 262845.6346\n",
      "Epoch 2736/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 239884.4567 - val_loss: 274392.2164\n",
      "Epoch 2737/5000\n",
      "134/134 [==============================] - 0s 289us/step - loss: 223703.7018 - val_loss: 209089.9727\n",
      "Epoch 2738/5000\n",
      "134/134 [==============================] - 0s 338us/step - loss: 234642.7076 - val_loss: 300225.6880\n",
      "Epoch 2739/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 224413.0458 - val_loss: 229088.7346\n",
      "Epoch 2740/5000\n",
      "134/134 [==============================] - 0s 354us/step - loss: 240029.7840 - val_loss: 291280.4972\n",
      "Epoch 2741/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 236126.5652 - val_loss: 389614.7694\n",
      "Epoch 2742/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 287648.6491 - val_loss: 220240.1413\n",
      "Epoch 2743/5000\n",
      "134/134 [==============================] - 0s 287us/step - loss: 268141.3837 - val_loss: 374363.0224\n",
      "Epoch 2744/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 362004.3594 - val_loss: 335421.1119\n",
      "Epoch 2745/5000\n",
      "134/134 [==============================] - 0s 320us/step - loss: 231842.9714 - val_loss: 249480.1208\n",
      "Epoch 2746/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 225072.4086 - val_loss: 212720.9363\n",
      "Epoch 2747/5000\n",
      "134/134 [==============================] - 0s 319us/step - loss: 209114.1936 - val_loss: 242105.5807\n",
      "Epoch 2748/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 235083.7218 - val_loss: 232333.4226\n",
      "Epoch 2749/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 263776.2246 - val_loss: 322317.8941\n",
      "Epoch 2750/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 246928.1581 - val_loss: 399404.0905\n",
      "Epoch 2751/5000\n",
      "134/134 [==============================] - 0s 263us/step - loss: 248242.8871 - val_loss: 378463.6744\n",
      "Epoch 2752/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 242773.1222 - val_loss: 364265.2827\n",
      "Epoch 2753/5000\n",
      "134/134 [==============================] - 0s 295us/step - loss: 498708.2170 - val_loss: 862923.2388\n",
      "Epoch 2754/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 393994.3370 - val_loss: 438266.5410\n",
      "Epoch 2755/5000\n",
      "134/134 [==============================] - 0s 323us/step - loss: 320808.5098 - val_loss: 212885.1066\n",
      "Epoch 2756/5000\n",
      "134/134 [==============================] - 0s 315us/step - loss: 206288.6320 - val_loss: 188195.4716\n",
      "Epoch 2757/5000\n",
      "134/134 [==============================] - 0s 263us/step - loss: 194632.3316 - val_loss: 197614.4475\n",
      "Epoch 2758/5000\n",
      "134/134 [==============================] - 0s 253us/step - loss: 199097.0865 - val_loss: 191122.2670\n",
      "Epoch 2759/5000\n",
      "134/134 [==============================] - 0s 267us/step - loss: 190791.9378 - val_loss: 185594.6189\n",
      "Epoch 2760/5000\n",
      "134/134 [==============================] - 0s 265us/step - loss: 189829.6669 - val_loss: 185407.8363\n",
      "Epoch 2761/5000\n",
      "134/134 [==============================] - 0s 265us/step - loss: 189881.5717 - val_loss: 184849.8036\n",
      "Epoch 2762/5000\n",
      "134/134 [==============================] - 0s 256us/step - loss: 189078.4867 - val_loss: 192969.6777\n",
      "Epoch 2763/5000\n",
      "134/134 [==============================] - 0s 265us/step - loss: 204249.6919 - val_loss: 205215.6390\n",
      "Epoch 2764/5000\n",
      "134/134 [==============================] - 0s 268us/step - loss: 243698.4496 - val_loss: 207768.7414\n",
      "Epoch 2765/5000\n",
      "134/134 [==============================] - 0s 287us/step - loss: 268363.8920 - val_loss: 406536.8955\n",
      "Epoch 2766/5000\n",
      "134/134 [==============================] - 0s 292us/step - loss: 252348.0088 - val_loss: 196160.3594\n",
      "Epoch 2767/5000\n",
      "134/134 [==============================] - 0s 342us/step - loss: 200522.1207 - val_loss: 190627.6021\n",
      "Epoch 2768/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 212124.6737 - val_loss: 304315.7113\n",
      "Epoch 2769/5000\n",
      "134/134 [==============================] - 0s 285us/step - loss: 397342.6515 - val_loss: 339170.5385\n",
      "Epoch 2770/5000\n",
      "134/134 [==============================] - 0s 294us/step - loss: 287516.5661 - val_loss: 398647.5574\n",
      "Epoch 2771/5000\n",
      "134/134 [==============================] - 0s 272us/step - loss: 314724.8308 - val_loss: 644870.0355\n",
      "Epoch 2772/5000\n",
      "134/134 [==============================] - 0s 281us/step - loss: 345591.6388 - val_loss: 294708.3414\n",
      "Epoch 2773/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 300us/step - loss: 458012.5303 - val_loss: 258509.8386\n",
      "Epoch 2774/5000\n",
      "134/134 [==============================] - 0s 336us/step - loss: 263071.6603 - val_loss: 327941.0009\n",
      "Epoch 2775/5000\n",
      "134/134 [==============================] - 0s 271us/step - loss: 252297.7526 - val_loss: 337843.4846\n",
      "Epoch 2776/5000\n",
      "134/134 [==============================] - 0s 304us/step - loss: 258292.5521 - val_loss: 257832.9186\n",
      "Epoch 2777/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 202481.3389 - val_loss: 199601.4702\n",
      "Epoch 2778/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 194333.1654 - val_loss: 244586.6861\n",
      "Epoch 2779/5000\n",
      "134/134 [==============================] - 0s 519us/step - loss: 202934.0742 - val_loss: 214253.3699\n",
      "Epoch 2780/5000\n",
      "134/134 [==============================] - 0s 330us/step - loss: 224086.6212 - val_loss: 315523.3265\n",
      "Epoch 2781/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 285603.0749 - val_loss: 273164.8563\n",
      "Epoch 2782/5000\n",
      "134/134 [==============================] - 0s 284us/step - loss: 299307.4246 - val_loss: 214154.8064\n",
      "Epoch 2783/5000\n",
      "134/134 [==============================] - 0s 324us/step - loss: 250963.3601 - val_loss: 225055.7579\n",
      "Epoch 2784/5000\n",
      "134/134 [==============================] - 0s 317us/step - loss: 230752.1102 - val_loss: 218662.2761\n",
      "Epoch 2785/5000\n",
      "134/134 [==============================] - 0s 269us/step - loss: 227348.6793 - val_loss: 200624.9035\n",
      "Epoch 2786/5000\n",
      "134/134 [==============================] - 0s 276us/step - loss: 257014.0700 - val_loss: 352454.8022\n",
      "Epoch 2787/5000\n",
      "134/134 [==============================] - 0s 255us/step - loss: 268406.1180 - val_loss: 219542.4702\n",
      "Epoch 2788/5000\n",
      "134/134 [==============================] - 0s 255us/step - loss: 225213.8126 - val_loss: 213225.2421\n",
      "Epoch 2789/5000\n",
      "134/134 [==============================] - 0s 266us/step - loss: 317821.0663 - val_loss: 375039.2495\n",
      "Epoch 2790/5000\n",
      "134/134 [==============================] - 0s 272us/step - loss: 302173.9755 - val_loss: 263308.1726\n",
      "Epoch 2791/5000\n",
      "134/134 [==============================] - 0s 262us/step - loss: 306453.9496 - val_loss: 718458.1530\n",
      "Epoch 2792/5000\n",
      "134/134 [==============================] - 0s 754us/step - loss: 766383.7999 - val_loss: 295168.6152\n",
      "Epoch 2793/5000\n",
      "134/134 [==============================] - 0s 282us/step - loss: 244762.0139 - val_loss: 189667.4384\n",
      "Epoch 2794/5000\n",
      "134/134 [==============================] - 0s 275us/step - loss: 191842.0149 - val_loss: 185815.9165\n",
      "Epoch 2795/5000\n",
      "134/134 [==============================] - 0s 277us/step - loss: 187989.0499 - val_loss: 183319.7003\n",
      "Epoch 2796/5000\n",
      "134/134 [==============================] - 0s 295us/step - loss: 186201.7650 - val_loss: 190812.0212\n",
      "Epoch 2797/5000\n",
      "134/134 [==============================] - 0s 262us/step - loss: 189733.0698 - val_loss: 183728.2572\n",
      "Epoch 2798/5000\n",
      "134/134 [==============================] - 0s 283us/step - loss: 190546.2095 - val_loss: 283654.6007\n",
      "Epoch 2799/5000\n",
      "134/134 [==============================] - 0s 267us/step - loss: 292444.1706 - val_loss: 338627.3834\n",
      "Epoch 2800/5000\n",
      "134/134 [==============================] - 0s 260us/step - loss: 284762.9649 - val_loss: 218942.4881\n",
      "Epoch 2801/5000\n",
      "134/134 [==============================] - 0s 268us/step - loss: 208522.5761 - val_loss: 200273.0306\n",
      "Epoch 2802/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 289858.2673 - val_loss: 271471.9487\n",
      "Epoch 2803/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 241296.5168 - val_loss: 201875.7090\n",
      "Epoch 2804/5000\n",
      "134/134 [==============================] - 0s 281us/step - loss: 205141.7992 - val_loss: 188311.4291\n",
      "Epoch 2805/5000\n",
      "134/134 [==============================] - 0s 266us/step - loss: 198998.5924 - val_loss: 259964.3200\n",
      "Epoch 2806/5000\n",
      "134/134 [==============================] - 0s 291us/step - loss: 248755.8187 - val_loss: 204847.9965\n",
      "Epoch 2807/5000\n",
      "134/134 [==============================] - 0s 287us/step - loss: 199110.1859 - val_loss: 206453.1486\n",
      "Epoch 2808/5000\n",
      "134/134 [==============================] - 0s 299us/step - loss: 225511.4173 - val_loss: 235476.1152\n",
      "Epoch 2809/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 212406.7323 - val_loss: 211647.5945\n",
      "Epoch 2810/5000\n",
      "134/134 [==============================] - 0s 267us/step - loss: 267316.8492 - val_loss: 522944.3806\n",
      "Epoch 2811/5000\n",
      "134/134 [==============================] - 0s 289us/step - loss: 282281.2636 - val_loss: 239044.0499\n",
      "Epoch 2812/5000\n",
      "134/134 [==============================] - 0s 281us/step - loss: 234280.2870 - val_loss: 208380.0135\n",
      "Epoch 2813/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 209091.3910 - val_loss: 255411.7663\n",
      "Epoch 2814/5000\n",
      "134/134 [==============================] - 0s 282us/step - loss: 287729.7084 - val_loss: 237374.4445\n",
      "Epoch 2815/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 298819.7966 - val_loss: 201252.7486\n",
      "Epoch 2816/5000\n",
      "134/134 [==============================] - 0s 298us/step - loss: 230069.2036 - val_loss: 229569.4692\n",
      "Epoch 2817/5000\n",
      "134/134 [==============================] - 0s 300us/step - loss: 210102.6721 - val_loss: 190233.4137\n",
      "Epoch 2818/5000\n",
      "134/134 [==============================] - 0s 292us/step - loss: 188556.4261 - val_loss: 182715.3937\n",
      "Epoch 2819/5000\n",
      "134/134 [==============================] - 0s 273us/step - loss: 195014.8899 - val_loss: 228258.8988\n",
      "Epoch 2820/5000\n",
      "134/134 [==============================] - 0s 260us/step - loss: 195594.2687 - val_loss: 304294.3326\n",
      "Epoch 2821/5000\n",
      "134/134 [==============================] - 0s 282us/step - loss: 229673.0557 - val_loss: 474916.1213\n",
      "Epoch 2822/5000\n",
      "134/134 [==============================] - 0s 267us/step - loss: 353494.4948 - val_loss: 279243.7901\n",
      "Epoch 2823/5000\n",
      "134/134 [==============================] - 0s 334us/step - loss: 239272.0363 - val_loss: 322961.4300\n",
      "Epoch 2824/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 294083.0263 - val_loss: 251936.1870\n",
      "Epoch 2825/5000\n",
      "134/134 [==============================] - 0s 261us/step - loss: 243193.5794 - val_loss: 238760.1357\n",
      "Epoch 2826/5000\n",
      "134/134 [==============================] - 0s 276us/step - loss: 246638.0041 - val_loss: 266044.1516\n",
      "Epoch 2827/5000\n",
      "134/134 [==============================] - 0s 263us/step - loss: 217029.9471 - val_loss: 209372.1287\n",
      "Epoch 2828/5000\n",
      "134/134 [==============================] - 0s 267us/step - loss: 220055.3336 - val_loss: 208811.1735\n",
      "Epoch 2829/5000\n",
      "134/134 [==============================] - 0s 280us/step - loss: 211589.5896 - val_loss: 193696.5103\n",
      "Epoch 2830/5000\n",
      "134/134 [==============================] - 0s 259us/step - loss: 197674.8561 - val_loss: 302855.8876\n",
      "Epoch 2831/5000\n",
      "134/134 [==============================] - 0s 271us/step - loss: 353253.9941 - val_loss: 227408.0131\n",
      "Epoch 2832/5000\n",
      "134/134 [==============================] - 0s 284us/step - loss: 232106.0189 - val_loss: 189737.7568\n",
      "Epoch 2833/5000\n",
      "134/134 [==============================] - 0s 285us/step - loss: 204026.6959 - val_loss: 191917.4986\n",
      "Epoch 2834/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 200920.0681 - val_loss: 239429.7309\n",
      "Epoch 2835/5000\n",
      "134/134 [==============================] - 0s 325us/step - loss: 199473.5633 - val_loss: 212463.6161\n",
      "Epoch 2836/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 223072.7971 - val_loss: 219430.5191\n",
      "Epoch 2837/5000\n",
      "134/134 [==============================] - 0s 323us/step - loss: 340625.9050 - val_loss: 235635.7715\n",
      "Epoch 2838/5000\n",
      "134/134 [==============================] - 0s 324us/step - loss: 207758.6435 - val_loss: 181498.8531\n",
      "Epoch 2839/5000\n",
      "134/134 [==============================] - 0s 418us/step - loss: 189105.8987 - val_loss: 194588.3762\n",
      "Epoch 2840/5000\n",
      "134/134 [==============================] - 0s 392us/step - loss: 211578.5431 - val_loss: 189670.4109\n",
      "Epoch 2841/5000\n",
      "134/134 [==============================] - 0s 355us/step - loss: 205273.3871 - val_loss: 220830.4566\n",
      "Epoch 2842/5000\n",
      "134/134 [==============================] - 0s 319us/step - loss: 333177.2432 - val_loss: 267469.1350\n",
      "Epoch 2843/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 293us/step - loss: 260419.6180 - val_loss: 443816.0494\n",
      "Epoch 2844/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 240975.6280 - val_loss: 230053.3997\n",
      "Epoch 2845/5000\n",
      "134/134 [==============================] - 0s 283us/step - loss: 197273.8946 - val_loss: 275358.3069\n",
      "Epoch 2846/5000\n",
      "134/134 [==============================] - 0s 268us/step - loss: 285082.4238 - val_loss: 330130.2649\n",
      "Epoch 2847/5000\n",
      "134/134 [==============================] - 0s 268us/step - loss: 289312.8429 - val_loss: 219590.6493\n",
      "Epoch 2848/5000\n",
      "134/134 [==============================] - 0s 280us/step - loss: 212417.6068 - val_loss: 298079.0431\n",
      "Epoch 2849/5000\n",
      "134/134 [==============================] - 0s 274us/step - loss: 228462.1231 - val_loss: 181881.9806\n",
      "Epoch 2850/5000\n",
      "134/134 [==============================] - 0s 350us/step - loss: 195934.1519 - val_loss: 200777.6385\n",
      "Epoch 2851/5000\n",
      "134/134 [==============================] - 0s 273us/step - loss: 195090.7240 - val_loss: 186862.9328\n",
      "Epoch 2852/5000\n",
      "134/134 [==============================] - 0s 259us/step - loss: 213883.2149 - val_loss: 621940.3246\n",
      "Epoch 2853/5000\n",
      "134/134 [==============================] - 0s 264us/step - loss: 347650.6701 - val_loss: 208771.9405\n",
      "Epoch 2854/5000\n",
      "134/134 [==============================] - 0s 282us/step - loss: 218877.1579 - val_loss: 224175.6110\n",
      "Epoch 2855/5000\n",
      "134/134 [==============================] - 0s 285us/step - loss: 193046.5529 - val_loss: 389653.5793\n",
      "Epoch 2856/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 302474.4223 - val_loss: 284355.2351\n",
      "Epoch 2857/5000\n",
      "134/134 [==============================] - 0s 373us/step - loss: 225968.0458 - val_loss: 196850.7934\n",
      "Epoch 2858/5000\n",
      "134/134 [==============================] - 0s 372us/step - loss: 193003.5760 - val_loss: 183402.0737\n",
      "Epoch 2859/5000\n",
      "134/134 [==============================] - 0s 358us/step - loss: 184484.0388 - val_loss: 182267.6080\n",
      "Epoch 2860/5000\n",
      "134/134 [==============================] - 0s 347us/step - loss: 204416.2943 - val_loss: 199573.4139\n",
      "Epoch 2861/5000\n",
      "134/134 [==============================] - 0s 299us/step - loss: 230675.9357 - val_loss: 242665.5135\n",
      "Epoch 2862/5000\n",
      "134/134 [==============================] - 0s 318us/step - loss: 218330.6230 - val_loss: 206919.6196\n",
      "Epoch 2863/5000\n",
      "134/134 [==============================] - 0s 292us/step - loss: 212209.5049 - val_loss: 215192.7913\n",
      "Epoch 2864/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 226337.4101 - val_loss: 275516.6273\n",
      "Epoch 2865/5000\n",
      "134/134 [==============================] - 0s 290us/step - loss: 280127.9054 - val_loss: 240954.3302\n",
      "Epoch 2866/5000\n",
      "134/134 [==============================] - 0s 275us/step - loss: 258975.2130 - val_loss: 417280.7656\n",
      "Epoch 2867/5000\n",
      "134/134 [==============================] - 0s 257us/step - loss: 351415.6065 - val_loss: 823533.3526\n",
      "Epoch 2868/5000\n",
      "134/134 [==============================] - 0s 282us/step - loss: 337670.1787 - val_loss: 335880.9837\n",
      "Epoch 2869/5000\n",
      "134/134 [==============================] - 0s 285us/step - loss: 310347.9988 - val_loss: 211069.5406\n",
      "Epoch 2870/5000\n",
      "134/134 [==============================] - 0s 364us/step - loss: 191923.1115 - val_loss: 209809.2020\n",
      "Epoch 2871/5000\n",
      "134/134 [==============================] - 0s 371us/step - loss: 185911.2218 - val_loss: 187982.5928\n",
      "Epoch 2872/5000\n",
      "134/134 [==============================] - 0s 354us/step - loss: 188708.9626 - val_loss: 188154.0693\n",
      "Epoch 2873/5000\n",
      "134/134 [==============================] - 0s 362us/step - loss: 250301.5867 - val_loss: 256493.0350\n",
      "Epoch 2874/5000\n",
      "134/134 [==============================] - 0s 295us/step - loss: 201646.0791 - val_loss: 213399.7565\n",
      "Epoch 2875/5000\n",
      "134/134 [==============================] - 0s 274us/step - loss: 196216.7766 - val_loss: 188230.7465\n",
      "Epoch 2876/5000\n",
      "134/134 [==============================] - 0s 282us/step - loss: 204893.8224 - val_loss: 309283.3069\n",
      "Epoch 2877/5000\n",
      "134/134 [==============================] - 0s 262us/step - loss: 217924.9750 - val_loss: 205587.3174\n",
      "Epoch 2878/5000\n",
      "134/134 [==============================] - 0s 264us/step - loss: 231723.3968 - val_loss: 349551.1898\n",
      "Epoch 2879/5000\n",
      "134/134 [==============================] - 0s 297us/step - loss: 329604.5253 - val_loss: 355172.9977\n",
      "Epoch 2880/5000\n",
      "134/134 [==============================] - 0s 339us/step - loss: 253092.1119 - val_loss: 219429.2920\n",
      "Epoch 2881/5000\n",
      "134/134 [==============================] - 0s 262us/step - loss: 291214.3895 - val_loss: 789805.7640\n",
      "Epoch 2882/5000\n",
      "134/134 [==============================] - 0s 266us/step - loss: 501422.7517 - val_loss: 203825.4751\n",
      "Epoch 2883/5000\n",
      "134/134 [==============================] - 0s 286us/step - loss: 192252.9253 - val_loss: 186195.8960\n",
      "Epoch 2884/5000\n",
      "134/134 [==============================] - 0s 271us/step - loss: 193286.9291 - val_loss: 211567.5124\n",
      "Epoch 2885/5000\n",
      "134/134 [==============================] - 0s 297us/step - loss: 188685.7086 - val_loss: 186026.0872\n",
      "Epoch 2886/5000\n",
      "134/134 [==============================] - 0s 288us/step - loss: 223616.7632 - val_loss: 271873.2435\n",
      "Epoch 2887/5000\n",
      "134/134 [==============================] - 0s 287us/step - loss: 285738.4949 - val_loss: 202802.2435\n",
      "Epoch 2888/5000\n",
      "134/134 [==============================] - 0s 294us/step - loss: 199003.8356 - val_loss: 185912.1406\n",
      "Epoch 2889/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 188084.6728 - val_loss: 180570.2213\n",
      "Epoch 2890/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 195073.8955 - val_loss: 183463.5599\n",
      "Epoch 2891/5000\n",
      "134/134 [==============================] - 0s 299us/step - loss: 188113.9286 - val_loss: 191693.6628\n",
      "Epoch 2892/5000\n",
      "134/134 [==============================] - 0s 284us/step - loss: 195920.4310 - val_loss: 191111.1017\n",
      "Epoch 2893/5000\n",
      "134/134 [==============================] - 0s 278us/step - loss: 213586.3440 - val_loss: 382098.6805\n",
      "Epoch 2894/5000\n",
      "134/134 [==============================] - 0s 281us/step - loss: 262294.0283 - val_loss: 314851.8027\n",
      "Epoch 2895/5000\n",
      "134/134 [==============================] - 0s 288us/step - loss: 304489.8345 - val_loss: 211841.0459\n",
      "Epoch 2896/5000\n",
      "134/134 [==============================] - 0s 336us/step - loss: 204825.5622 - val_loss: 190701.2230\n",
      "Epoch 2897/5000\n",
      "134/134 [==============================] - 0s 315us/step - loss: 186691.6063 - val_loss: 183891.9795\n",
      "Epoch 2898/5000\n",
      "134/134 [==============================] - 0s 298us/step - loss: 192332.6014 - val_loss: 214893.7244\n",
      "Epoch 2899/5000\n",
      "134/134 [==============================] - 0s 281us/step - loss: 207724.3615 - val_loss: 522856.9394\n",
      "Epoch 2900/5000\n",
      "134/134 [==============================] - 0s 262us/step - loss: 295795.4263 - val_loss: 211887.9482\n",
      "Epoch 2901/5000\n",
      "134/134 [==============================] - 0s 269us/step - loss: 198212.9385 - val_loss: 182264.3328\n",
      "Epoch 2902/5000\n",
      "134/134 [==============================] - 0s 258us/step - loss: 184876.3389 - val_loss: 200360.0578\n",
      "Epoch 2903/5000\n",
      "134/134 [==============================] - 0s 272us/step - loss: 185894.4762 - val_loss: 185083.5009\n",
      "Epoch 2904/5000\n",
      "134/134 [==============================] - 0s 377us/step - loss: 202945.2549 - val_loss: 231731.7631\n",
      "Epoch 2905/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 215781.7026 - val_loss: 221798.3018\n",
      "Epoch 2906/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 228838.3854 - val_loss: 200298.4830\n",
      "Epoch 2907/5000\n",
      "134/134 [==============================] - 0s 270us/step - loss: 247840.2197 - val_loss: 225834.9757\n",
      "Epoch 2908/5000\n",
      "134/134 [==============================] - 0s 286us/step - loss: 200126.4230 - val_loss: 185109.4412\n",
      "Epoch 2909/5000\n",
      "134/134 [==============================] - 0s 279us/step - loss: 188063.6069 - val_loss: 192715.6670\n",
      "Epoch 2910/5000\n",
      "134/134 [==============================] - 0s 341us/step - loss: 210588.7449 - val_loss: 253076.1138\n",
      "Epoch 2911/5000\n",
      "134/134 [==============================] - 0s 335us/step - loss: 234879.6703 - val_loss: 216486.9394\n",
      "Epoch 2912/5000\n",
      "134/134 [==============================] - 0s 298us/step - loss: 326484.9832 - val_loss: 464783.8685\n",
      "Epoch 2913/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 307us/step - loss: 292455.6159 - val_loss: 329744.7479\n",
      "Epoch 2914/5000\n",
      "134/134 [==============================] - 0s 267us/step - loss: 226216.7403 - val_loss: 440865.2649\n",
      "Epoch 2915/5000\n",
      "134/134 [==============================] - 0s 274us/step - loss: 346082.4426 - val_loss: 219140.5963\n",
      "Epoch 2916/5000\n",
      "134/134 [==============================] - 0s 269us/step - loss: 337008.9664 - val_loss: 222865.6024\n",
      "Epoch 2917/5000\n",
      "134/134 [==============================] - 0s 261us/step - loss: 201442.1425 - val_loss: 197333.9123\n",
      "Epoch 2918/5000\n",
      "134/134 [==============================] - 0s 274us/step - loss: 216864.3877 - val_loss: 268113.0630\n",
      "Epoch 2919/5000\n",
      "134/134 [==============================] - 0s 261us/step - loss: 250038.5605 - val_loss: 208619.2806\n",
      "Epoch 2920/5000\n",
      "134/134 [==============================] - 0s 269us/step - loss: 270757.7880 - val_loss: 233523.2903\n",
      "Epoch 2921/5000\n",
      "134/134 [==============================] - 0s 265us/step - loss: 212336.2502 - val_loss: 330626.4683\n",
      "Epoch 2922/5000\n",
      "134/134 [==============================] - 0s 261us/step - loss: 239868.5006 - val_loss: 195567.9697\n",
      "Epoch 2923/5000\n",
      "134/134 [==============================] - 0s 533us/step - loss: 194664.7285 - val_loss: 196415.3549\n",
      "Epoch 2924/5000\n",
      "134/134 [==============================] - 0s 315us/step - loss: 202404.9094 - val_loss: 301898.6362\n",
      "Epoch 2925/5000\n",
      "134/134 [==============================] - 0s 283us/step - loss: 212270.7840 - val_loss: 563900.6954\n",
      "Epoch 2926/5000\n",
      "134/134 [==============================] - 0s 260us/step - loss: 310909.4487 - val_loss: 194600.3764\n",
      "Epoch 2927/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 203208.7604 - val_loss: 194874.2577\n",
      "Epoch 2928/5000\n",
      "134/134 [==============================] - 0s 266us/step - loss: 218403.0924 - val_loss: 238244.9529\n",
      "Epoch 2929/5000\n",
      "134/134 [==============================] - 0s 259us/step - loss: 252790.8870 - val_loss: 212622.6460\n",
      "Epoch 2930/5000\n",
      "134/134 [==============================] - 0s 265us/step - loss: 192649.1678 - val_loss: 282124.7603\n",
      "Epoch 2931/5000\n",
      "134/134 [==============================] - 0s 266us/step - loss: 199433.2997 - val_loss: 340561.9153\n",
      "Epoch 2932/5000\n",
      "134/134 [==============================] - 0s 267us/step - loss: 267387.7500 - val_loss: 406662.9795\n",
      "Epoch 2933/5000\n",
      "134/134 [==============================] - 0s 280us/step - loss: 282693.1033 - val_loss: 428558.1922\n",
      "Epoch 2934/5000\n",
      "134/134 [==============================] - 0s 277us/step - loss: 285241.6468 - val_loss: 214358.3442\n",
      "Epoch 2935/5000\n",
      "134/134 [==============================] - 0s 267us/step - loss: 201046.1360 - val_loss: 224894.5788\n",
      "Epoch 2936/5000\n",
      "134/134 [==============================] - 0s 270us/step - loss: 221048.9193 - val_loss: 418706.4804\n",
      "Epoch 2937/5000\n",
      "134/134 [==============================] - 0s 253us/step - loss: 203731.7280 - val_loss: 215654.9771\n",
      "Epoch 2938/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 214347.1883 - val_loss: 205606.7936\n",
      "Epoch 2939/5000\n",
      "134/134 [==============================] - 0s 232us/step - loss: 269634.4263 - val_loss: 279378.2547\n",
      "Epoch 2940/5000\n",
      "134/134 [==============================] - 0s 267us/step - loss: 368673.1150 - val_loss: 233767.9562\n",
      "Epoch 2941/5000\n",
      "134/134 [==============================] - 0s 264us/step - loss: 289420.0612 - val_loss: 271186.2351\n",
      "Epoch 2942/5000\n",
      "134/134 [==============================] - 0s 246us/step - loss: 204392.6572 - val_loss: 254020.9825\n",
      "Epoch 2943/5000\n",
      "134/134 [==============================] - 0s 254us/step - loss: 237821.2938 - val_loss: 285037.5868\n",
      "Epoch 2944/5000\n",
      "134/134 [==============================] - 0s 256us/step - loss: 231642.8088 - val_loss: 191703.9769\n",
      "Epoch 2945/5000\n",
      "134/134 [==============================] - 0s 269us/step - loss: 196543.1198 - val_loss: 198209.1040\n",
      "Epoch 2946/5000\n",
      "134/134 [==============================] - 0s 261us/step - loss: 226821.8130 - val_loss: 187702.8797\n",
      "Epoch 2947/5000\n",
      "134/134 [==============================] - 0s 281us/step - loss: 193908.1655 - val_loss: 191169.1728\n",
      "Epoch 2948/5000\n",
      "134/134 [==============================] - 0s 281us/step - loss: 212508.3770 - val_loss: 313200.1665\n",
      "Epoch 2949/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 373737.7807 - val_loss: 353983.1546\n",
      "Epoch 2950/5000\n",
      "134/134 [==============================] - 0s 297us/step - loss: 259520.9527 - val_loss: 251396.1166\n",
      "Epoch 2951/5000\n",
      "134/134 [==============================] - 0s 294us/step - loss: 227213.6560 - val_loss: 201510.3722\n",
      "Epoch 2952/5000\n",
      "134/134 [==============================] - 0s 291us/step - loss: 197926.1286 - val_loss: 183556.3871\n",
      "Epoch 2953/5000\n",
      "134/134 [==============================] - 0s 285us/step - loss: 184289.0065 - val_loss: 206635.5597\n",
      "Epoch 2954/5000\n",
      "134/134 [==============================] - 0s 284us/step - loss: 202187.7336 - val_loss: 254874.1642\n",
      "Epoch 2955/5000\n",
      "134/134 [==============================] - 0s 278us/step - loss: 202767.2518 - val_loss: 192774.8335\n",
      "Epoch 2956/5000\n",
      "134/134 [==============================] - 0s 264us/step - loss: 272976.2716 - val_loss: 188467.0688\n",
      "Epoch 2957/5000\n",
      "134/134 [==============================] - 0s 278us/step - loss: 186891.2576 - val_loss: 195839.5303\n",
      "Epoch 2958/5000\n",
      "134/134 [==============================] - 0s 276us/step - loss: 198326.5588 - val_loss: 197338.1737\n",
      "Epoch 2959/5000\n",
      "134/134 [==============================] - 0s 283us/step - loss: 213320.1438 - val_loss: 193927.2020\n",
      "Epoch 2960/5000\n",
      "134/134 [==============================] - 0s 284us/step - loss: 198232.3475 - val_loss: 212166.1924\n",
      "Epoch 2961/5000\n",
      "134/134 [==============================] - 0s 299us/step - loss: 215228.3141 - val_loss: 312032.3834\n",
      "Epoch 2962/5000\n",
      "134/134 [==============================] - 0s 254us/step - loss: 335014.6911 - val_loss: 329307.8638\n",
      "Epoch 2963/5000\n",
      "134/134 [==============================] - 0s 280us/step - loss: 265900.3453 - val_loss: 317503.1980\n",
      "Epoch 2964/5000\n",
      "134/134 [==============================] - 0s 288us/step - loss: 265003.4323 - val_loss: 315783.9086\n",
      "Epoch 2965/5000\n",
      "134/134 [==============================] - 0s 282us/step - loss: 303497.5877 - val_loss: 266532.4664\n",
      "Epoch 2966/5000\n",
      "134/134 [==============================] - 0s 295us/step - loss: 220826.5112 - val_loss: 199249.4114\n",
      "Epoch 2967/5000\n",
      "134/134 [==============================] - 0s 262us/step - loss: 227558.3640 - val_loss: 193647.4170\n",
      "Epoch 2968/5000\n",
      "134/134 [==============================] - 0s 265us/step - loss: 202948.2151 - val_loss: 183369.1653\n",
      "Epoch 2969/5000\n",
      "134/134 [==============================] - 0s 264us/step - loss: 187659.2425 - val_loss: 178367.7556\n",
      "Epoch 2970/5000\n",
      "134/134 [==============================] - 0s 235us/step - loss: 197207.8440 - val_loss: 212350.5793\n",
      "Epoch 2971/5000\n",
      "134/134 [==============================] - 0s 249us/step - loss: 189763.5882 - val_loss: 378911.4846\n",
      "Epoch 2972/5000\n",
      "134/134 [==============================] - 0s 255us/step - loss: 255225.4224 - val_loss: 230032.3820\n",
      "Epoch 2973/5000\n",
      "134/134 [==============================] - 0s 245us/step - loss: 453448.6974 - val_loss: 211179.5084\n",
      "Epoch 2974/5000\n",
      "134/134 [==============================] - 0s 244us/step - loss: 223820.2191 - val_loss: 233997.0564\n",
      "Epoch 2975/5000\n",
      "134/134 [==============================] - 0s 265us/step - loss: 203309.6581 - val_loss: 228033.4692\n",
      "Epoch 2976/5000\n",
      "134/134 [==============================] - 0s 253us/step - loss: 220630.8489 - val_loss: 185482.4165\n",
      "Epoch 2977/5000\n",
      "134/134 [==============================] - 0s 253us/step - loss: 189530.3783 - val_loss: 225992.6567\n",
      "Epoch 2978/5000\n",
      "134/134 [==============================] - 0s 269us/step - loss: 196197.1693 - val_loss: 191070.5355\n",
      "Epoch 2979/5000\n",
      "134/134 [==============================] - 0s 268us/step - loss: 247572.9006 - val_loss: 400981.3904\n",
      "Epoch 2980/5000\n",
      "134/134 [==============================] - 0s 263us/step - loss: 347395.9456 - val_loss: 203750.5359\n",
      "Epoch 2981/5000\n",
      "134/134 [==============================] - 0s 291us/step - loss: 213071.0929 - val_loss: 197324.0947\n",
      "Epoch 2982/5000\n",
      "134/134 [==============================] - 0s 261us/step - loss: 206222.2255 - val_loss: 336015.0322\n",
      "Epoch 2983/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 284us/step - loss: 264266.2044 - val_loss: 236646.5280\n",
      "Epoch 2984/5000\n",
      "134/134 [==============================] - 0s 283us/step - loss: 216139.2205 - val_loss: 510959.5765\n",
      "Epoch 2985/5000\n",
      "134/134 [==============================] - 0s 284us/step - loss: 345959.4507 - val_loss: 199018.6348\n",
      "Epoch 2986/5000\n",
      "134/134 [==============================] - 0s 285us/step - loss: 192288.8811 - val_loss: 191543.4520\n",
      "Epoch 2987/5000\n",
      "134/134 [==============================] - 0s 271us/step - loss: 217223.9225 - val_loss: 268778.0905\n",
      "Epoch 2988/5000\n",
      "134/134 [==============================] - 0s 289us/step - loss: 203591.5513 - val_loss: 203934.3263\n",
      "Epoch 2989/5000\n",
      "134/134 [==============================] - 0s 278us/step - loss: 215672.5729 - val_loss: 184388.8232\n",
      "Epoch 2990/5000\n",
      "134/134 [==============================] - 0s 299us/step - loss: 186228.5959 - val_loss: 202043.1796\n",
      "Epoch 2991/5000\n",
      "134/134 [==============================] - 0s 315us/step - loss: 192770.8191 - val_loss: 176729.3249\n",
      "Epoch 2992/5000\n",
      "134/134 [==============================] - 0s 269us/step - loss: 185580.4292 - val_loss: 195572.7290\n",
      "Epoch 2993/5000\n",
      "134/134 [==============================] - 0s 283us/step - loss: 197676.2684 - val_loss: 252313.9403\n",
      "Epoch 2994/5000\n",
      "134/134 [==============================] - ETA: 0s - loss: 310095.75 - 0s 275us/step - loss: 233570.8200 - val_loss: 202869.4599\n",
      "Epoch 2995/5000\n",
      "134/134 [==============================] - 0s 277us/step - loss: 269918.7926 - val_loss: 192743.5651\n",
      "Epoch 2996/5000\n",
      "134/134 [==============================] - 0s 284us/step - loss: 228878.4592 - val_loss: 361392.4599\n",
      "Epoch 2997/5000\n",
      "134/134 [==============================] - 0s 271us/step - loss: 295331.8698 - val_loss: 193745.2729\n",
      "Epoch 2998/5000\n",
      "134/134 [==============================] - 0s 277us/step - loss: 214902.6766 - val_loss: 190625.1271\n",
      "Epoch 2999/5000\n",
      "134/134 [==============================] - 0s 311us/step - loss: 199065.9391 - val_loss: 328314.8246\n",
      "Epoch 3000/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 337556.7666 - val_loss: 295951.9846\n",
      "Epoch 3001/5000\n",
      "134/134 [==============================] - 0s 294us/step - loss: 304573.5392 - val_loss: 276957.1175\n",
      "Epoch 3002/5000\n",
      "134/134 [==============================] - 0s 268us/step - loss: 204043.5831 - val_loss: 357854.5858\n",
      "Epoch 3003/5000\n",
      "134/134 [==============================] - 0s 267us/step - loss: 281014.9565 - val_loss: 313328.3125\n",
      "Epoch 3004/5000\n",
      "134/134 [==============================] - 0s 268us/step - loss: 282264.0292 - val_loss: 203230.8249\n",
      "Epoch 3005/5000\n",
      "134/134 [==============================] - 0s 240us/step - loss: 260348.3419 - val_loss: 251641.5865\n",
      "Epoch 3006/5000\n",
      "134/134 [==============================] - 0s 256us/step - loss: 254620.2229 - val_loss: 220984.3888\n",
      "Epoch 3007/5000\n",
      "134/134 [==============================] - 0s 257us/step - loss: 211030.9313 - val_loss: 334308.2225\n",
      "Epoch 3008/5000\n",
      "134/134 [==============================] - 0s 259us/step - loss: 221355.4225 - val_loss: 235730.9977\n",
      "Epoch 3009/5000\n",
      "134/134 [==============================] - 0s 260us/step - loss: 204665.9245 - val_loss: 191860.2505\n",
      "Epoch 3010/5000\n",
      "134/134 [==============================] - 0s 241us/step - loss: 185780.3259 - val_loss: 195081.1427\n",
      "Epoch 3011/5000\n",
      "134/134 [==============================] - 0s 242us/step - loss: 184949.0613 - val_loss: 207541.1327\n",
      "Epoch 3012/5000\n",
      "134/134 [==============================] - 0s 272us/step - loss: 191075.8599 - val_loss: 195640.9230\n",
      "Epoch 3013/5000\n",
      "134/134 [==============================] - 0s 244us/step - loss: 243367.5263 - val_loss: 225250.5704\n",
      "Epoch 3014/5000\n",
      "134/134 [==============================] - 0s 260us/step - loss: 293611.4328 - val_loss: 230412.3741\n",
      "Epoch 3015/5000\n",
      "134/134 [==============================] - 0s 269us/step - loss: 223631.0681 - val_loss: 238355.4312\n",
      "Epoch 3016/5000\n",
      "134/134 [==============================] - 0s 275us/step - loss: 205366.5226 - val_loss: 191165.6877\n",
      "Epoch 3017/5000\n",
      "134/134 [==============================] - 0s 282us/step - loss: 217242.5016 - val_loss: 211085.5833\n",
      "Epoch 3018/5000\n",
      "134/134 [==============================] - 0s 268us/step - loss: 192388.0273 - val_loss: 290941.5616\n",
      "Epoch 3019/5000\n",
      "134/134 [==============================] - 0s 271us/step - loss: 201224.5038 - val_loss: 198814.9202\n",
      "Epoch 3020/5000\n",
      "134/134 [==============================] - 0s 275us/step - loss: 232217.5107 - val_loss: 195406.0611\n",
      "Epoch 3021/5000\n",
      "134/134 [==============================] - 0s 278us/step - loss: 252648.4299 - val_loss: 226091.8377\n",
      "Epoch 3022/5000\n",
      "134/134 [==============================] - 0s 268us/step - loss: 226620.3073 - val_loss: 255894.9132\n",
      "Epoch 3023/5000\n",
      "134/134 [==============================] - 0s 280us/step - loss: 223569.2672 - val_loss: 196636.6089\n",
      "Epoch 3024/5000\n",
      "134/134 [==============================] - 0s 269us/step - loss: 182755.0218 - val_loss: 173845.9102\n",
      "Epoch 3025/5000\n",
      "134/134 [==============================] - 0s 285us/step - loss: 190748.6770 - val_loss: 478631.7295\n",
      "Epoch 3026/5000\n",
      "134/134 [==============================] - 0s 286us/step - loss: 284807.8959 - val_loss: 285400.1558\n",
      "Epoch 3027/5000\n",
      "134/134 [==============================] - 0s 283us/step - loss: 263267.5855 - val_loss: 886161.6950\n",
      "Epoch 3028/5000\n",
      "134/134 [==============================] - 0s 283us/step - loss: 503976.7411 - val_loss: 281827.2367\n",
      "Epoch 3029/5000\n",
      "134/134 [==============================] - 0s 269us/step - loss: 272150.9492 - val_loss: 215093.6530\n",
      "Epoch 3030/5000\n",
      "134/134 [==============================] - 0s 284us/step - loss: 234372.2985 - val_loss: 186871.3393\n",
      "Epoch 3031/5000\n",
      "134/134 [==============================] - 0s 282us/step - loss: 189835.9030 - val_loss: 173661.9135\n",
      "Epoch 3032/5000\n",
      "134/134 [==============================] - 0s 272us/step - loss: 183712.4433 - val_loss: 179927.2668\n",
      "Epoch 3033/5000\n",
      "134/134 [==============================] - 0s 281us/step - loss: 178895.4222 - val_loss: 173994.7423\n",
      "Epoch 3034/5000\n",
      "134/134 [==============================] - 0s 300us/step - loss: 180559.9436 - val_loss: 167795.3808\n",
      "Epoch 3035/5000\n",
      "134/134 [==============================] - 0s 271us/step - loss: 175455.2239 - val_loss: 167653.1126\n",
      "Epoch 3036/5000\n",
      "134/134 [==============================] - 0s 277us/step - loss: 183620.7026 - val_loss: 199870.5350\n",
      "Epoch 3037/5000\n",
      "134/134 [==============================] - 0s 280us/step - loss: 253645.4745 - val_loss: 403742.9487\n",
      "Epoch 3038/5000\n",
      "134/134 [==============================] - 0s 277us/step - loss: 256487.9572 - val_loss: 411587.9683\n",
      "Epoch 3039/5000\n",
      "134/134 [==============================] - 0s 271us/step - loss: 268495.8728 - val_loss: 263932.5345\n",
      "Epoch 3040/5000\n",
      "134/134 [==============================] - 0s 270us/step - loss: 217124.2829 - val_loss: 333530.4328\n",
      "Epoch 3041/5000\n",
      "134/134 [==============================] - 0s 271us/step - loss: 293480.0340 - val_loss: 420098.6735\n",
      "Epoch 3042/5000\n",
      "134/134 [==============================] - 0s 263us/step - loss: 295266.9611 - val_loss: 437603.1950\n",
      "Epoch 3043/5000\n",
      "134/134 [==============================] - 0s 258us/step - loss: 359250.3719 - val_loss: 379765.3778\n",
      "Epoch 3044/5000\n",
      "134/134 [==============================] - 0s 272us/step - loss: 353873.0082 - val_loss: 204724.9753\n",
      "Epoch 3045/5000\n",
      "134/134 [==============================] - 0s 258us/step - loss: 219030.4988 - val_loss: 219576.4550\n",
      "Epoch 3046/5000\n",
      "134/134 [==============================] - 0s 271us/step - loss: 205181.4077 - val_loss: 190432.6404\n",
      "Epoch 3047/5000\n",
      "134/134 [==============================] - 0s 259us/step - loss: 191501.8347 - val_loss: 184467.8347\n",
      "Epoch 3048/5000\n",
      "134/134 [==============================] - 0s 264us/step - loss: 179874.8575 - val_loss: 170942.2789\n",
      "Epoch 3049/5000\n",
      "134/134 [==============================] - 0s 273us/step - loss: 177166.3538 - val_loss: 186086.0406\n",
      "Epoch 3050/5000\n",
      "134/134 [==============================] - 0s 274us/step - loss: 191915.2586 - val_loss: 229887.8587\n",
      "Epoch 3051/5000\n",
      "134/134 [==============================] - 0s 267us/step - loss: 250967.7810 - val_loss: 674982.0261\n",
      "Epoch 3052/5000\n",
      "134/134 [==============================] - 0s 268us/step - loss: 317618.6147 - val_loss: 284816.8321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3053/5000\n",
      "134/134 [==============================] - 0s 262us/step - loss: 200660.4699 - val_loss: 184475.1721\n",
      "Epoch 3054/5000\n",
      "134/134 [==============================] - 0s 257us/step - loss: 214775.2609 - val_loss: 174879.4165\n",
      "Epoch 3055/5000\n",
      "134/134 [==============================] - 0s 261us/step - loss: 183988.4746 - val_loss: 181647.9284\n",
      "Epoch 3056/5000\n",
      "134/134 [==============================] - 0s 268us/step - loss: 178818.2484 - val_loss: 174023.9627\n",
      "Epoch 3057/5000\n",
      "134/134 [==============================] - 0s 274us/step - loss: 174294.5808 - val_loss: 167294.5075\n",
      "Epoch 3058/5000\n",
      "134/134 [==============================] - 0s 268us/step - loss: 177405.0518 - val_loss: 195943.2682\n",
      "Epoch 3059/5000\n",
      "134/134 [==============================] - 0s 271us/step - loss: 196558.0952 - val_loss: 181479.6719\n",
      "Epoch 3060/5000\n",
      "134/134 [==============================] - 0s 264us/step - loss: 196781.5749 - val_loss: 193703.1651\n",
      "Epoch 3061/5000\n",
      "134/134 [==============================] - 0s 264us/step - loss: 197521.6982 - val_loss: 246236.1968\n",
      "Epoch 3062/5000\n",
      "134/134 [==============================] - 0s 268us/step - loss: 255162.6598 - val_loss: 191937.8727\n",
      "Epoch 3063/5000\n",
      "134/134 [==============================] - 0s 261us/step - loss: 207873.4256 - val_loss: 219814.1838\n",
      "Epoch 3064/5000\n",
      "134/134 [==============================] - 0s 270us/step - loss: 201849.6333 - val_loss: 313288.1707\n",
      "Epoch 3065/5000\n",
      "134/134 [==============================] - 0s 264us/step - loss: 304005.4253 - val_loss: 291560.9953\n",
      "Epoch 3066/5000\n",
      "134/134 [==============================] - 0s 264us/step - loss: 244557.9374 - val_loss: 196167.4506\n",
      "Epoch 3067/5000\n",
      "134/134 [==============================] - 0s 271us/step - loss: 210024.5130 - val_loss: 290621.8722\n",
      "Epoch 3068/5000\n",
      "134/134 [==============================] - 0s 300us/step - loss: 199546.4656 - val_loss: 186406.0970\n",
      "Epoch 3069/5000\n",
      "134/134 [==============================] - 0s 264us/step - loss: 189874.6046 - val_loss: 182064.7253\n",
      "Epoch 3070/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 197627.0938 - val_loss: 187412.8144\n",
      "Epoch 3071/5000\n",
      "134/134 [==============================] - 0s 298us/step - loss: 229484.2566 - val_loss: 562086.7015\n",
      "Epoch 3072/5000\n",
      "134/134 [==============================] - 0s 297us/step - loss: 285493.2927 - val_loss: 221841.7379\n",
      "Epoch 3073/5000\n",
      "134/134 [==============================] - 0s 339us/step - loss: 185597.4843 - val_loss: 171794.0296\n",
      "Epoch 3074/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 168746.5008 - val_loss: 190047.8878\n",
      "Epoch 3075/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 188467.0826 - val_loss: 181335.5872\n",
      "Epoch 3076/5000\n",
      "134/134 [==============================] - 0s 292us/step - loss: 189165.2036 - val_loss: 183402.6313\n",
      "Epoch 3077/5000\n",
      "134/134 [==============================] - 0s 435us/step - loss: 188505.6668 - val_loss: 168341.2404\n",
      "Epoch 3078/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 171502.9359 - val_loss: 186530.1507\n",
      "Epoch 3079/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 250952.5809 - val_loss: 284525.3561\n",
      "Epoch 3080/5000\n",
      "134/134 [==============================] - 0s 345us/step - loss: 253646.3924 - val_loss: 418431.3685\n",
      "Epoch 3081/5000\n",
      "134/134 [==============================] - 0s 339us/step - loss: 324529.3438 - val_loss: 566149.2057\n",
      "Epoch 3082/5000\n",
      "134/134 [==============================] - 0s 342us/step - loss: 639208.6984 - val_loss: 227260.3039\n",
      "Epoch 3083/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 271802.4138 - val_loss: 280024.0716\n",
      "Epoch 3084/5000\n",
      "134/134 [==============================] - 0s 345us/step - loss: 260897.6533 - val_loss: 245431.6215\n",
      "Epoch 3085/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 204152.0875 - val_loss: 173197.0592\n",
      "Epoch 3086/5000\n",
      "134/134 [==============================] - 0s 333us/step - loss: 190347.3734 - val_loss: 169344.3188\n",
      "Epoch 3087/5000\n",
      "134/134 [==============================] - 0s 365us/step - loss: 186232.7938 - val_loss: 196323.6971\n",
      "Epoch 3088/5000\n",
      "134/134 [==============================] - 0s 359us/step - loss: 191434.5258 - val_loss: 179808.7855\n",
      "Epoch 3089/5000\n",
      "134/134 [==============================] - 0s 331us/step - loss: 173954.9081 - val_loss: 175930.1698\n",
      "Epoch 3090/5000\n",
      "134/134 [==============================] - 0s 311us/step - loss: 171799.3032 - val_loss: 176721.3640\n",
      "Epoch 3091/5000\n",
      "134/134 [==============================] - 0s 261us/step - loss: 211699.0111 - val_loss: 252420.4636\n",
      "Epoch 3092/5000\n",
      "134/134 [==============================] - 0s 267us/step - loss: 187090.7176 - val_loss: 446360.8937\n",
      "Epoch 3093/5000\n",
      "134/134 [==============================] - 0s 259us/step - loss: 273091.4816 - val_loss: 199173.7320\n",
      "Epoch 3094/5000\n",
      "134/134 [==============================] - 0s 283us/step - loss: 205697.0983 - val_loss: 290115.2948\n",
      "Epoch 3095/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 223172.0021 - val_loss: 213794.9690\n",
      "Epoch 3096/5000\n",
      "134/134 [==============================] - 0s 348us/step - loss: 259503.7275 - val_loss: 236973.1556\n",
      "Epoch 3097/5000\n",
      "134/134 [==============================] - 0s 323us/step - loss: 264734.4734 - val_loss: 216854.6287\n",
      "Epoch 3098/5000\n",
      "134/134 [==============================] - 0s 341us/step - loss: 267330.6021 - val_loss: 395733.5168\n",
      "Epoch 3099/5000\n",
      "134/134 [==============================] - 0s 301us/step - loss: 251289.8119 - val_loss: 184399.7733\n",
      "Epoch 3100/5000\n",
      "134/134 [==============================] - 0s 318us/step - loss: 177365.8960 - val_loss: 176582.6656\n",
      "Epoch 3101/5000\n",
      "134/134 [==============================] - 0s 339us/step - loss: 186076.6123 - val_loss: 182738.3440\n",
      "Epoch 3102/5000\n",
      "134/134 [==============================] - 0s 338us/step - loss: 182002.8895 - val_loss: 220453.2873\n",
      "Epoch 3103/5000\n",
      "134/134 [==============================] - 0s 393us/step - loss: 184790.7490 - val_loss: 291069.7101\n",
      "Epoch 3104/5000\n",
      "134/134 [==============================] - 0s 427us/step - loss: 258950.5779 - val_loss: 183653.1740\n",
      "Epoch 3105/5000\n",
      "134/134 [==============================] - 0s 380us/step - loss: 209982.1197 - val_loss: 287101.7034\n",
      "Epoch 3106/5000\n",
      "134/134 [==============================] - 0s 354us/step - loss: 305203.5788 - val_loss: 263243.1842\n",
      "Epoch 3107/5000\n",
      "134/134 [==============================] - 0s 279us/step - loss: 270895.4813 - val_loss: 587571.0616\n",
      "Epoch 3108/5000\n",
      "134/134 [==============================] - 0s 257us/step - loss: 273979.7364 - val_loss: 257094.3857\n",
      "Epoch 3109/5000\n",
      "134/134 [==============================] - 0s 261us/step - loss: 198638.3792 - val_loss: 175184.4837\n",
      "Epoch 3110/5000\n",
      "134/134 [==============================] - 0s 276us/step - loss: 187579.1740 - val_loss: 174790.6080\n",
      "Epoch 3111/5000\n",
      "134/134 [==============================] - 0s 290us/step - loss: 185576.1891 - val_loss: 172879.3633\n",
      "Epoch 3112/5000\n",
      "134/134 [==============================] - 0s 278us/step - loss: 174643.0512 - val_loss: 172582.3918\n",
      "Epoch 3113/5000\n",
      "134/134 [==============================] - 0s 272us/step - loss: 170697.4253 - val_loss: 183445.9268\n",
      "Epoch 3114/5000\n",
      "134/134 [==============================] - 0s 274us/step - loss: 176208.1995 - val_loss: 187427.4979\n",
      "Epoch 3115/5000\n",
      "134/134 [==============================] - 0s 269us/step - loss: 235845.3770 - val_loss: 354350.5784\n",
      "Epoch 3116/5000\n",
      "134/134 [==============================] - 0s 274us/step - loss: 237337.2770 - val_loss: 212862.4081\n",
      "Epoch 3117/5000\n",
      "134/134 [==============================] - 0s 275us/step - loss: 180050.3125 - val_loss: 275506.6612\n",
      "Epoch 3118/5000\n",
      "134/134 [==============================] - 0s 266us/step - loss: 224007.7880 - val_loss: 219506.8102\n",
      "Epoch 3119/5000\n",
      "134/134 [==============================] - 0s 273us/step - loss: 241356.1523 - val_loss: 335559.0068\n",
      "Epoch 3120/5000\n",
      "134/134 [==============================] - 0s 259us/step - loss: 249747.1849 - val_loss: 324948.6115\n",
      "Epoch 3121/5000\n",
      "134/134 [==============================] - 0s 287us/step - loss: 489918.2334 - val_loss: 207822.6098\n",
      "Epoch 3122/5000\n",
      "134/134 [==============================] - 0s 265us/step - loss: 187952.1432 - val_loss: 195942.7472\n",
      "Epoch 3123/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 267us/step - loss: 186314.2206 - val_loss: 620562.0173\n",
      "Epoch 3124/5000\n",
      "134/134 [==============================] - 0s 271us/step - loss: 286723.6758 - val_loss: 179574.4489\n",
      "Epoch 3125/5000\n",
      "134/134 [==============================] - 0s 262us/step - loss: 194883.6869 - val_loss: 171644.7796\n",
      "Epoch 3126/5000\n",
      "134/134 [==============================] - 0s 258us/step - loss: 189769.4049 - val_loss: 187052.8878\n",
      "Epoch 3127/5000\n",
      "134/134 [==============================] - 0s 274us/step - loss: 197867.5368 - val_loss: 214685.1712\n",
      "Epoch 3128/5000\n",
      "134/134 [==============================] - 0s 262us/step - loss: 192930.0373 - val_loss: 362446.1031\n",
      "Epoch 3129/5000\n",
      "134/134 [==============================] - 0s 285us/step - loss: 279413.1547 - val_loss: 243663.2421\n",
      "Epoch 3130/5000\n",
      "134/134 [==============================] - 0s 259us/step - loss: 208858.0091 - val_loss: 170625.5035\n",
      "Epoch 3131/5000\n",
      "134/134 [==============================] - 0s 259us/step - loss: 171931.2298 - val_loss: 182333.0359\n",
      "Epoch 3132/5000\n",
      "134/134 [==============================] - 0s 259us/step - loss: 168181.4171 - val_loss: 160134.7663\n",
      "Epoch 3133/5000\n",
      "134/134 [==============================] - 0s 263us/step - loss: 171321.1451 - val_loss: 171611.2528\n",
      "Epoch 3134/5000\n",
      "134/134 [==============================] - 0s 266us/step - loss: 176915.4370 - val_loss: 168974.8547\n",
      "Epoch 3135/5000\n",
      "134/134 [==============================] - 0s 271us/step - loss: 189834.5191 - val_loss: 181406.4888\n",
      "Epoch 3136/5000\n",
      "134/134 [==============================] - 0s 252us/step - loss: 207647.2435 - val_loss: 459339.7892\n",
      "Epoch 3137/5000\n",
      "134/134 [==============================] - 0s 257us/step - loss: 208981.2022 - val_loss: 656327.0187\n",
      "Epoch 3138/5000\n",
      "134/134 [==============================] - 0s 689us/step - loss: 271901.8722 - val_loss: 313121.2668\n",
      "Epoch 3139/5000\n",
      "134/134 [==============================] - 0s 329us/step - loss: 209493.6395 - val_loss: 180667.1481\n",
      "Epoch 3140/5000\n",
      "134/134 [==============================] - 0s 261us/step - loss: 192416.7641 - val_loss: 170799.1159\n",
      "Epoch 3141/5000\n",
      "134/134 [==============================] - 0s 258us/step - loss: 204314.4783 - val_loss: 423294.2276\n",
      "Epoch 3142/5000\n",
      "134/134 [==============================] - 0s 289us/step - loss: 260689.2587 - val_loss: 172113.0236\n",
      "Epoch 3143/5000\n",
      "134/134 [==============================] - 0s 271us/step - loss: 177732.0853 - val_loss: 245423.4674\n",
      "Epoch 3144/5000\n",
      "134/134 [==============================] - 0s 397us/step - loss: 188155.7688 - val_loss: 437774.5201\n",
      "Epoch 3145/5000\n",
      "134/134 [==============================] - 0s 464us/step - loss: 271989.8263 - val_loss: 869235.7603\n",
      "Epoch 3146/5000\n",
      "134/134 [==============================] - 0s 520us/step - loss: 335583.2581 - val_loss: 305457.6376\n",
      "Epoch 3147/5000\n",
      "134/134 [==============================] - 0s 606us/step - loss: 219493.8371 - val_loss: 421151.2929\n",
      "Epoch 3148/5000\n",
      "134/134 [==============================] - 0s 453us/step - loss: 227717.7526 - val_loss: 194771.8078\n",
      "Epoch 3149/5000\n",
      "134/134 [==============================] - 0s 350us/step - loss: 199230.5298 - val_loss: 167448.3778\n",
      "Epoch 3150/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 187316.5472 - val_loss: 180768.9492\n",
      "Epoch 3151/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 203426.6996 - val_loss: 224108.7512\n",
      "Epoch 3152/5000\n",
      "134/134 [==============================] - 0s 318us/step - loss: 195371.6003 - val_loss: 312943.9478\n",
      "Epoch 3153/5000\n",
      "134/134 [==============================] - 0s 351us/step - loss: 239087.3696 - val_loss: 182438.6369\n",
      "Epoch 3154/5000\n",
      "134/134 [==============================] - 0s 323us/step - loss: 178933.2532 - val_loss: 199335.6877\n",
      "Epoch 3155/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 181824.2198 - val_loss: 159218.1110\n",
      "Epoch 3156/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 177376.2341 - val_loss: 338106.0336\n",
      "Epoch 3157/5000\n",
      "134/134 [==============================] - 0s 346us/step - loss: 208759.6065 - val_loss: 179291.3060\n",
      "Epoch 3158/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 190984.0020 - val_loss: 178710.3932\n",
      "Epoch 3159/5000\n",
      "134/134 [==============================] - 0s 301us/step - loss: 220334.7555 - val_loss: 183840.9834\n",
      "Epoch 3160/5000\n",
      "134/134 [==============================] - 0s 323us/step - loss: 200030.1248 - val_loss: 382562.0989\n",
      "Epoch 3161/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 286918.7004 - val_loss: 261921.4067\n",
      "Epoch 3162/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 204863.4552 - val_loss: 188528.6756\n",
      "Epoch 3163/5000\n",
      "134/134 [==============================] - 0s 378us/step - loss: 205034.2717 - val_loss: 720254.7864\n",
      "Epoch 3164/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 230814.4100 - val_loss: 202223.1495\n",
      "Epoch 3165/5000\n",
      "134/134 [==============================] - 0s 391us/step - loss: 265372.3141 - val_loss: 173432.6339\n",
      "Epoch 3166/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 166966.1133 - val_loss: 165015.7195\n",
      "Epoch 3167/5000\n",
      "134/134 [==============================] - 0s 291us/step - loss: 174921.9079 - val_loss: 284470.4170\n",
      "Epoch 3168/5000\n",
      "134/134 [==============================] - 0s 304us/step - loss: 178968.6957 - val_loss: 165744.8862\n",
      "Epoch 3169/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 171717.4760 - val_loss: 160933.5289\n",
      "Epoch 3170/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 162478.5652 - val_loss: 158351.7785\n",
      "Epoch 3171/5000\n",
      "134/134 [==============================] - 0s 317us/step - loss: 166499.4125 - val_loss: 195536.8806\n",
      "Epoch 3172/5000\n",
      "134/134 [==============================] - 0s 342us/step - loss: 209452.9148 - val_loss: 308901.2920\n",
      "Epoch 3173/5000\n",
      "134/134 [==============================] - 0s 365us/step - loss: 231058.8989 - val_loss: 161744.4503\n",
      "Epoch 3174/5000\n",
      "134/134 [==============================] - 0s 503us/step - loss: 174640.0052 - val_loss: 169536.3314\n",
      "Epoch 3175/5000\n",
      "134/134 [==============================] - 0s 475us/step - loss: 195022.0422 - val_loss: 245454.6940\n",
      "Epoch 3176/5000\n",
      "134/134 [==============================] - 0s 372us/step - loss: 189998.9634 - val_loss: 165313.5821\n",
      "Epoch 3177/5000\n",
      "134/134 [==============================] - 0s 445us/step - loss: 170973.9728 - val_loss: 180647.4300\n",
      "Epoch 3178/5000\n",
      "134/134 [==============================] - 0s 464us/step - loss: 182798.9398 - val_loss: 273239.4785\n",
      "Epoch 3179/5000\n",
      "134/134 [==============================] - 0s 377us/step - loss: 248274.9464 - val_loss: 238375.3169\n",
      "Epoch 3180/5000\n",
      "134/134 [==============================] - 0s 345us/step - loss: 292682.8188 - val_loss: 401223.5970\n",
      "Epoch 3181/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 230622.0586 - val_loss: 187636.5686\n",
      "Epoch 3182/5000\n",
      "134/134 [==============================] - 0s 343us/step - loss: 209521.4035 - val_loss: 188312.1537\n",
      "Epoch 3183/5000\n",
      "134/134 [==============================] - 0s 362us/step - loss: 193337.6197 - val_loss: 188912.7421\n",
      "Epoch 3184/5000\n",
      "134/134 [==============================] - 0s 360us/step - loss: 184090.9378 - val_loss: 166670.8424\n",
      "Epoch 3185/5000\n",
      "134/134 [==============================] - 0s 364us/step - loss: 181876.9081 - val_loss: 206223.8454\n",
      "Epoch 3186/5000\n",
      "134/134 [==============================] - 0s 349us/step - loss: 233542.5855 - val_loss: 184063.4056\n",
      "Epoch 3187/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 199307.2961 - val_loss: 307755.9709\n",
      "Epoch 3188/5000\n",
      "134/134 [==============================] - 0s 381us/step - loss: 241988.7000 - val_loss: 380558.7367\n",
      "Epoch 3189/5000\n",
      "134/134 [==============================] - 0s 347us/step - loss: 253764.1214 - val_loss: 188743.3507\n",
      "Epoch 3190/5000\n",
      "134/134 [==============================] - 0s 397us/step - loss: 193323.2132 - val_loss: 237061.8601\n",
      "Epoch 3191/5000\n",
      "134/134 [==============================] - 0s 399us/step - loss: 191335.6471 - val_loss: 175114.6199\n",
      "Epoch 3192/5000\n",
      "134/134 [==============================] - 0s 369us/step - loss: 181782.1264 - val_loss: 191265.9091\n",
      "Epoch 3193/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 359us/step - loss: 209136.7056 - val_loss: 205871.2929\n",
      "Epoch 3194/5000\n",
      "134/134 [==============================] - 0s 351us/step - loss: 234373.1922 - val_loss: 325623.5205\n",
      "Epoch 3195/5000\n",
      "134/134 [==============================] - 0s 485us/step - loss: 221953.1554 - val_loss: 234600.6224\n",
      "Epoch 3196/5000\n",
      "134/134 [==============================] - 0s 409us/step - loss: 208145.1234 - val_loss: 184511.4879\n",
      "Epoch 3197/5000\n",
      "134/134 [==============================] - 0s 356us/step - loss: 208513.4166 - val_loss: 168119.1360\n",
      "Epoch 3198/5000\n",
      "134/134 [==============================] - 0s 356us/step - loss: 199188.6903 - val_loss: 461021.3545\n",
      "Epoch 3199/5000\n",
      "134/134 [==============================] - 0s 343us/step - loss: 241460.5241 - val_loss: 579908.4119\n",
      "Epoch 3200/5000\n",
      "134/134 [==============================] - 0s 341us/step - loss: 330246.7673 - val_loss: 566033.6754\n",
      "Epoch 3201/5000\n",
      "134/134 [==============================] - 0s 343us/step - loss: 289142.6927 - val_loss: 631277.1306\n",
      "Epoch 3202/5000\n",
      "134/134 [==============================] - 0s 282us/step - loss: 428073.3527 - val_loss: 214579.8953\n",
      "Epoch 3203/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 284049.4653 - val_loss: 345038.5868\n",
      "Epoch 3204/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 200464.7729 - val_loss: 383311.8022\n",
      "Epoch 3205/5000\n",
      "134/134 [==============================] - 0s 271us/step - loss: 274945.0384 - val_loss: 200931.5989\n",
      "Epoch 3206/5000\n",
      "134/134 [==============================] - 0s 333us/step - loss: 186526.0176 - val_loss: 170510.2549\n",
      "Epoch 3207/5000\n",
      "134/134 [==============================] - 0s 287us/step - loss: 175959.0126 - val_loss: 160885.6901\n",
      "Epoch 3208/5000\n",
      "134/134 [==============================] - 0s 332us/step - loss: 162913.7341 - val_loss: 158193.8871\n",
      "Epoch 3209/5000\n",
      "134/134 [==============================] - 0s 338us/step - loss: 168435.1603 - val_loss: 355425.3195\n",
      "Epoch 3210/5000\n",
      "134/134 [==============================] - 0s 531us/step - loss: 226866.9786 - val_loss: 235631.8582\n",
      "Epoch 3211/5000\n",
      "134/134 [==============================] - 0s 401us/step - loss: 266245.7638 - val_loss: 441254.8162\n",
      "Epoch 3212/5000\n",
      "134/134 [==============================] - 0s 397us/step - loss: 273560.6516 - val_loss: 339540.7668\n",
      "Epoch 3213/5000\n",
      "134/134 [==============================] - 0s 404us/step - loss: 197425.8870 - val_loss: 174522.6283\n",
      "Epoch 3214/5000\n",
      "134/134 [==============================] - 0s 374us/step - loss: 192088.9592 - val_loss: 176677.0385\n",
      "Epoch 3215/5000\n",
      "134/134 [==============================] - 0s 287us/step - loss: 177671.5153 - val_loss: 170795.0868\n",
      "Epoch 3216/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 166594.5404 - val_loss: 165539.5774\n",
      "Epoch 3217/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 171318.2111 - val_loss: 170152.7010\n",
      "Epoch 3218/5000\n",
      "134/134 [==============================] - 0s 324us/step - loss: 166367.6170 - val_loss: 257906.0952\n",
      "Epoch 3219/5000\n",
      "134/134 [==============================] - 0s 367us/step - loss: 191160.0508 - val_loss: 303595.2903\n",
      "Epoch 3220/5000\n",
      "134/134 [==============================] - 0s 398us/step - loss: 282757.6587 - val_loss: 204769.1033\n",
      "Epoch 3221/5000\n",
      "134/134 [==============================] - 0s 355us/step - loss: 191941.4461 - val_loss: 267990.5527\n",
      "Epoch 3222/5000\n",
      "134/134 [==============================] - 0s 414us/step - loss: 280260.7608 - val_loss: 183911.7570\n",
      "Epoch 3223/5000\n",
      "134/134 [==============================] - 0s 387us/step - loss: 210311.9899 - val_loss: 160607.1980\n",
      "Epoch 3224/5000\n",
      "134/134 [==============================] - 0s 406us/step - loss: 166797.1226 - val_loss: 156152.2034\n",
      "Epoch 3225/5000\n",
      "134/134 [==============================] - 0s 412us/step - loss: 160648.3531 - val_loss: 183798.4021\n",
      "Epoch 3226/5000\n",
      "134/134 [==============================] - 0s 388us/step - loss: 314354.6395 - val_loss: 185161.1199\n",
      "Epoch 3227/5000\n",
      "134/134 [==============================] - 0s 433us/step - loss: 178393.5699 - val_loss: 163037.3386\n",
      "Epoch 3228/5000\n",
      "134/134 [==============================] - 0s 408us/step - loss: 166786.2923 - val_loss: 161746.8246\n",
      "Epoch 3229/5000\n",
      "134/134 [==============================] - 0s 358us/step - loss: 168099.4121 - val_loss: 182912.0907\n",
      "Epoch 3230/5000\n",
      "134/134 [==============================] - 0s 335us/step - loss: 171359.1185 - val_loss: 175742.0959\n",
      "Epoch 3231/5000\n",
      "134/134 [==============================] - 0s 388us/step - loss: 165545.5215 - val_loss: 156256.5457\n",
      "Epoch 3232/5000\n",
      "134/134 [==============================] - 0s 382us/step - loss: 169465.7751 - val_loss: 171517.0737\n",
      "Epoch 3233/5000\n",
      "134/134 [==============================] - 0s 380us/step - loss: 168657.6114 - val_loss: 215704.1763\n",
      "Epoch 3234/5000\n",
      "134/134 [==============================] - 0s 358us/step - loss: 230263.3655 - val_loss: 316564.0261\n",
      "Epoch 3235/5000\n",
      "134/134 [==============================] - 0s 384us/step - loss: 189227.3877 - val_loss: 196278.8349\n",
      "Epoch 3236/5000\n",
      "134/134 [==============================] - 0s 363us/step - loss: 262314.3514 - val_loss: 1769753.1213\n",
      "Epoch 3237/5000\n",
      "134/134 [==============================] - 0s 343us/step - loss: 743872.5615 - val_loss: 195725.6147\n",
      "Epoch 3238/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 207399.5720 - val_loss: 164456.2533\n",
      "Epoch 3239/5000\n",
      "134/134 [==============================] - 0s 345us/step - loss: 165196.3806 - val_loss: 153512.1012\n",
      "Epoch 3240/5000\n",
      "134/134 [==============================] - 0s 311us/step - loss: 156997.9630 - val_loss: 154489.6283\n",
      "Epoch 3241/5000\n",
      "134/134 [==============================] - 0s 333us/step - loss: 156106.4316 - val_loss: 168069.6353\n",
      "Epoch 3242/5000\n",
      "134/134 [==============================] - 0s 522us/step - loss: 157703.8199 - val_loss: 152866.7393\n",
      "Epoch 3243/5000\n",
      "134/134 [==============================] - 0s 409us/step - loss: 155829.2153 - val_loss: 157938.5674\n",
      "Epoch 3244/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 158608.5998 - val_loss: 155489.5924\n",
      "Epoch 3245/5000\n",
      "134/134 [==============================] - 0s 358us/step - loss: 166677.4130 - val_loss: 168312.5791\n",
      "Epoch 3246/5000\n",
      "134/134 [==============================] - 0s 333us/step - loss: 190650.0775 - val_loss: 196278.5504\n",
      "Epoch 3247/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 179735.7818 - val_loss: 166784.2561\n",
      "Epoch 3248/5000\n",
      "134/134 [==============================] - 0s 342us/step - loss: 164030.4355 - val_loss: 163074.5711\n",
      "Epoch 3249/5000\n",
      "134/134 [==============================] - 0s 345us/step - loss: 166041.4909 - val_loss: 249711.4548\n",
      "Epoch 3250/5000\n",
      "134/134 [==============================] - 0s 431us/step - loss: 254695.8127 - val_loss: 172428.7190\n",
      "Epoch 3251/5000\n",
      "134/134 [==============================] - 0s 438us/step - loss: 286234.8412 - val_loss: 272247.1003\n",
      "Epoch 3252/5000\n",
      "134/134 [==============================] - 0s 372us/step - loss: 269860.3913 - val_loss: 190417.9636\n",
      "Epoch 3253/5000\n",
      "134/134 [==============================] - 0s 319us/step - loss: 196245.7963 - val_loss: 185309.9338\n",
      "Epoch 3254/5000\n",
      "134/134 [==============================] - 0s 344us/step - loss: 224955.7873 - val_loss: 251659.9137\n",
      "Epoch 3255/5000\n",
      "134/134 [==============================] - 0s 333us/step - loss: 210525.0695 - val_loss: 227801.2579\n",
      "Epoch 3256/5000\n",
      "134/134 [==============================] - 0s 323us/step - loss: 192975.0907 - val_loss: 442999.5336\n",
      "Epoch 3257/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 242437.3472 - val_loss: 250494.9021\n",
      "Epoch 3258/5000\n",
      "134/134 [==============================] - 0s 347us/step - loss: 258798.6922 - val_loss: 169903.9688\n",
      "Epoch 3259/5000\n",
      "134/134 [==============================] - 0s 369us/step - loss: 187816.6786 - val_loss: 163494.8151\n",
      "Epoch 3260/5000\n",
      "134/134 [==============================] - 0s 360us/step - loss: 163396.0605 - val_loss: 218475.2561\n",
      "Epoch 3261/5000\n",
      "134/134 [==============================] - 0s 479us/step - loss: 181726.1411 - val_loss: 208889.8277\n",
      "Epoch 3262/5000\n",
      "134/134 [==============================] - 0s 355us/step - loss: 239682.5619 - val_loss: 905829.3228\n",
      "Epoch 3263/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 418us/step - loss: 318112.5414 - val_loss: 206153.0942\n",
      "Epoch 3264/5000\n",
      "134/134 [==============================] - 0s 386us/step - loss: 212917.4150 - val_loss: 181489.5215\n",
      "Epoch 3265/5000\n",
      "134/134 [==============================] - 0s 432us/step - loss: 197836.0838 - val_loss: 420319.6558\n",
      "Epoch 3266/5000\n",
      "134/134 [==============================] - 0s 451us/step - loss: 248492.1013 - val_loss: 180434.2425\n",
      "Epoch 3267/5000\n",
      "134/134 [==============================] - 0s 508us/step - loss: 199180.6448 - val_loss: 273716.4818\n",
      "Epoch 3268/5000\n",
      "134/134 [==============================] - 0s 437us/step - loss: 216299.6209 - val_loss: 206868.7409\n",
      "Epoch 3269/5000\n",
      "134/134 [==============================] - 0s 334us/step - loss: 193462.3265 - val_loss: 622399.2006\n",
      "Epoch 3270/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 267270.8804 - val_loss: 192583.2136\n",
      "Epoch 3271/5000\n",
      "134/134 [==============================] - 0s 336us/step - loss: 198619.2806 - val_loss: 442471.7192\n",
      "Epoch 3272/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 312906.1192 - val_loss: 178698.4375\n",
      "Epoch 3273/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 179647.9848 - val_loss: 166477.7101\n",
      "Epoch 3274/5000\n",
      "134/134 [==============================] - 0s 338us/step - loss: 174621.3278 - val_loss: 156844.3787\n",
      "Epoch 3275/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 162307.6149 - val_loss: 169887.8554\n",
      "Epoch 3276/5000\n",
      "134/134 [==============================] - 0s 345us/step - loss: 197354.0535 - val_loss: 160607.8577\n",
      "Epoch 3277/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 164606.5415 - val_loss: 153490.2470\n",
      "Epoch 3278/5000\n",
      "134/134 [==============================] - 0s 320us/step - loss: 165637.2429 - val_loss: 164337.7181\n",
      "Epoch 3279/5000\n",
      "134/134 [==============================] - 0s 361us/step - loss: 172650.3095 - val_loss: 194605.7094\n",
      "Epoch 3280/5000\n",
      "134/134 [==============================] - 0s 449us/step - loss: 169165.5252 - val_loss: 250524.1045\n",
      "Epoch 3281/5000\n",
      "134/134 [==============================] - 0s 514us/step - loss: 215921.2918 - val_loss: 202533.7701\n",
      "Epoch 3282/5000\n",
      "134/134 [==============================] - 0s 403us/step - loss: 188630.2215 - val_loss: 227472.7680\n",
      "Epoch 3283/5000\n",
      "134/134 [==============================] - 0s 380us/step - loss: 176289.8391 - val_loss: 181556.4678\n",
      "Epoch 3284/5000\n",
      "134/134 [==============================] - 0s 395us/step - loss: 240771.2430 - val_loss: 305734.5947\n",
      "Epoch 3285/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 300040.0166 - val_loss: 368975.9569\n",
      "Epoch 3286/5000\n",
      "134/134 [==============================] - 0s 337us/step - loss: 214695.3277 - val_loss: 267666.5723\n",
      "Epoch 3287/5000\n",
      "134/134 [==============================] - 0s 352us/step - loss: 321036.2801 - val_loss: 317457.8153\n",
      "Epoch 3288/5000\n",
      "134/134 [==============================] - 0s 333us/step - loss: 256492.7176 - val_loss: 772316.6045\n",
      "Epoch 3289/5000\n",
      "134/134 [==============================] - 0s 288us/step - loss: 234181.1442 - val_loss: 159076.2927\n",
      "Epoch 3290/5000\n",
      "134/134 [==============================] - 0s 365us/step - loss: 163452.8739 - val_loss: 151610.3608\n",
      "Epoch 3291/5000\n",
      "134/134 [==============================] - 0s 448us/step - loss: 154403.1826 - val_loss: 168834.2064\n",
      "Epoch 3292/5000\n",
      "134/134 [==============================] - 0s 441us/step - loss: 168843.8265 - val_loss: 154286.2759\n",
      "Epoch 3293/5000\n",
      "134/134 [==============================] - 0s 423us/step - loss: 159453.0431 - val_loss: 290326.2929\n",
      "Epoch 3294/5000\n",
      "134/134 [==============================] - 0s 412us/step - loss: 285443.8953 - val_loss: 241191.3755\n",
      "Epoch 3295/5000\n",
      "134/134 [==============================] - 0s 387us/step - loss: 211335.6115 - val_loss: 217047.9846\n",
      "Epoch 3296/5000\n",
      "134/134 [==============================] - 0s 301us/step - loss: 222590.4683 - val_loss: 167962.6007\n",
      "Epoch 3297/5000\n",
      "134/134 [==============================] - 0s 332us/step - loss: 160587.3627 - val_loss: 156186.2964\n",
      "Epoch 3298/5000\n",
      "134/134 [==============================] - 0s 318us/step - loss: 160229.4292 - val_loss: 153487.5574\n",
      "Epoch 3299/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 174532.9805 - val_loss: 165810.4354\n",
      "Epoch 3300/5000\n",
      "134/134 [==============================] - 0s 337us/step - loss: 176446.3386 - val_loss: 213075.2612\n",
      "Epoch 3301/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 204922.5625 - val_loss: 322177.5047\n",
      "Epoch 3302/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 218839.1916 - val_loss: 181655.3843\n",
      "Epoch 3303/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 200500.5564 - val_loss: 174223.9023\n",
      "Epoch 3304/5000\n",
      "134/134 [==============================] - 0s 318us/step - loss: 171667.4453 - val_loss: 161677.8589\n",
      "Epoch 3305/5000\n",
      "134/134 [==============================] - 0s 344us/step - loss: 188891.7204 - val_loss: 194002.5760\n",
      "Epoch 3306/5000\n",
      "134/134 [==============================] - 0s 386us/step - loss: 186467.8221 - val_loss: 471337.0410\n",
      "Epoch 3307/5000\n",
      "134/134 [==============================] - 0s 422us/step - loss: 356898.8756 - val_loss: 807186.8645\n",
      "Epoch 3308/5000\n",
      "134/134 [==============================] - 0s 408us/step - loss: 386304.7511 - val_loss: 198689.1042\n",
      "Epoch 3309/5000\n",
      "134/134 [==============================] - 0s 385us/step - loss: 184691.9884 - val_loss: 601993.4380\n",
      "Epoch 3310/5000\n",
      "134/134 [==============================] - 0s 389us/step - loss: 285727.9688 - val_loss: 1141069.8601\n",
      "Epoch 3311/5000\n",
      "134/134 [==============================] - 0s 368us/step - loss: 322920.6811 - val_loss: 295145.2122\n",
      "Epoch 3312/5000\n",
      "134/134 [==============================] - 0s 325us/step - loss: 179220.5160 - val_loss: 161930.3930\n",
      "Epoch 3313/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 160951.9506 - val_loss: 160114.6481\n",
      "Epoch 3314/5000\n",
      "134/134 [==============================] - 0s 342us/step - loss: 163079.3886 - val_loss: 160620.0392\n",
      "Epoch 3315/5000\n",
      "134/134 [==============================] - 0s 285us/step - loss: 158685.3834 - val_loss: 159889.0466\n",
      "Epoch 3316/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 165316.1072 - val_loss: 167678.2073\n",
      "Epoch 3317/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 163492.6301 - val_loss: 354691.6397\n",
      "Epoch 3318/5000\n",
      "134/134 [==============================] - 0s 345us/step - loss: 248556.2160 - val_loss: 174038.5007\n",
      "Epoch 3319/5000\n",
      "134/134 [==============================] - 0s 297us/step - loss: 193555.1597 - val_loss: 169663.5919\n",
      "Epoch 3320/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 164591.2550 - val_loss: 188249.0369\n",
      "Epoch 3321/5000\n",
      "134/134 [==============================] - 0s 286us/step - loss: 215390.0351 - val_loss: 178306.6418\n",
      "Epoch 3322/5000\n",
      "134/134 [==============================] - 0s 315us/step - loss: 180618.9295 - val_loss: 174005.0742\n",
      "Epoch 3323/5000\n",
      "134/134 [==============================] - 0s 352us/step - loss: 190308.7188 - val_loss: 186300.9480\n",
      "Epoch 3324/5000\n",
      "134/134 [==============================] - 0s 349us/step - loss: 259213.2662 - val_loss: 362043.6549\n",
      "Epoch 3325/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 219598.2948 - val_loss: 237566.4172\n",
      "Epoch 3326/5000\n",
      "134/134 [==============================] - 0s 318us/step - loss: 243814.5089 - val_loss: 245474.2537\n",
      "Epoch 3327/5000\n",
      "134/134 [==============================] - 0s 367us/step - loss: 296212.1179 - val_loss: 300149.1091\n",
      "Epoch 3328/5000\n",
      "134/134 [==============================] - 0s 377us/step - loss: 221696.5526 - val_loss: 158748.0609\n",
      "Epoch 3329/5000\n",
      "134/134 [==============================] - 0s 349us/step - loss: 167637.2208 - val_loss: 151543.6866\n",
      "Epoch 3330/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 156040.7771 - val_loss: 155457.1539\n",
      "Epoch 3331/5000\n",
      "134/134 [==============================] - 0s 364us/step - loss: 155295.2750 - val_loss: 165538.3979\n",
      "Epoch 3332/5000\n",
      "134/134 [==============================] - 0s 379us/step - loss: 167130.9574 - val_loss: 157239.6856\n",
      "Epoch 3333/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 298us/step - loss: 205585.6283 - val_loss: 242481.3703\n",
      "Epoch 3334/5000\n",
      "134/134 [==============================] - 0s 320us/step - loss: 222355.3008 - val_loss: 195250.2598\n",
      "Epoch 3335/5000\n",
      "134/134 [==============================] - 0s 388us/step - loss: 201357.8890 - val_loss: 237390.4911\n",
      "Epoch 3336/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 254472.5242 - val_loss: 302428.8169\n",
      "Epoch 3337/5000\n",
      "134/134 [==============================] - 0s 334us/step - loss: 270946.5941 - val_loss: 381530.3993\n",
      "Epoch 3338/5000\n",
      "134/134 [==============================] - 0s 371us/step - loss: 213015.1196 - val_loss: 165459.9331\n",
      "Epoch 3339/5000\n",
      "134/134 [==============================] - 0s 337us/step - loss: 169080.5766 - val_loss: 157297.8193\n",
      "Epoch 3340/5000\n",
      "134/134 [==============================] - 0s 367us/step - loss: 158415.4573 - val_loss: 167400.4228\n",
      "Epoch 3341/5000\n",
      "134/134 [==============================] - ETA: 0s - loss: 174397.50 - 0s 337us/step - loss: 164022.6726 - val_loss: 156758.8468\n",
      "Epoch 3342/5000\n",
      "134/134 [==============================] - 0s 353us/step - loss: 158035.6701 - val_loss: 152075.6612\n",
      "Epoch 3343/5000\n",
      "134/134 [==============================] - 0s 332us/step - loss: 156427.2983 - val_loss: 155141.4865\n",
      "Epoch 3344/5000\n",
      "134/134 [==============================] - 0s 365us/step - loss: 200434.5146 - val_loss: 214714.3468\n",
      "Epoch 3345/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 230607.9711 - val_loss: 160617.6586\n",
      "Epoch 3346/5000\n",
      "134/134 [==============================] - 0s 300us/step - loss: 167590.7055 - val_loss: 184858.3713\n",
      "Epoch 3347/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 228201.9482 - val_loss: 648636.6567\n",
      "Epoch 3348/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 350693.9029 - val_loss: 658339.8414\n",
      "Epoch 3349/5000\n",
      "134/134 [==============================] - 0s 342us/step - loss: 233315.5024 - val_loss: 178969.3398\n",
      "Epoch 3350/5000\n",
      "134/134 [==============================] - 0s 333us/step - loss: 173030.5754 - val_loss: 186875.4305\n",
      "Epoch 3351/5000\n",
      "134/134 [==============================] - 0s 346us/step - loss: 221338.5912 - val_loss: 366698.9067\n",
      "Epoch 3352/5000\n",
      "134/134 [==============================] - 0s 333us/step - loss: 201544.5722 - val_loss: 187169.8552\n",
      "Epoch 3353/5000\n",
      "134/134 [==============================] - 0s 336us/step - loss: 166376.7329 - val_loss: 160873.5893\n",
      "Epoch 3354/5000\n",
      "134/134 [==============================] - 0s 332us/step - loss: 157329.2410 - val_loss: 172628.2957\n",
      "Epoch 3355/5000\n",
      "134/134 [==============================] - 0s 354us/step - loss: 176123.4921 - val_loss: 225300.2808\n",
      "Epoch 3356/5000\n",
      "134/134 [==============================] - 0s 343us/step - loss: 189395.9011 - val_loss: 210525.3517\n",
      "Epoch 3357/5000\n",
      "134/134 [==============================] - 0s 353us/step - loss: 192407.9546 - val_loss: 175684.6730\n",
      "Epoch 3358/5000\n",
      "134/134 [==============================] - 0s 332us/step - loss: 171001.0641 - val_loss: 207058.1189\n",
      "Epoch 3359/5000\n",
      "134/134 [==============================] - 0s 329us/step - loss: 159736.1764 - val_loss: 160964.2885\n",
      "Epoch 3360/5000\n",
      "134/134 [==============================] - 0s 317us/step - loss: 157995.5458 - val_loss: 211777.5949\n",
      "Epoch 3361/5000\n",
      "134/134 [==============================] - 0s 369us/step - loss: 202562.9321 - val_loss: 535779.3727\n",
      "Epoch 3362/5000\n",
      "134/134 [==============================] - 0s 341us/step - loss: 254734.1635 - val_loss: 177748.8470\n",
      "Epoch 3363/5000\n",
      "134/134 [==============================] - 0s 336us/step - loss: 232060.6791 - val_loss: 177830.1740\n",
      "Epoch 3364/5000\n",
      "134/134 [==============================] - 0s 329us/step - loss: 170226.9916 - val_loss: 184451.5732\n",
      "Epoch 3365/5000\n",
      "134/134 [==============================] - 0s 346us/step - loss: 192530.3920 - val_loss: 232523.6437\n",
      "Epoch 3366/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 220456.9434 - val_loss: 762070.5429\n",
      "Epoch 3367/5000\n",
      "134/134 [==============================] - 0s 339us/step - loss: 291632.6121 - val_loss: 181947.1094\n",
      "Epoch 3368/5000\n",
      "134/134 [==============================] - 0s 331us/step - loss: 203446.3320 - val_loss: 170522.1712\n",
      "Epoch 3369/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 171529.3400 - val_loss: 308454.2705\n",
      "Epoch 3370/5000\n",
      "134/134 [==============================] - 0s 339us/step - loss: 224325.3954 - val_loss: 220122.1542\n",
      "Epoch 3371/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 168186.8867 - val_loss: 148113.6567\n",
      "Epoch 3372/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 155238.5519 - val_loss: 187024.4202\n",
      "Epoch 3373/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 158317.5588 - val_loss: 164156.6001\n",
      "Epoch 3374/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 168866.5135 - val_loss: 214451.4207\n",
      "Epoch 3375/5000\n",
      "134/134 [==============================] - 0s 324us/step - loss: 185797.8261 - val_loss: 225487.2295\n",
      "Epoch 3376/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 218952.8284 - val_loss: 338268.5299\n",
      "Epoch 3377/5000\n",
      "134/134 [==============================] - 0s 349us/step - loss: 261023.0693 - val_loss: 1097007.6978\n",
      "Epoch 3378/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 472448.2853 - val_loss: 486576.1777\n",
      "Epoch 3379/5000\n",
      "134/134 [==============================] - 0s 311us/step - loss: 249709.9618 - val_loss: 578418.6465\n",
      "Epoch 3380/5000\n",
      "134/134 [==============================] - 0s 394us/step - loss: 214671.4318 - val_loss: 215304.4622\n",
      "Epoch 3381/5000\n",
      "134/134 [==============================] - 0s 374us/step - loss: 189939.7755 - val_loss: 168811.5511\n",
      "Epoch 3382/5000\n",
      "134/134 [==============================] - 0s 420us/step - loss: 157225.4943 - val_loss: 147279.5989\n",
      "Epoch 3383/5000\n",
      "134/134 [==============================] - 0s 376us/step - loss: 150059.0798 - val_loss: 166407.9732\n",
      "Epoch 3384/5000\n",
      "134/134 [==============================] - 0s 365us/step - loss: 151852.1230 - val_loss: 145871.0401\n",
      "Epoch 3385/5000\n",
      "134/134 [==============================] - 0s 357us/step - loss: 154437.6895 - val_loss: 168578.0877\n",
      "Epoch 3386/5000\n",
      "134/134 [==============================] - 0s 338us/step - loss: 164822.8171 - val_loss: 157796.0723\n",
      "Epoch 3387/5000\n",
      "134/134 [==============================] - 0s 351us/step - loss: 154462.3838 - val_loss: 152627.5919\n",
      "Epoch 3388/5000\n",
      "134/134 [==============================] - 0s 331us/step - loss: 171644.9570 - val_loss: 201791.9510\n",
      "Epoch 3389/5000\n",
      "134/134 [==============================] - 0s 335us/step - loss: 168687.7579 - val_loss: 310931.5448\n",
      "Epoch 3390/5000\n",
      "134/134 [==============================] - 0s 360us/step - loss: 189234.8382 - val_loss: 180820.9737\n",
      "Epoch 3391/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 175970.0906 - val_loss: 272300.4156\n",
      "Epoch 3392/5000\n",
      "134/134 [==============================] - 0s 392us/step - loss: 207122.7980 - val_loss: 760955.7976\n",
      "Epoch 3393/5000\n",
      "134/134 [==============================] - 0s 450us/step - loss: 504689.6445 - val_loss: 184070.9291\n",
      "Epoch 3394/5000\n",
      "134/134 [==============================] - 0s 430us/step - loss: 193965.7729 - val_loss: 298762.5994\n",
      "Epoch 3395/5000\n",
      "134/134 [==============================] - 0s 379us/step - loss: 213268.9496 - val_loss: 280893.9007\n",
      "Epoch 3396/5000\n",
      "134/134 [==============================] - 0s 351us/step - loss: 206912.0028 - val_loss: 156960.8396\n",
      "Epoch 3397/5000\n",
      "134/134 [==============================] - 0s 411us/step - loss: 160918.7578 - val_loss: 158409.2484\n",
      "Epoch 3398/5000\n",
      "134/134 [==============================] - 0s 361us/step - loss: 152868.2452 - val_loss: 146635.0079\n",
      "Epoch 3399/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 148535.0805 - val_loss: 148997.8204\n",
      "Epoch 3400/5000\n",
      "134/134 [==============================] - 0s 355us/step - loss: 163237.1966 - val_loss: 181846.9650\n",
      "Epoch 3401/5000\n",
      "134/134 [==============================] - 0s 482us/step - loss: 203139.4109 - val_loss: 257905.4748\n",
      "Epoch 3402/5000\n",
      "134/134 [==============================] - 0s 339us/step - loss: 210906.2860 - val_loss: 296151.9063\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3403/5000\n",
      "134/134 [==============================] - 0s 373us/step - loss: 242703.7571 - val_loss: 176632.3797\n",
      "Epoch 3404/5000\n",
      "134/134 [==============================] - 0s 444us/step - loss: 164310.2641 - val_loss: 217683.3246\n",
      "Epoch 3405/5000\n",
      "134/134 [==============================] - 0s 433us/step - loss: 161612.6698 - val_loss: 147791.6586\n",
      "Epoch 3406/5000\n",
      "134/134 [==============================] - 0s 341us/step - loss: 154268.5508 - val_loss: 148481.8825\n",
      "Epoch 3407/5000\n",
      "134/134 [==============================] - 0s 291us/step - loss: 156205.7822 - val_loss: 299959.6133\n",
      "Epoch 3408/5000\n",
      "134/134 [==============================] - 0s 350us/step - loss: 199254.5907 - val_loss: 189895.4098\n",
      "Epoch 3409/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 191234.0915 - val_loss: 205094.4823\n",
      "Epoch 3410/5000\n",
      "134/134 [==============================] - 0s 335us/step - loss: 284878.8236 - val_loss: 257446.9468\n",
      "Epoch 3411/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 228085.3061 - val_loss: 183949.6096\n",
      "Epoch 3412/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 213470.8735 - val_loss: 198357.3946\n",
      "Epoch 3413/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 257398.4092 - val_loss: 173918.5805\n",
      "Epoch 3414/5000\n",
      "134/134 [==============================] - 0s 304us/step - loss: 175521.1782 - val_loss: 229417.2733\n",
      "Epoch 3415/5000\n",
      "134/134 [==============================] - 0s 320us/step - loss: 204838.7702 - val_loss: 314155.7565\n",
      "Epoch 3416/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 177075.0490 - val_loss: 151796.6222\n",
      "Epoch 3417/5000\n",
      "134/134 [==============================] - 0s 426us/step - loss: 169279.7563 - val_loss: 180363.6166\n",
      "Epoch 3418/5000\n",
      "134/134 [==============================] - 0s 467us/step - loss: 177839.1280 - val_loss: 190402.9319\n",
      "Epoch 3419/5000\n",
      "134/134 [==============================] - 0s 439us/step - loss: 177511.5175 - val_loss: 210566.8827\n",
      "Epoch 3420/5000\n",
      "134/134 [==============================] - ETA: 0s - loss: 5936.91 - 0s 496us/step - loss: 179493.1320 - val_loss: 160164.1049\n",
      "Epoch 3421/5000\n",
      "134/134 [==============================] - 0s 430us/step - loss: 189818.1127 - val_loss: 158764.8743\n",
      "Epoch 3422/5000\n",
      "134/134 [==============================] - 0s 354us/step - loss: 174720.3306 - val_loss: 165632.0980\n",
      "Epoch 3423/5000\n",
      "134/134 [==============================] - 0s 388us/step - loss: 171627.8682 - val_loss: 304701.8298\n",
      "Epoch 3424/5000\n",
      "134/134 [==============================] - 0s 349us/step - loss: 181003.0871 - val_loss: 230567.2917\n",
      "Epoch 3425/5000\n",
      "134/134 [==============================] - 0s 360us/step - loss: 220494.1477 - val_loss: 179184.7192\n",
      "Epoch 3426/5000\n",
      "134/134 [==============================] - 0s 406us/step - loss: 193803.4816 - val_loss: 171164.3846\n",
      "Epoch 3427/5000\n",
      "134/134 [==============================] - 0s 352us/step - loss: 197480.4503 - val_loss: 161871.3148\n",
      "Epoch 3428/5000\n",
      "134/134 [==============================] - 0s 432us/step - loss: 185720.2928 - val_loss: 162635.0030\n",
      "Epoch 3429/5000\n",
      "134/134 [==============================] - 0s 392us/step - loss: 197610.3535 - val_loss: 172116.4697\n",
      "Epoch 3430/5000\n",
      "134/134 [==============================] - 0s 354us/step - loss: 296620.9771 - val_loss: 275255.9333\n",
      "Epoch 3431/5000\n",
      "134/134 [==============================] - 0s 409us/step - loss: 297590.2388 - val_loss: 485230.2341\n",
      "Epoch 3432/5000\n",
      "134/134 [==============================] - 0s 391us/step - loss: 343485.8619 - val_loss: 194247.0658\n",
      "Epoch 3433/5000\n",
      "134/134 [==============================] - 0s 390us/step - loss: 221001.8916 - val_loss: 402160.6474\n",
      "Epoch 3434/5000\n",
      "134/134 [==============================] - 0s 319us/step - loss: 193793.3519 - val_loss: 313977.4963\n",
      "Epoch 3435/5000\n",
      "134/134 [==============================] - 0s 364us/step - loss: 165673.6037 - val_loss: 186229.0672\n",
      "Epoch 3436/5000\n",
      "134/134 [==============================] - ETA: 0s - loss: 277091.81 - 0s 338us/step - loss: 173348.5933 - val_loss: 178441.9576\n",
      "Epoch 3437/5000\n",
      "134/134 [==============================] - 0s 291us/step - loss: 176585.8530 - val_loss: 184742.9874\n",
      "Epoch 3438/5000\n",
      "134/134 [==============================] - 0s 243us/step - loss: 167797.8384 - val_loss: 258419.1891\n",
      "Epoch 3439/5000\n",
      "134/134 [==============================] - 0s 245us/step - loss: 211001.5934 - val_loss: 592621.5196\n",
      "Epoch 3440/5000\n",
      "134/134 [==============================] - 0s 238us/step - loss: 334007.3484 - val_loss: 245516.9683\n",
      "Epoch 3441/5000\n",
      "134/134 [==============================] - 0s 523us/step - loss: 218051.9274 - val_loss: 185673.7906\n",
      "Epoch 3442/5000\n",
      "134/134 [==============================] - 0s 631us/step - loss: 169947.0702 - val_loss: 159698.5490\n",
      "Epoch 3443/5000\n",
      "134/134 [==============================] - 0s 709us/step - loss: 164491.3143 - val_loss: 151058.9433\n",
      "Epoch 3444/5000\n",
      "134/134 [==============================] - 0s 497us/step - loss: 159840.8204 - val_loss: 200908.8703\n",
      "Epoch 3445/5000\n",
      "134/134 [==============================] - 0s 494us/step - loss: 210125.9380 - val_loss: 176916.5112\n",
      "Epoch 3446/5000\n",
      "134/134 [==============================] - 0s 420us/step - loss: 199740.3411 - val_loss: 158226.6451\n",
      "Epoch 3447/5000\n",
      "134/134 [==============================] - 0s 472us/step - loss: 164676.9204 - val_loss: 311869.7115\n",
      "Epoch 3448/5000\n",
      "134/134 [==============================] - 0s 512us/step - loss: 213477.6608 - val_loss: 158994.8309\n",
      "Epoch 3449/5000\n",
      "134/134 [==============================] - 0s 477us/step - loss: 166570.9103 - val_loss: 426792.9366\n",
      "Epoch 3450/5000\n",
      "134/134 [==============================] - 0s 395us/step - loss: 366331.6537 - val_loss: 315741.1789\n",
      "Epoch 3451/5000\n",
      "134/134 [==============================] - 0s 411us/step - loss: 306108.7333 - val_loss: 155253.7218\n",
      "Epoch 3452/5000\n",
      "134/134 [==============================] - 0s 394us/step - loss: 175365.7584 - val_loss: 290712.9776\n",
      "Epoch 3453/5000\n",
      "134/134 [==============================] - 0s 507us/step - loss: 171252.4247 - val_loss: 152718.9081\n",
      "Epoch 3454/5000\n",
      "134/134 [==============================] - 0s 389us/step - loss: 158512.6859 - val_loss: 150302.7428\n",
      "Epoch 3455/5000\n",
      "134/134 [==============================] - 0s 423us/step - loss: 189275.9799 - val_loss: 154152.8750\n",
      "Epoch 3456/5000\n",
      "134/134 [==============================] - 0s 465us/step - loss: 154282.3726 - val_loss: 173315.9130\n",
      "Epoch 3457/5000\n",
      "134/134 [==============================] - 0s 420us/step - loss: 242094.6150 - val_loss: 187622.5431\n",
      "Epoch 3458/5000\n",
      "134/134 [==============================] - 0s 411us/step - loss: 186658.6101 - val_loss: 157131.6737\n",
      "Epoch 3459/5000\n",
      "134/134 [==============================] - 0s 452us/step - loss: 175044.5427 - val_loss: 208117.5578\n",
      "Epoch 3460/5000\n",
      "134/134 [==============================] - 0s 401us/step - loss: 164045.9248 - val_loss: 163267.9974\n",
      "Epoch 3461/5000\n",
      "134/134 [==============================] - 0s 377us/step - loss: 152230.9083 - val_loss: 169182.7402\n",
      "Epoch 3462/5000\n",
      "134/134 [==============================] - 0s 356us/step - loss: 159237.0916 - val_loss: 166689.2083\n",
      "Epoch 3463/5000\n",
      "134/134 [==============================] - 0s 473us/step - loss: 154064.0803 - val_loss: 174927.7873\n",
      "Epoch 3464/5000\n",
      "134/134 [==============================] - 0s 364us/step - loss: 179785.5253 - val_loss: 243540.6411\n",
      "Epoch 3465/5000\n",
      "134/134 [==============================] - 0s 404us/step - loss: 203210.9202 - val_loss: 193656.2582\n",
      "Epoch 3466/5000\n",
      "134/134 [==============================] - 0s 438us/step - loss: 196510.4241 - val_loss: 168047.5201\n",
      "Epoch 3467/5000\n",
      "134/134 [==============================] - 0s 401us/step - loss: 364104.0417 - val_loss: 280787.9310\n",
      "Epoch 3468/5000\n",
      "134/134 [==============================] - 0s 455us/step - loss: 300081.1747 - val_loss: 182211.6346\n",
      "Epoch 3469/5000\n",
      "134/134 [==============================] - 0s 354us/step - loss: 169519.1093 - val_loss: 371379.7015\n",
      "Epoch 3470/5000\n",
      "134/134 [==============================] - 0s 404us/step - loss: 423876.1256 - val_loss: 191339.6600\n",
      "Epoch 3471/5000\n",
      "134/134 [==============================] - 0s 408us/step - loss: 248500.5638 - val_loss: 157958.3920\n",
      "Epoch 3472/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 381us/step - loss: 192115.9963 - val_loss: 175891.9067\n",
      "Epoch 3473/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 169847.0789 - val_loss: 156243.0401\n",
      "Epoch 3474/5000\n",
      "134/134 [==============================] - 0s 381us/step - loss: 175874.7018 - val_loss: 163394.7535\n",
      "Epoch 3475/5000\n",
      "134/134 [==============================] - 0s 372us/step - loss: 157389.7206 - val_loss: 145605.3013\n",
      "Epoch 3476/5000\n",
      "134/134 [==============================] - 0s 336us/step - loss: 147940.8687 - val_loss: 207547.6409\n",
      "Epoch 3477/5000\n",
      "134/134 [==============================] - 0s 354us/step - loss: 157056.6595 - val_loss: 163983.3043\n",
      "Epoch 3478/5000\n",
      "134/134 [==============================] - 0s 373us/step - loss: 161472.9501 - val_loss: 281020.3326\n",
      "Epoch 3479/5000\n",
      "134/134 [==============================] - 0s 463us/step - loss: 191182.1663 - val_loss: 212622.4981\n",
      "Epoch 3480/5000\n",
      "134/134 [==============================] - 0s 447us/step - loss: 199216.0924 - val_loss: 155859.4590\n",
      "Epoch 3481/5000\n",
      "134/134 [==============================] - 0s 483us/step - loss: 217822.5010 - val_loss: 193976.1607\n",
      "Epoch 3482/5000\n",
      "134/134 [==============================] - 0s 474us/step - loss: 291597.1054 - val_loss: 225802.8638\n",
      "Epoch 3483/5000\n",
      "134/134 [==============================] - 0s 477us/step - loss: 184181.7309 - val_loss: 208439.9632\n",
      "Epoch 3484/5000\n",
      "134/134 [==============================] - 0s 409us/step - loss: 179904.1517 - val_loss: 170482.4058\n",
      "Epoch 3485/5000\n",
      "134/134 [==============================] - 0s 470us/step - loss: 181906.0879 - val_loss: 165965.9853\n",
      "Epoch 3486/5000\n",
      "134/134 [==============================] - 0s 389us/step - loss: 195719.7435 - val_loss: 168832.2845\n",
      "Epoch 3487/5000\n",
      "134/134 [==============================] - 0s 358us/step - loss: 165911.5308 - val_loss: 164313.4895\n",
      "Epoch 3488/5000\n",
      "134/134 [==============================] - 0s 346us/step - loss: 259509.2713 - val_loss: 180927.6535\n",
      "Epoch 3489/5000\n",
      "134/134 [==============================] - 0s 464us/step - loss: 173599.6764 - val_loss: 218960.2584\n",
      "Epoch 3490/5000\n",
      "134/134 [==============================] - 0s 392us/step - loss: 174417.3808 - val_loss: 175498.2491\n",
      "Epoch 3491/5000\n",
      "134/134 [==============================] - 0s 336us/step - loss: 158226.0938 - val_loss: 161209.0928\n",
      "Epoch 3492/5000\n",
      "134/134 [==============================] - 0s 361us/step - loss: 154685.5083 - val_loss: 171115.7796\n",
      "Epoch 3493/5000\n",
      "134/134 [==============================] - 0s 362us/step - loss: 170961.1886 - val_loss: 156634.8351\n",
      "Epoch 3494/5000\n",
      "134/134 [==============================] - 0s 429us/step - loss: 204114.8682 - val_loss: 229013.5448\n",
      "Epoch 3495/5000\n",
      "134/134 [==============================] - 0s 376us/step - loss: 217933.3317 - val_loss: 211836.5562\n",
      "Epoch 3496/5000\n",
      "134/134 [==============================] - 0s 450us/step - loss: 205258.2811 - val_loss: 249137.5728\n",
      "Epoch 3497/5000\n",
      "134/134 [==============================] - 0s 473us/step - loss: 248492.4204 - val_loss: 193740.2806\n",
      "Epoch 3498/5000\n",
      "134/134 [==============================] - 0s 382us/step - loss: 392999.4162 - val_loss: 231060.9296\n",
      "Epoch 3499/5000\n",
      "134/134 [==============================] - 0s 368us/step - loss: 288936.7366 - val_loss: 152182.7491\n",
      "Epoch 3500/5000\n",
      "134/134 [==============================] - 0s 432us/step - loss: 163775.3936 - val_loss: 148980.8116\n",
      "Epoch 3501/5000\n",
      "134/134 [==============================] - 0s 366us/step - loss: 152940.1500 - val_loss: 151242.5119\n",
      "Epoch 3502/5000\n",
      "134/134 [==============================] - 0s 338us/step - loss: 152663.2073 - val_loss: 180490.2118\n",
      "Epoch 3503/5000\n",
      "134/134 [==============================] - 0s 321us/step - loss: 187192.7506 - val_loss: 148114.7360\n",
      "Epoch 3504/5000\n",
      "134/134 [==============================] - 0s 332us/step - loss: 168349.1284 - val_loss: 294858.0513\n",
      "Epoch 3505/5000\n",
      "134/134 [==============================] - 0s 333us/step - loss: 161323.4874 - val_loss: 165485.7083\n",
      "Epoch 3506/5000\n",
      "134/134 [==============================] - 0s 373us/step - loss: 235412.2418 - val_loss: 316008.4627\n",
      "Epoch 3507/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 261664.0444 - val_loss: 190878.1462\n",
      "Epoch 3508/5000\n",
      "134/134 [==============================] - 0s 348us/step - loss: 183714.9639 - val_loss: 229888.9384\n",
      "Epoch 3509/5000\n",
      "134/134 [==============================] - 0s 368us/step - loss: 251227.6798 - val_loss: 229866.0469\n",
      "Epoch 3510/5000\n",
      "134/134 [==============================] - 0s 357us/step - loss: 391182.5002 - val_loss: 657703.3881\n",
      "Epoch 3511/5000\n",
      "134/134 [==============================] - 0s 395us/step - loss: 255771.9890 - val_loss: 154686.9160\n",
      "Epoch 3512/5000\n",
      "134/134 [==============================] - 0s 451us/step - loss: 162272.6924 - val_loss: 142468.0574\n",
      "Epoch 3513/5000\n",
      "134/134 [==============================] - 0s 402us/step - loss: 146343.2810 - val_loss: 153066.3909\n",
      "Epoch 3514/5000\n",
      "134/134 [==============================] - 0s 457us/step - loss: 148097.8897 - val_loss: 150214.1859\n",
      "Epoch 3515/5000\n",
      "134/134 [==============================] - 0s 441us/step - loss: 161511.3110 - val_loss: 148951.1448\n",
      "Epoch 3516/5000\n",
      "134/134 [==============================] - 0s 403us/step - loss: 156374.1553 - val_loss: 148344.8941\n",
      "Epoch 3517/5000\n",
      "134/134 [==============================] - 0s 502us/step - loss: 153612.3607 - val_loss: 161661.9618\n",
      "Epoch 3518/5000\n",
      "134/134 [==============================] - 0s 426us/step - loss: 158235.5149 - val_loss: 298158.2817\n",
      "Epoch 3519/5000\n",
      "134/134 [==============================] - 0s 369us/step - loss: 176927.4166 - val_loss: 185481.2302\n",
      "Epoch 3520/5000\n",
      "134/134 [==============================] - 0s 401us/step - loss: 179360.8347 - val_loss: 432764.0583\n",
      "Epoch 3521/5000\n",
      "134/134 [==============================] - 0s 401us/step - loss: 348813.3126 - val_loss: 189910.5919\n",
      "Epoch 3522/5000\n",
      "134/134 [==============================] - 0s 435us/step - loss: 196102.6481 - val_loss: 281683.1828\n",
      "Epoch 3523/5000\n",
      "134/134 [==============================] - 0s 410us/step - loss: 174443.5317 - val_loss: 167020.5746\n",
      "Epoch 3524/5000\n",
      "134/134 [==============================] - 0s 420us/step - loss: 154030.8667 - val_loss: 142304.0431\n",
      "Epoch 3525/5000\n",
      "134/134 [==============================] - 0s 390us/step - loss: 158793.7259 - val_loss: 146804.4328\n",
      "Epoch 3526/5000\n",
      "134/134 [==============================] - 0s 389us/step - loss: 158256.4391 - val_loss: 168098.2668\n",
      "Epoch 3527/5000\n",
      "134/134 [==============================] - 0s 425us/step - loss: 157410.0511 - val_loss: 148941.2871\n",
      "Epoch 3528/5000\n",
      "134/134 [==============================] - 0s 356us/step - loss: 155749.8668 - val_loss: 271460.6026\n",
      "Epoch 3529/5000\n",
      "134/134 [==============================] - 0s 360us/step - loss: 271385.4590 - val_loss: 193151.0606\n",
      "Epoch 3530/5000\n",
      "134/134 [==============================] - 0s 349us/step - loss: 201424.8365 - val_loss: 412296.4991\n",
      "Epoch 3531/5000\n",
      "134/134 [==============================] - 0s 381us/step - loss: 203123.2397 - val_loss: 163284.7855\n",
      "Epoch 3532/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 161177.5301 - val_loss: 262733.7383\n",
      "Epoch 3533/5000\n",
      "134/134 [==============================] - 0s 410us/step - loss: 229946.7315 - val_loss: 234718.8519\n",
      "Epoch 3534/5000\n",
      "134/134 [==============================] - 0s 405us/step - loss: 192047.8860 - val_loss: 186061.4011\n",
      "Epoch 3535/5000\n",
      "134/134 [==============================] - 0s 426us/step - loss: 172984.3237 - val_loss: 273409.1171\n",
      "Epoch 3536/5000\n",
      "134/134 [==============================] - 0s 379us/step - loss: 263519.0553 - val_loss: 466161.1751\n",
      "Epoch 3537/5000\n",
      "134/134 [==============================] - 0s 377us/step - loss: 218285.6002 - val_loss: 226612.1973\n",
      "Epoch 3538/5000\n",
      "134/134 [==============================] - 0s 338us/step - loss: 212785.9981 - val_loss: 223998.2626\n",
      "Epoch 3539/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 165078.4286 - val_loss: 144629.1681\n",
      "Epoch 3540/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 156401.4114 - val_loss: 145272.6416\n",
      "Epoch 3541/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 163237.5890 - val_loss: 140192.6842\n",
      "Epoch 3542/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 317us/step - loss: 143176.9197 - val_loss: 148567.1584\n",
      "Epoch 3543/5000\n",
      "134/134 [==============================] - 0s 439us/step - loss: 153788.8185 - val_loss: 161622.4900\n",
      "Epoch 3544/5000\n",
      "134/134 [==============================] - 0s 428us/step - loss: 155992.8834 - val_loss: 143394.5012\n",
      "Epoch 3545/5000\n",
      "134/134 [==============================] - 0s 448us/step - loss: 160505.7591 - val_loss: 210219.2192\n",
      "Epoch 3546/5000\n",
      "134/134 [==============================] - 0s 315us/step - loss: 184519.0054 - val_loss: 231915.2675\n",
      "Epoch 3547/5000\n",
      "134/134 [==============================] - 0s 349us/step - loss: 321556.8404 - val_loss: 211360.0021\n",
      "Epoch 3548/5000\n",
      "134/134 [==============================] - 0s 298us/step - loss: 193812.9963 - val_loss: 161340.4494\n",
      "Epoch 3549/5000\n",
      "134/134 [==============================] - 0s 337us/step - loss: 193260.7777 - val_loss: 208343.3990\n",
      "Epoch 3550/5000\n",
      "134/134 [==============================] - 0s 344us/step - loss: 221057.6128 - val_loss: 736738.1082\n",
      "Epoch 3551/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 220180.1500 - val_loss: 180610.0378\n",
      "Epoch 3552/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 220447.3626 - val_loss: 260033.7612\n",
      "Epoch 3553/5000\n",
      "134/134 [==============================] - 0s 333us/step - loss: 191211.7373 - val_loss: 160217.8008\n",
      "Epoch 3554/5000\n",
      "134/134 [==============================] - 0s 291us/step - loss: 210385.5749 - val_loss: 203534.6849\n",
      "Epoch 3555/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 166573.4017 - val_loss: 140791.9562\n",
      "Epoch 3556/5000\n",
      "134/134 [==============================] - 0s 332us/step - loss: 152685.0127 - val_loss: 156993.7941\n",
      "Epoch 3557/5000\n",
      "134/134 [==============================] - 0s 435us/step - loss: 155121.9023 - val_loss: 173532.6684\n",
      "Epoch 3558/5000\n",
      "134/134 [==============================] - 0s 412us/step - loss: 169948.5418 - val_loss: 158627.4781\n",
      "Epoch 3559/5000\n",
      "134/134 [==============================] - 0s 441us/step - loss: 168568.8362 - val_loss: 564527.6912\n",
      "Epoch 3560/5000\n",
      "134/134 [==============================] - 0s 414us/step - loss: 435697.3648 - val_loss: 207644.5098\n",
      "Epoch 3561/5000\n",
      "134/134 [==============================] - 0s 345us/step - loss: 187897.2974 - val_loss: 151759.0613\n",
      "Epoch 3562/5000\n",
      "134/134 [==============================] - 0s 282us/step - loss: 158089.0039 - val_loss: 143088.3340\n",
      "Epoch 3563/5000\n",
      "134/134 [==============================] - 0s 337us/step - loss: 143351.1694 - val_loss: 144119.7283\n",
      "Epoch 3564/5000\n",
      "134/134 [==============================] - 0s 401us/step - loss: 139606.8507 - val_loss: 140264.7913\n",
      "Epoch 3565/5000\n",
      "134/134 [==============================] - 0s 498us/step - loss: 141897.4666 - val_loss: 142457.3449\n",
      "Epoch 3566/5000\n",
      "134/134 [==============================] - 0s 411us/step - loss: 147490.9949 - val_loss: 137162.2682\n",
      "Epoch 3567/5000\n",
      "134/134 [==============================] - 0s 434us/step - loss: 146150.8802 - val_loss: 203821.0541\n",
      "Epoch 3568/5000\n",
      "134/134 [==============================] - 0s 493us/step - loss: 152802.6406 - val_loss: 156049.2794\n",
      "Epoch 3569/5000\n",
      "134/134 [==============================] - 0s 462us/step - loss: 159264.5347 - val_loss: 199668.2278\n",
      "Epoch 3570/5000\n",
      "134/134 [==============================] - 0s 368us/step - loss: 194662.1048 - val_loss: 237574.6383\n",
      "Epoch 3571/5000\n",
      "134/134 [==============================] - 0s 343us/step - loss: 338763.4191 - val_loss: 487678.4524\n",
      "Epoch 3572/5000\n",
      "134/134 [==============================] - 0s 379us/step - loss: 263939.6712 - val_loss: 171515.5273\n",
      "Epoch 3573/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 182808.2025 - val_loss: 204748.0072\n",
      "Epoch 3574/5000\n",
      "134/134 [==============================] - 0s 365us/step - loss: 178362.7358 - val_loss: 225125.8057\n",
      "Epoch 3575/5000\n",
      "134/134 [==============================] - 0s 507us/step - loss: 233422.4637 - val_loss: 188309.5868\n",
      "Epoch 3576/5000\n",
      "134/134 [==============================] - 0s 473us/step - loss: 318945.2754 - val_loss: 179216.9307\n",
      "Epoch 3577/5000\n",
      "134/134 [==============================] - 0s 432us/step - loss: 207258.8041 - val_loss: 623168.0756\n",
      "Epoch 3578/5000\n",
      "134/134 [==============================] - 0s 408us/step - loss: 368924.3523 - val_loss: 297279.4058\n",
      "Epoch 3579/5000\n",
      "134/134 [==============================] - 0s 447us/step - loss: 242948.2605 - val_loss: 257540.2565\n",
      "Epoch 3580/5000\n",
      "134/134 [==============================] - 0s 417us/step - loss: 210117.9672 - val_loss: 633960.3377\n",
      "Epoch 3581/5000\n",
      "134/134 [==============================] - 0s 445us/step - loss: 282244.9713 - val_loss: 901969.6026\n",
      "Epoch 3582/5000\n",
      "134/134 [==============================] - 0s 419us/step - loss: 286806.6514 - val_loss: 155235.2281\n",
      "Epoch 3583/5000\n",
      "134/134 [==============================] - 0s 414us/step - loss: 172697.8541 - val_loss: 142498.1129\n",
      "Epoch 3584/5000\n",
      "134/134 [==============================] - 0s 375us/step - loss: 141735.0615 - val_loss: 137236.4529\n",
      "Epoch 3585/5000\n",
      "134/134 [==============================] - 0s 333us/step - loss: 147795.1461 - val_loss: 162331.2824\n",
      "Epoch 3586/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 143381.6950 - val_loss: 140660.4244\n",
      "Epoch 3587/5000\n",
      "134/134 [==============================] - 0s 359us/step - loss: 141686.1260 - val_loss: 138021.5620\n",
      "Epoch 3588/5000\n",
      "134/134 [==============================] - 0s 378us/step - loss: 154425.7876 - val_loss: 160037.1544\n",
      "Epoch 3589/5000\n",
      "134/134 [==============================] - 0s 342us/step - loss: 146528.6075 - val_loss: 170687.9771\n",
      "Epoch 3590/5000\n",
      "134/134 [==============================] - 0s 365us/step - loss: 154447.0541 - val_loss: 175552.6481\n",
      "Epoch 3591/5000\n",
      "134/134 [==============================] - 0s 338us/step - loss: 206865.2608 - val_loss: 177672.4506\n",
      "Epoch 3592/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 224772.4604 - val_loss: 340142.5285\n",
      "Epoch 3593/5000\n",
      "134/134 [==============================] - 0s 337us/step - loss: 206430.8656 - val_loss: 409909.0597\n",
      "Epoch 3594/5000\n",
      "134/134 [==============================] - 0s 331us/step - loss: 414466.8898 - val_loss: 559047.0896\n",
      "Epoch 3595/5000\n",
      "134/134 [==============================] - 0s 319us/step - loss: 310060.9743 - val_loss: 151826.2896\n",
      "Epoch 3596/5000\n",
      "134/134 [==============================] - 0s 333us/step - loss: 205099.5136 - val_loss: 166336.9737\n",
      "Epoch 3597/5000\n",
      "134/134 [==============================] - 0s 346us/step - loss: 156864.7952 - val_loss: 147752.1371\n",
      "Epoch 3598/5000\n",
      "134/134 [==============================] - 0s 334us/step - loss: 156427.6019 - val_loss: 256113.3591\n",
      "Epoch 3599/5000\n",
      "134/134 [==============================] - 0s 376us/step - loss: 167837.2139 - val_loss: 153344.8125\n",
      "Epoch 3600/5000\n",
      "134/134 [==============================] - 0s 404us/step - loss: 174430.1077 - val_loss: 220713.5224\n",
      "Epoch 3601/5000\n",
      "134/134 [==============================] - 0s 456us/step - loss: 195470.4885 - val_loss: 562151.1712\n",
      "Epoch 3602/5000\n",
      "134/134 [==============================] - 0s 345us/step - loss: 277861.2331 - val_loss: 289083.7687\n",
      "Epoch 3603/5000\n",
      "134/134 [==============================] - 0s 370us/step - loss: 276499.5222 - val_loss: 245046.6315\n",
      "Epoch 3604/5000\n",
      "134/134 [==============================] - 0s 380us/step - loss: 259143.0606 - val_loss: 288549.2244\n",
      "Epoch 3605/5000\n",
      "134/134 [==============================] - 0s 330us/step - loss: 211170.0553 - val_loss: 147436.9485\n",
      "Epoch 3606/5000\n",
      "134/134 [==============================] - 0s 294us/step - loss: 151987.2400 - val_loss: 279265.1227\n",
      "Epoch 3607/5000\n",
      "134/134 [==============================] - 0s 334us/step - loss: 183341.6395 - val_loss: 256319.6539\n",
      "Epoch 3608/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 204803.9156 - val_loss: 158633.6598\n",
      "Epoch 3609/5000\n",
      "134/134 [==============================] - 0s 359us/step - loss: 149913.0772 - val_loss: 302763.5912\n",
      "Epoch 3610/5000\n",
      "134/134 [==============================] - 0s 372us/step - loss: 171242.2990 - val_loss: 360901.5700\n",
      "Epoch 3611/5000\n",
      "134/134 [==============================] - 0s 335us/step - loss: 223578.9610 - val_loss: 153129.7276\n",
      "Epoch 3612/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 347us/step - loss: 193184.8649 - val_loss: 143304.4991\n",
      "Epoch 3613/5000\n",
      "134/134 [==============================] - 0s 399us/step - loss: 145570.2549 - val_loss: 138461.1208\n",
      "Epoch 3614/5000\n",
      "134/134 [==============================] - 0s 320us/step - loss: 146142.1517 - val_loss: 140193.4806\n",
      "Epoch 3615/5000\n",
      "134/134 [==============================] - 0s 378us/step - loss: 164843.3777 - val_loss: 161657.1343\n",
      "Epoch 3616/5000\n",
      "134/134 [==============================] - 0s 339us/step - loss: 173334.0619 - val_loss: 296356.0448\n",
      "Epoch 3617/5000\n",
      "134/134 [==============================] - 0s 358us/step - loss: 192321.0302 - val_loss: 332301.7080\n",
      "Epoch 3618/5000\n",
      "134/134 [==============================] - 0s 352us/step - loss: 290309.2739 - val_loss: 741507.4151\n",
      "Epoch 3619/5000\n",
      "134/134 [==============================] - 0s 369us/step - loss: 283670.9302 - val_loss: 164811.9422\n",
      "Epoch 3620/5000\n",
      "134/134 [==============================] - 0s 371us/step - loss: 172658.2301 - val_loss: 175051.2827\n",
      "Epoch 3621/5000\n",
      "134/134 [==============================] - 0s 330us/step - loss: 168909.6743 - val_loss: 247448.9121\n",
      "Epoch 3622/5000\n",
      "134/134 [==============================] - 0s 390us/step - loss: 208866.2682 - val_loss: 184819.2017\n",
      "Epoch 3623/5000\n",
      "134/134 [==============================] - 0s 379us/step - loss: 158932.9114 - val_loss: 409312.1250\n",
      "Epoch 3624/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 217831.8727 - val_loss: 154720.2491\n",
      "Epoch 3625/5000\n",
      "134/134 [==============================] - 0s 379us/step - loss: 199197.6734 - val_loss: 179082.4764\n",
      "Epoch 3626/5000\n",
      "134/134 [==============================] - 0s 283us/step - loss: 192377.4766 - val_loss: 171789.4368\n",
      "Epoch 3627/5000\n",
      "134/134 [==============================] - 0s 331us/step - loss: 154346.2946 - val_loss: 164367.4960\n",
      "Epoch 3628/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 171458.2083 - val_loss: 259705.9925\n",
      "Epoch 3629/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 382904.5358 - val_loss: 373401.4911\n",
      "Epoch 3630/5000\n",
      "134/134 [==============================] - 0s 331us/step - loss: 183582.8475 - val_loss: 148282.3055\n",
      "Epoch 3631/5000\n",
      "134/134 [==============================] - 0s 343us/step - loss: 144324.7011 - val_loss: 142296.1842\n",
      "Epoch 3632/5000\n",
      "134/134 [==============================] - 0s 348us/step - loss: 145236.1832 - val_loss: 138878.3470\n",
      "Epoch 3633/5000\n",
      "134/134 [==============================] - 0s 329us/step - loss: 140350.0220 - val_loss: 157638.0082\n",
      "Epoch 3634/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 147284.0985 - val_loss: 146175.7610\n",
      "Epoch 3635/5000\n",
      "134/134 [==============================] - 0s 342us/step - loss: 146821.7070 - val_loss: 153470.1572\n",
      "Epoch 3636/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 197165.7857 - val_loss: 182782.3018\n",
      "Epoch 3637/5000\n",
      "134/134 [==============================] - 0s 338us/step - loss: 191783.8634 - val_loss: 248274.4268\n",
      "Epoch 3638/5000\n",
      "134/134 [==============================] - 0s 333us/step - loss: 182367.9535 - val_loss: 182100.6577\n",
      "Epoch 3639/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 193107.9026 - val_loss: 201928.6418\n",
      "Epoch 3640/5000\n",
      "134/134 [==============================] - 0s 382us/step - loss: 169264.6920 - val_loss: 226905.1516\n",
      "Epoch 3641/5000\n",
      "134/134 [==============================] - 0s 331us/step - loss: 168217.6828 - val_loss: 157561.8979\n",
      "Epoch 3642/5000\n",
      "134/134 [==============================] - 0s 408us/step - loss: 160706.2268 - val_loss: 193005.0280\n",
      "Epoch 3643/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 168217.0237 - val_loss: 151770.2425\n",
      "Epoch 3644/5000\n",
      "134/134 [==============================] - 0s 350us/step - loss: 233836.7607 - val_loss: 296450.6507\n",
      "Epoch 3645/5000\n",
      "134/134 [==============================] - 0s 339us/step - loss: 201676.9830 - val_loss: 161294.3846\n",
      "Epoch 3646/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 169078.6549 - val_loss: 365787.2369\n",
      "Epoch 3647/5000\n",
      "134/134 [==============================] - 0s 336us/step - loss: 198453.5279 - val_loss: 158704.0466\n",
      "Epoch 3648/5000\n",
      "134/134 [==============================] - 0s 353us/step - loss: 164419.9330 - val_loss: 303731.3382\n",
      "Epoch 3649/5000\n",
      "134/134 [==============================] - 0s 323us/step - loss: 308488.6321 - val_loss: 183627.9198\n",
      "Epoch 3650/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 173944.9726 - val_loss: 137781.5051\n",
      "Epoch 3651/5000\n",
      "134/134 [==============================] - 0s 353us/step - loss: 149401.3089 - val_loss: 388842.9277\n",
      "Epoch 3652/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 259848.2941 - val_loss: 367709.9081\n",
      "Epoch 3653/5000\n",
      "134/134 [==============================] - 0s 341us/step - loss: 258186.7102 - val_loss: 136686.3417\n",
      "Epoch 3654/5000\n",
      "134/134 [==============================] - 0s 332us/step - loss: 138860.9228 - val_loss: 133584.0571\n",
      "Epoch 3655/5000\n",
      "134/134 [==============================] - 0s 360us/step - loss: 136938.4708 - val_loss: 132013.4282\n",
      "Epoch 3656/5000\n",
      "134/134 [==============================] - 0s 360us/step - loss: 137971.8847 - val_loss: 146766.9489\n",
      "Epoch 3657/5000\n",
      "134/134 [==============================] - 0s 436us/step - loss: 142361.2870 - val_loss: 140203.1147\n",
      "Epoch 3658/5000\n",
      "134/134 [==============================] - 0s 415us/step - loss: 145064.8685 - val_loss: 140664.2731\n",
      "Epoch 3659/5000\n",
      "134/134 [==============================] - 0s 444us/step - loss: 150398.2294 - val_loss: 202679.4312\n",
      "Epoch 3660/5000\n",
      "134/134 [==============================] - 0s 385us/step - loss: 152660.7455 - val_loss: 146458.7164\n",
      "Epoch 3661/5000\n",
      "134/134 [==============================] - 0s 377us/step - loss: 181256.8159 - val_loss: 199754.7535\n",
      "Epoch 3662/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 297444.4426 - val_loss: 208450.6653\n",
      "Epoch 3663/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 156694.6529 - val_loss: 143740.6686\n",
      "Epoch 3664/5000\n",
      "134/134 [==============================] - 0s 290us/step - loss: 148666.4249 - val_loss: 143283.3174\n",
      "Epoch 3665/5000\n",
      "134/134 [==============================] - 0s 378us/step - loss: 149046.7383 - val_loss: 149362.8594\n",
      "Epoch 3666/5000\n",
      "134/134 [==============================] - 0s 345us/step - loss: 173672.5122 - val_loss: 477761.3424\n",
      "Epoch 3667/5000\n",
      "134/134 [==============================] - 0s 344us/step - loss: 379954.1498 - val_loss: 163610.6831\n",
      "Epoch 3668/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 161265.1173 - val_loss: 461493.9897\n",
      "Epoch 3669/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 328986.9299 - val_loss: 243426.0376\n",
      "Epoch 3670/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 208564.3946 - val_loss: 162057.1817\n",
      "Epoch 3671/5000\n",
      "134/134 [==============================] - 0s 323us/step - loss: 149429.3415 - val_loss: 137109.0714\n",
      "Epoch 3672/5000\n",
      "134/134 [==============================] - 0s 341us/step - loss: 139447.2618 - val_loss: 134040.6343\n",
      "Epoch 3673/5000\n",
      "134/134 [==============================] - 0s 317us/step - loss: 134866.7994 - val_loss: 133925.9653\n",
      "Epoch 3674/5000\n",
      "134/134 [==============================] - 0s 292us/step - loss: 133871.5786 - val_loss: 138820.9951\n",
      "Epoch 3675/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 136050.4474 - val_loss: 172458.9300\n",
      "Epoch 3676/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 200219.9033 - val_loss: 167217.6702\n",
      "Epoch 3677/5000\n",
      "134/134 [==============================] - 0s 325us/step - loss: 157092.7045 - val_loss: 170754.7320\n",
      "Epoch 3678/5000\n",
      "134/134 [==============================] - 0s 411us/step - loss: 228324.7894 - val_loss: 178747.9753\n",
      "Epoch 3679/5000\n",
      "134/134 [==============================] - 0s 377us/step - loss: 186129.9440 - val_loss: 137745.6490\n",
      "Epoch 3680/5000\n",
      "134/134 [==============================] - 0s 392us/step - loss: 137657.5149 - val_loss: 133240.4035\n",
      "Epoch 3681/5000\n",
      "134/134 [==============================] - 0s 409us/step - loss: 142371.3601 - val_loss: 371375.8687\n",
      "Epoch 3682/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 363us/step - loss: 279338.0916 - val_loss: 259752.2108\n",
      "Epoch 3683/5000\n",
      "134/134 [==============================] - 0s 363us/step - loss: 257659.5873 - val_loss: 189022.0373\n",
      "Epoch 3684/5000\n",
      "134/134 [==============================] - 0s 337us/step - loss: 152070.0333 - val_loss: 134948.8946\n",
      "Epoch 3685/5000\n",
      "134/134 [==============================] - 0s 292us/step - loss: 136429.3555 - val_loss: 154983.5828\n",
      "Epoch 3686/5000\n",
      "134/134 [==============================] - 0s 348us/step - loss: 144537.3481 - val_loss: 156154.5823\n",
      "Epoch 3687/5000\n",
      "134/134 [==============================] - 0s 317us/step - loss: 171934.4184 - val_loss: 161674.9284\n",
      "Epoch 3688/5000\n",
      "134/134 [==============================] - 0s 339us/step - loss: 206866.5526 - val_loss: 161474.5590\n",
      "Epoch 3689/5000\n",
      "134/134 [==============================] - 0s 348us/step - loss: 188006.7196 - val_loss: 155249.1891\n",
      "Epoch 3690/5000\n",
      "134/134 [==============================] - 0s 325us/step - loss: 143225.6021 - val_loss: 154603.5714\n",
      "Epoch 3691/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 142347.0782 - val_loss: 159051.0564\n",
      "Epoch 3692/5000\n",
      "134/134 [==============================] - 0s 301us/step - loss: 139940.4731 - val_loss: 136110.6954\n",
      "Epoch 3693/5000\n",
      "134/134 [==============================] - 0s 330us/step - loss: 143958.9806 - val_loss: 344939.1175\n",
      "Epoch 3694/5000\n",
      "134/134 [==============================] - 0s 320us/step - loss: 257660.6698 - val_loss: 164078.7264\n",
      "Epoch 3695/5000\n",
      "134/134 [==============================] - 0s 331us/step - loss: 193966.5914 - val_loss: 166660.4538\n",
      "Epoch 3696/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 145980.6727 - val_loss: 137243.3015\n",
      "Epoch 3697/5000\n",
      "134/134 [==============================] - 0s 335us/step - loss: 139110.3044 - val_loss: 144255.7924\n",
      "Epoch 3698/5000\n",
      "134/134 [==============================] - 0s 332us/step - loss: 138757.5171 - val_loss: 136863.2796\n",
      "Epoch 3699/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 137196.9133 - val_loss: 143851.2185\n",
      "Epoch 3700/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 139063.1262 - val_loss: 134215.1245\n",
      "Epoch 3701/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 162275.8631 - val_loss: 197653.9310\n",
      "Epoch 3702/5000\n",
      "134/134 [==============================] - 0s 281us/step - loss: 265891.3301 - val_loss: 167998.4977\n",
      "Epoch 3703/5000\n",
      "134/134 [==============================] - 0s 338us/step - loss: 212448.3970 - val_loss: 621790.5672\n",
      "Epoch 3704/5000\n",
      "134/134 [==============================] - 0s 333us/step - loss: 483174.3470 - val_loss: 241416.9340\n",
      "Epoch 3705/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 222259.5747 - val_loss: 142082.2218\n",
      "Epoch 3706/5000\n",
      "134/134 [==============================] - 0s 332us/step - loss: 143697.4189 - val_loss: 134076.0588\n",
      "Epoch 3707/5000\n",
      "134/134 [==============================] - 0s 324us/step - loss: 141710.2887 - val_loss: 135235.2500\n",
      "Epoch 3708/5000\n",
      "134/134 [==============================] - 0s 335us/step - loss: 145377.9813 - val_loss: 152038.7474\n",
      "Epoch 3709/5000\n",
      "134/134 [==============================] - 0s 339us/step - loss: 140054.1049 - val_loss: 129539.1537\n",
      "Epoch 3710/5000\n",
      "134/134 [==============================] - 0s 353us/step - loss: 138554.5050 - val_loss: 140348.1264\n",
      "Epoch 3711/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 146808.2339 - val_loss: 163997.2332\n",
      "Epoch 3712/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 153847.7365 - val_loss: 177636.5126\n",
      "Epoch 3713/5000\n",
      "134/134 [==============================] - 0s 368us/step - loss: 158618.3130 - val_loss: 185416.6959\n",
      "Epoch 3714/5000\n",
      "134/134 [==============================] - 0s 320us/step - loss: 171926.7161 - val_loss: 162911.6364\n",
      "Epoch 3715/5000\n",
      "134/134 [==============================] - 0s 338us/step - loss: 243408.4582 - val_loss: 140463.7726\n",
      "Epoch 3716/5000\n",
      "134/134 [==============================] - 0s 300us/step - loss: 210775.4369 - val_loss: 171530.4431\n",
      "Epoch 3717/5000\n",
      "134/134 [==============================] - 0s 323us/step - loss: 198084.8271 - val_loss: 175200.1364\n",
      "Epoch 3718/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 195203.2645 - val_loss: 163969.1924\n",
      "Epoch 3719/5000\n",
      "134/134 [==============================] - 0s 333us/step - loss: 165144.7831 - val_loss: 589721.8195\n",
      "Epoch 3720/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 246097.7371 - val_loss: 305963.6595\n",
      "Epoch 3721/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 219176.5341 - val_loss: 299486.4475\n",
      "Epoch 3722/5000\n",
      "134/134 [==============================] - 0s 325us/step - loss: 251656.5180 - val_loss: 183376.5618\n",
      "Epoch 3723/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 181391.6627 - val_loss: 290030.6593\n",
      "Epoch 3724/5000\n",
      "134/134 [==============================] - 0s 332us/step - loss: 192682.7804 - val_loss: 242327.6320\n",
      "Epoch 3725/5000\n",
      "134/134 [==============================] - 0s 318us/step - loss: 408534.2264 - val_loss: 594708.4058\n",
      "Epoch 3726/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 449902.2147 - val_loss: 211607.8265\n",
      "Epoch 3727/5000\n",
      "134/134 [==============================] - 0s 329us/step - loss: 168407.6649 - val_loss: 185215.4072\n",
      "Epoch 3728/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 140800.5817 - val_loss: 135462.0728\n",
      "Epoch 3729/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 135613.6198 - val_loss: 136980.9046\n",
      "Epoch 3730/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 141800.6590 - val_loss: 134291.6360\n",
      "Epoch 3731/5000\n",
      "134/134 [==============================] - 0s 329us/step - loss: 140621.9879 - val_loss: 278900.2771\n",
      "Epoch 3732/5000\n",
      "134/134 [==============================] - 0s 289us/step - loss: 179366.8812 - val_loss: 425277.6987\n",
      "Epoch 3733/5000\n",
      "134/134 [==============================] - 0s 350us/step - loss: 224875.6070 - val_loss: 174378.8888\n",
      "Epoch 3734/5000\n",
      "134/134 [==============================] - 0s 335us/step - loss: 176043.2766 - val_loss: 276821.8032\n",
      "Epoch 3735/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 283634.5896 - val_loss: 212341.0872\n",
      "Epoch 3736/5000\n",
      "134/134 [==============================] - 0s 321us/step - loss: 161976.8947 - val_loss: 170310.3470\n",
      "Epoch 3737/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 176436.9632 - val_loss: 158535.2733\n",
      "Epoch 3738/5000\n",
      "134/134 [==============================] - 0s 311us/step - loss: 139404.2131 - val_loss: 129777.0854\n",
      "Epoch 3739/5000\n",
      "134/134 [==============================] - 0s 285us/step - loss: 134581.1209 - val_loss: 135129.7234\n",
      "Epoch 3740/5000\n",
      "134/134 [==============================] - 0s 291us/step - loss: 133771.2861 - val_loss: 132750.3706\n",
      "Epoch 3741/5000\n",
      "134/134 [==============================] - 0s 318us/step - loss: 135572.0031 - val_loss: 133209.0784\n",
      "Epoch 3742/5000\n",
      "134/134 [==============================] - 0s 329us/step - loss: 138471.8769 - val_loss: 136391.7188\n",
      "Epoch 3743/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 137013.8271 - val_loss: 157132.9156\n",
      "Epoch 3744/5000\n",
      "134/134 [==============================] - 0s 363us/step - loss: 163758.8393 - val_loss: 381392.9081\n",
      "Epoch 3745/5000\n",
      "134/134 [==============================] - 0s 424us/step - loss: 203833.8983 - val_loss: 231194.8573\n",
      "Epoch 3746/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 176179.1989 - val_loss: 138754.8396\n",
      "Epoch 3747/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 212108.1227 - val_loss: 189301.5625\n",
      "Epoch 3748/5000\n",
      "134/134 [==============================] - 0s 357us/step - loss: 298451.0401 - val_loss: 410613.1402\n",
      "Epoch 3749/5000\n",
      "134/134 [==============================] - 0s 381us/step - loss: 350416.4418 - val_loss: 186070.6129\n",
      "Epoch 3750/5000\n",
      "134/134 [==============================] - 0s 357us/step - loss: 168166.6700 - val_loss: 157372.8862\n",
      "Epoch 3751/5000\n",
      "134/134 [==============================] - 0s 339us/step - loss: 138195.9825 - val_loss: 155044.6581\n",
      "Epoch 3752/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 347us/step - loss: 137804.1033 - val_loss: 139945.3696\n",
      "Epoch 3753/5000\n",
      "134/134 [==============================] - 0s 386us/step - loss: 141581.6405 - val_loss: 154618.3603\n",
      "Epoch 3754/5000\n",
      "134/134 [==============================] - 0s 334us/step - loss: 138850.7586 - val_loss: 199361.3074\n",
      "Epoch 3755/5000\n",
      "134/134 [==============================] - 0s 352us/step - loss: 210998.7101 - val_loss: 146256.7892\n",
      "Epoch 3756/5000\n",
      "134/134 [==============================] - 0s 331us/step - loss: 154089.4969 - val_loss: 235645.1730\n",
      "Epoch 3757/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 149055.1798 - val_loss: 151211.2493\n",
      "Epoch 3758/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 151938.4879 - val_loss: 190221.2360\n",
      "Epoch 3759/5000\n",
      "134/134 [==============================] - 0s 342us/step - loss: 139447.4475 - val_loss: 129688.2041\n",
      "Epoch 3760/5000\n",
      "134/134 [==============================] - 0s 362us/step - loss: 141980.4583 - val_loss: 162690.2682\n",
      "Epoch 3761/5000\n",
      "134/134 [==============================] - 0s 320us/step - loss: 173004.4064 - val_loss: 154537.5166\n",
      "Epoch 3762/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 205586.6539 - val_loss: 202441.0847\n",
      "Epoch 3763/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 218812.8286 - val_loss: 230592.4970\n",
      "Epoch 3764/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 239503.7355 - val_loss: 153507.1241\n",
      "Epoch 3765/5000\n",
      "134/134 [==============================] - 0s 330us/step - loss: 227465.1185 - val_loss: 185570.5525\n",
      "Epoch 3766/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 267576.1442 - val_loss: 272921.7810\n",
      "Epoch 3767/5000\n",
      "134/134 [==============================] - 0s 330us/step - loss: 289891.4132 - val_loss: 590147.0746\n",
      "Epoch 3768/5000\n",
      "134/134 [==============================] - 0s 343us/step - loss: 208871.2483 - val_loss: 148267.2964\n",
      "Epoch 3769/5000\n",
      "134/134 [==============================] - 0s 336us/step - loss: 154011.8563 - val_loss: 159345.3570\n",
      "Epoch 3770/5000\n",
      "134/134 [==============================] - 0s 318us/step - loss: 176040.2142 - val_loss: 140828.2006\n",
      "Epoch 3771/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 152601.4404 - val_loss: 154134.9853\n",
      "Epoch 3772/5000\n",
      "134/134 [==============================] - 0s 331us/step - loss: 189381.1397 - val_loss: 156583.2745\n",
      "Epoch 3773/5000\n",
      "134/134 [==============================] - 0s 333us/step - loss: 170893.8530 - val_loss: 189700.1619\n",
      "Epoch 3774/5000\n",
      "134/134 [==============================] - 0s 348us/step - loss: 165911.3623 - val_loss: 193321.4837\n",
      "Epoch 3775/5000\n",
      "134/134 [==============================] - 0s 342us/step - loss: 161942.7711 - val_loss: 132045.5233\n",
      "Epoch 3776/5000\n",
      "134/134 [==============================] - 0s 346us/step - loss: 141596.6262 - val_loss: 171439.6693\n",
      "Epoch 3777/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 215224.8791 - val_loss: 197984.9475\n",
      "Epoch 3778/5000\n",
      "134/134 [==============================] - 0s 359us/step - loss: 173598.9031 - val_loss: 148901.2848\n",
      "Epoch 3779/5000\n",
      "134/134 [==============================] - 0s 333us/step - loss: 175915.3573 - val_loss: 557015.1175\n",
      "Epoch 3780/5000\n",
      "134/134 [==============================] - 0s 338us/step - loss: 214545.2806 - val_loss: 182019.9704\n",
      "Epoch 3781/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 201226.1054 - val_loss: 415316.8293\n",
      "Epoch 3782/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 223748.4011 - val_loss: 150892.3305\n",
      "Epoch 3783/5000\n",
      "134/134 [==============================] - 0s 342us/step - loss: 168465.0339 - val_loss: 140049.6824\n",
      "Epoch 3784/5000\n",
      "134/134 [==============================] - 0s 297us/step - loss: 148072.0863 - val_loss: 143218.1418\n",
      "Epoch 3785/5000\n",
      "134/134 [==============================] - 0s 348us/step - loss: 148560.1866 - val_loss: 173334.2388\n",
      "Epoch 3786/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 154624.5238 - val_loss: 215945.1819\n",
      "Epoch 3787/5000\n",
      "134/134 [==============================] - 0s 304us/step - loss: 287621.6286 - val_loss: 183341.6525\n",
      "Epoch 3788/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 184891.4724 - val_loss: 134262.7337\n",
      "Epoch 3789/5000\n",
      "134/134 [==============================] - 0s 299us/step - loss: 132112.9153 - val_loss: 138782.9639\n",
      "Epoch 3790/5000\n",
      "134/134 [==============================] - 0s 325us/step - loss: 136759.9223 - val_loss: 244844.4506\n",
      "Epoch 3791/5000\n",
      "134/134 [==============================] - 0s 297us/step - loss: 197598.2374 - val_loss: 208559.2134\n",
      "Epoch 3792/5000\n",
      "134/134 [==============================] - 0s 380us/step - loss: 214746.1024 - val_loss: 141052.3766\n",
      "Epoch 3793/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 152681.5907 - val_loss: 263596.7374\n",
      "Epoch 3794/5000\n",
      "134/134 [==============================] - 0s 342us/step - loss: 159827.8116 - val_loss: 174798.3358\n",
      "Epoch 3795/5000\n",
      "134/134 [==============================] - 0s 301us/step - loss: 215000.4059 - val_loss: 140325.8337\n",
      "Epoch 3796/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 173502.2823 - val_loss: 171967.9268\n",
      "Epoch 3797/5000\n",
      "134/134 [==============================] - 0s 414us/step - loss: 154091.3484 - val_loss: 152192.3659\n",
      "Epoch 3798/5000\n",
      "134/134 [==============================] - 0s 451us/step - loss: 180393.6177 - val_loss: 141231.1651\n",
      "Epoch 3799/5000\n",
      "134/134 [==============================] - 0s 466us/step - loss: 134349.9088 - val_loss: 129901.0250\n",
      "Epoch 3800/5000\n",
      "134/134 [==============================] - 0s 456us/step - loss: 143352.3535 - val_loss: 144144.2395\n",
      "Epoch 3801/5000\n",
      "134/134 [==============================] - 0s 395us/step - loss: 150000.7295 - val_loss: 216150.3368\n",
      "Epoch 3802/5000\n",
      "134/134 [==============================] - 0s 458us/step - loss: 176874.2370 - val_loss: 165865.3626\n",
      "Epoch 3803/5000\n",
      "134/134 [==============================] - 0s 433us/step - loss: 151190.0887 - val_loss: 284577.2910\n",
      "Epoch 3804/5000\n",
      "134/134 [==============================] - 0s 406us/step - loss: 257355.7542 - val_loss: 1513581.0849\n",
      "Epoch 3805/5000\n",
      "134/134 [==============================] - 0s 397us/step - loss: 569725.0324 - val_loss: 319348.5014\n",
      "Epoch 3806/5000\n",
      "134/134 [==============================] - 0s 360us/step - loss: 238098.6174 - val_loss: 208906.5070\n",
      "Epoch 3807/5000\n",
      "134/134 [==============================] - 0s 352us/step - loss: 152635.4549 - val_loss: 133165.5450\n",
      "Epoch 3808/5000\n",
      "134/134 [==============================] - 0s 408us/step - loss: 135057.3302 - val_loss: 127632.9394\n",
      "Epoch 3809/5000\n",
      "134/134 [==============================] - 0s 389us/step - loss: 139069.2967 - val_loss: 127714.1462\n",
      "Epoch 3810/5000\n",
      "134/134 [==============================] - 0s 420us/step - loss: 134674.9144 - val_loss: 128273.0730\n",
      "Epoch 3811/5000\n",
      "134/134 [==============================] - 0s 361us/step - loss: 134417.4734 - val_loss: 127957.7955\n",
      "Epoch 3812/5000\n",
      "134/134 [==============================] - 0s 393us/step - loss: 130229.0452 - val_loss: 127044.5427\n",
      "Epoch 3813/5000\n",
      "134/134 [==============================] - 0s 342us/step - loss: 129924.2327 - val_loss: 145883.5788\n",
      "Epoch 3814/5000\n",
      "134/134 [==============================] - 0s 359us/step - loss: 144459.9527 - val_loss: 361971.6259\n",
      "Epoch 3815/5000\n",
      "134/134 [==============================] - 0s 359us/step - loss: 211815.6696 - val_loss: 146558.3594\n",
      "Epoch 3816/5000\n",
      "134/134 [==============================] - 0s 437us/step - loss: 208735.0227 - val_loss: 352116.3545\n",
      "Epoch 3817/5000\n",
      "134/134 [==============================] - 0s 474us/step - loss: 173480.0496 - val_loss: 178404.7337\n",
      "Epoch 3818/5000\n",
      "134/134 [==============================] - 0s 405us/step - loss: 214229.6806 - val_loss: 156178.3396\n",
      "Epoch 3819/5000\n",
      "134/134 [==============================] - 0s 370us/step - loss: 173719.8411 - val_loss: 144893.4888\n",
      "Epoch 3820/5000\n",
      "134/134 [==============================] - 0s 367us/step - loss: 146359.2412 - val_loss: 394760.8939\n",
      "Epoch 3821/5000\n",
      "134/134 [==============================] - 0s 365us/step - loss: 224780.9578 - val_loss: 282933.7764\n",
      "Epoch 3822/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 351us/step - loss: 198732.7132 - val_loss: 178805.9855\n",
      "Epoch 3823/5000\n",
      "134/134 [==============================] - 0s 347us/step - loss: 151684.7523 - val_loss: 150277.8440\n",
      "Epoch 3824/5000\n",
      "134/134 [==============================] - 0s 364us/step - loss: 158034.7694 - val_loss: 132212.1042\n",
      "Epoch 3825/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 133736.1444 - val_loss: 134462.5336\n",
      "Epoch 3826/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 135648.0032 - val_loss: 127153.1751\n",
      "Epoch 3827/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 187899.7831 - val_loss: 152227.7444\n",
      "Epoch 3828/5000\n",
      "134/134 [==============================] - 0s 329us/step - loss: 152497.3823 - val_loss: 153417.6856\n",
      "Epoch 3829/5000\n",
      "134/134 [==============================] - 0s 297us/step - loss: 185628.4412 - val_loss: 168879.1434\n",
      "Epoch 3830/5000\n",
      "134/134 [==============================] - 0s 343us/step - loss: 177304.6126 - val_loss: 147923.2585\n",
      "Epoch 3831/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 156606.3938 - val_loss: 143481.9923\n",
      "Epoch 3832/5000\n",
      "134/134 [==============================] - 0s 342us/step - loss: 141290.0278 - val_loss: 342316.3993\n",
      "Epoch 3833/5000\n",
      "134/134 [==============================] - 0s 374us/step - loss: 170619.4498 - val_loss: 140546.0807\n",
      "Epoch 3834/5000\n",
      "134/134 [==============================] - 0s 465us/step - loss: 192388.3841 - val_loss: 298168.2076\n",
      "Epoch 3835/5000\n",
      "134/134 [==============================] - 0s 422us/step - loss: 179491.6200 - val_loss: 214183.6145\n",
      "Epoch 3836/5000\n",
      "134/134 [==============================] - 0s 444us/step - loss: 190918.4196 - val_loss: 443082.7076\n",
      "Epoch 3837/5000\n",
      "134/134 [==============================] - 0s 396us/step - loss: 355293.5068 - val_loss: 153071.8790\n",
      "Epoch 3838/5000\n",
      "134/134 [==============================] - 0s 385us/step - loss: 156371.3906 - val_loss: 453340.5177\n",
      "Epoch 3839/5000\n",
      "134/134 [==============================] - 0s 373us/step - loss: 181095.7719 - val_loss: 128339.0140\n",
      "Epoch 3840/5000\n",
      "134/134 [==============================] - 0s 373us/step - loss: 138636.8535 - val_loss: 126551.2507\n",
      "Epoch 3841/5000\n",
      "134/134 [==============================] - 0s 386us/step - loss: 133175.8121 - val_loss: 134555.7773\n",
      "Epoch 3842/5000\n",
      "134/134 [==============================] - 0s 335us/step - loss: 130635.3438 - val_loss: 125154.8134\n",
      "Epoch 3843/5000\n",
      "134/134 [==============================] - 0s 357us/step - loss: 132692.8057 - val_loss: 125974.9559\n",
      "Epoch 3844/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 130378.0819 - val_loss: 193975.5924\n",
      "Epoch 3845/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 143895.0529 - val_loss: 161118.6040\n",
      "Epoch 3846/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 134696.9818 - val_loss: 135968.1110\n",
      "Epoch 3847/5000\n",
      "134/134 [==============================] - 0s 435us/step - loss: 178587.0641 - val_loss: 226571.0746\n",
      "Epoch 3848/5000\n",
      "134/134 [==============================] - 0s 361us/step - loss: 311437.1498 - val_loss: 667373.8102\n",
      "Epoch 3849/5000\n",
      "134/134 [==============================] - 0s 342us/step - loss: 257142.4924 - val_loss: 141030.5471\n",
      "Epoch 3850/5000\n",
      "134/134 [==============================] - 0s 359us/step - loss: 145790.1623 - val_loss: 150899.4123\n",
      "Epoch 3851/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 175353.1632 - val_loss: 133630.2908\n",
      "Epoch 3852/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 141140.3795 - val_loss: 307166.8955\n",
      "Epoch 3853/5000\n",
      "134/134 [==============================] - 0s 334us/step - loss: 259992.9607 - val_loss: 159373.7323\n",
      "Epoch 3854/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 225662.6794 - val_loss: 184925.7442\n",
      "Epoch 3855/5000\n",
      "134/134 [==============================] - 0s 427us/step - loss: 149526.3903 - val_loss: 131063.8958\n",
      "Epoch 3856/5000\n",
      "134/134 [==============================] - 0s 498us/step - loss: 133473.5086 - val_loss: 159169.4986\n",
      "Epoch 3857/5000\n",
      "134/134 [==============================] - 0s 370us/step - loss: 134213.2674 - val_loss: 124695.5479\n",
      "Epoch 3858/5000\n",
      "134/134 [==============================] - 0s 397us/step - loss: 130559.8511 - val_loss: 131553.2230\n",
      "Epoch 3859/5000\n",
      "134/134 [==============================] - 0s 396us/step - loss: 134990.5580 - val_loss: 126843.2073\n",
      "Epoch 3860/5000\n",
      "134/134 [==============================] - 0s 329us/step - loss: 133813.7381 - val_loss: 133730.3923\n",
      "Epoch 3861/5000\n",
      "134/134 [==============================] - 0s 321us/step - loss: 151538.8082 - val_loss: 132329.2290\n",
      "Epoch 3862/5000\n",
      "134/134 [==============================] - 0s 338us/step - loss: 254641.6684 - val_loss: 256245.7115\n",
      "Epoch 3863/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 186858.3554 - val_loss: 265437.4557\n",
      "Epoch 3864/5000\n",
      "134/134 [==============================] - 0s 348us/step - loss: 189670.1637 - val_loss: 274136.8167\n",
      "Epoch 3865/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 192436.2044 - val_loss: 147362.3904\n",
      "Epoch 3866/5000\n",
      "134/134 [==============================] - 0s 352us/step - loss: 142125.2981 - val_loss: 131912.1909\n",
      "Epoch 3867/5000\n",
      "134/134 [==============================] - 0s 338us/step - loss: 151776.5554 - val_loss: 301134.9923\n",
      "Epoch 3868/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 233449.1255 - val_loss: 297393.8589\n",
      "Epoch 3869/5000\n",
      "134/134 [==============================] - 0s 397us/step - loss: 259533.1262 - val_loss: 134650.5483\n",
      "Epoch 3870/5000\n",
      "134/134 [==============================] - 0s 432us/step - loss: 140829.3282 - val_loss: 137706.9523\n",
      "Epoch 3871/5000\n",
      "134/134 [==============================] - 0s 376us/step - loss: 150799.3813 - val_loss: 200337.5462\n",
      "Epoch 3872/5000\n",
      "134/134 [==============================] - 0s 402us/step - loss: 236599.2744 - val_loss: 450746.6838\n",
      "Epoch 3873/5000\n",
      "134/134 [==============================] - 0s 372us/step - loss: 191658.7821 - val_loss: 123514.5966\n",
      "Epoch 3874/5000\n",
      "134/134 [==============================] - 0s 323us/step - loss: 127246.1336 - val_loss: 196272.4310\n",
      "Epoch 3875/5000\n",
      "134/134 [==============================] - 0s 330us/step - loss: 142577.0563 - val_loss: 135461.2269\n",
      "Epoch 3876/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 136057.1095 - val_loss: 130955.3615\n",
      "Epoch 3877/5000\n",
      "134/134 [==============================] - 0s 344us/step - loss: 149998.6646 - val_loss: 153854.0322\n",
      "Epoch 3878/5000\n",
      "134/134 [==============================] - 0s 336us/step - loss: 132932.2116 - val_loss: 126836.7710\n",
      "Epoch 3879/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 151291.8064 - val_loss: 150054.4604\n",
      "Epoch 3880/5000\n",
      "134/134 [==============================] - 0s 268us/step - loss: 183008.5236 - val_loss: 129295.2324\n",
      "Epoch 3881/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 149761.3983 - val_loss: 159624.6870\n",
      "Epoch 3882/5000\n",
      "134/134 [==============================] - 0s 264us/step - loss: 176790.4031 - val_loss: 159515.1504\n",
      "Epoch 3883/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 234188.8219 - val_loss: 617643.1493\n",
      "Epoch 3884/5000\n",
      "134/134 [==============================] - 0s 297us/step - loss: 330107.9428 - val_loss: 231983.8533\n",
      "Epoch 3885/5000\n",
      "134/134 [==============================] - 0s 357us/step - loss: 166411.9319 - val_loss: 143780.4825\n",
      "Epoch 3886/5000\n",
      "134/134 [==============================] - 0s 336us/step - loss: 138215.2271 - val_loss: 125419.6563\n",
      "Epoch 3887/5000\n",
      "134/134 [==============================] - 0s 412us/step - loss: 143837.1416 - val_loss: 134677.8242\n",
      "Epoch 3888/5000\n",
      "134/134 [==============================] - 0s 402us/step - loss: 138736.3899 - val_loss: 131698.8154\n",
      "Epoch 3889/5000\n",
      "134/134 [==============================] - 0s 406us/step - loss: 133232.5884 - val_loss: 258378.2421\n",
      "Epoch 3890/5000\n",
      "134/134 [==============================] - 0s 387us/step - loss: 179317.0841 - val_loss: 420742.0168\n",
      "Epoch 3891/5000\n",
      "134/134 [==============================] - 0s 381us/step - loss: 237696.0847 - val_loss: 135497.5278\n",
      "Epoch 3892/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 367us/step - loss: 147287.6131 - val_loss: 130874.5625\n",
      "Epoch 3893/5000\n",
      "134/134 [==============================] - 0s 347us/step - loss: 135472.6844 - val_loss: 124072.0555\n",
      "Epoch 3894/5000\n",
      "134/134 [==============================] - 0s 350us/step - loss: 138979.9305 - val_loss: 175725.8573\n",
      "Epoch 3895/5000\n",
      "134/134 [==============================] - 0s 318us/step - loss: 159112.7516 - val_loss: 141231.6187\n",
      "Epoch 3896/5000\n",
      "134/134 [==============================] - 0s 376us/step - loss: 157493.1073 - val_loss: 136611.8055\n",
      "Epoch 3897/5000\n",
      "134/134 [==============================] - 0s 351us/step - loss: 147239.1660 - val_loss: 144834.3190\n",
      "Epoch 3898/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 142128.0849 - val_loss: 316541.9925\n",
      "Epoch 3899/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 212313.5141 - val_loss: 220496.9981\n",
      "Epoch 3900/5000\n",
      "134/134 [==============================] - 0s 320us/step - loss: 221652.8141 - val_loss: 358586.0317\n",
      "Epoch 3901/5000\n",
      "134/134 [==============================] - 0s 325us/step - loss: 193093.7222 - val_loss: 393643.9809\n",
      "Epoch 3902/5000\n",
      "134/134 [==============================] - 0s 373us/step - loss: 271158.9501 - val_loss: 181827.8689\n",
      "Epoch 3903/5000\n",
      "134/134 [==============================] - 0s 402us/step - loss: 224065.3296 - val_loss: 158233.9569\n",
      "Epoch 3904/5000\n",
      "134/134 [==============================] - 0s 538us/step - loss: 276210.8097 - val_loss: 189989.1919\n",
      "Epoch 3905/5000\n",
      "134/134 [==============================] - 0s 464us/step - loss: 183715.8404 - val_loss: 200050.9408\n",
      "Epoch 3906/5000\n",
      "134/134 [==============================] - 0s 339us/step - loss: 147936.8543 - val_loss: 131698.4361\n",
      "Epoch 3907/5000\n",
      "134/134 [==============================] - 0s 333us/step - loss: 146511.5222 - val_loss: 166225.8470\n",
      "Epoch 3908/5000\n",
      "134/134 [==============================] - 0s 287us/step - loss: 130833.8316 - val_loss: 154312.7778\n",
      "Epoch 3909/5000\n",
      "134/134 [==============================] - 0s 336us/step - loss: 127477.3478 - val_loss: 128177.7076\n",
      "Epoch 3910/5000\n",
      "134/134 [==============================] - 0s 334us/step - loss: 175386.4829 - val_loss: 297587.8200\n",
      "Epoch 3911/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 228953.2250 - val_loss: 158283.8237\n",
      "Epoch 3912/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 345529.1684 - val_loss: 308741.1497\n",
      "Epoch 3913/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 181152.8602 - val_loss: 204489.7871\n",
      "Epoch 3914/5000\n",
      "134/134 [==============================] - 0s 367us/step - loss: 178746.0305 - val_loss: 194759.9636\n",
      "Epoch 3915/5000\n",
      "134/134 [==============================] - 0s 344us/step - loss: 170147.6961 - val_loss: 130159.6567\n",
      "Epoch 3916/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 131938.7674 - val_loss: 152605.4282\n",
      "Epoch 3917/5000\n",
      "134/134 [==============================] - 0s 372us/step - loss: 132783.1234 - val_loss: 125336.4778\n",
      "Epoch 3918/5000\n",
      "134/134 [==============================] - 0s 262us/step - loss: 127702.0051 - val_loss: 141086.1570\n",
      "Epoch 3919/5000\n",
      "134/134 [==============================] - 0s 345us/step - loss: 146323.4951 - val_loss: 154838.4394\n",
      "Epoch 3920/5000\n",
      "134/134 [==============================] - 0s 380us/step - loss: 154756.2396 - val_loss: 142053.4846\n",
      "Epoch 3921/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 147605.5532 - val_loss: 433606.9394\n",
      "Epoch 3922/5000\n",
      "134/134 [==============================] - 0s 324us/step - loss: 256554.7320 - val_loss: 173098.0359\n",
      "Epoch 3923/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 304148.5976 - val_loss: 285031.8027\n",
      "Epoch 3924/5000\n",
      "134/134 [==============================] - 0s 370us/step - loss: 185164.1920 - val_loss: 142983.9850\n",
      "Epoch 3925/5000\n",
      "134/134 [==============================] - 0s 333us/step - loss: 165578.6035 - val_loss: 637365.1660\n",
      "Epoch 3926/5000\n",
      "134/134 [==============================] - 0s 338us/step - loss: 206671.5122 - val_loss: 341303.0588\n",
      "Epoch 3927/5000\n",
      "134/134 [==============================] - 0s 287us/step - loss: 201906.1157 - val_loss: 658760.6325\n",
      "Epoch 3928/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 235395.3246 - val_loss: 372592.7351\n",
      "Epoch 3929/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 431660.9655 - val_loss: 133184.2076\n",
      "Epoch 3930/5000\n",
      "134/134 [==============================] - 0s 353us/step - loss: 137951.7751 - val_loss: 153295.7796\n",
      "Epoch 3931/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 147410.5142 - val_loss: 128535.3001\n",
      "Epoch 3932/5000\n",
      "134/134 [==============================] - 0s 330us/step - loss: 151567.6759 - val_loss: 133933.1369\n",
      "Epoch 3933/5000\n",
      "134/134 [==============================] - 0s 353us/step - loss: 145222.3724 - val_loss: 126214.2789\n",
      "Epoch 3934/5000\n",
      "134/134 [==============================] - 0s 330us/step - loss: 139421.4224 - val_loss: 130885.2699\n",
      "Epoch 3935/5000\n",
      "134/134 [==============================] - 0s 339us/step - loss: 129759.4158 - val_loss: 182866.4445\n",
      "Epoch 3936/5000\n",
      "134/134 [==============================] - 0s 351us/step - loss: 134067.8914 - val_loss: 185664.1446\n",
      "Epoch 3937/5000\n",
      "134/134 [==============================] - 0s 352us/step - loss: 164840.1678 - val_loss: 152341.7415\n",
      "Epoch 3938/5000\n",
      "134/134 [==============================] - 0s 381us/step - loss: 193571.7785 - val_loss: 149222.4025\n",
      "Epoch 3939/5000\n",
      "134/134 [==============================] - 0s 337us/step - loss: 169507.1758 - val_loss: 158685.9683\n",
      "Epoch 3940/5000\n",
      "134/134 [==============================] - 0s 405us/step - loss: 145494.5985 - val_loss: 162112.4035\n",
      "Epoch 3941/5000\n",
      "134/134 [==============================] - 0s 402us/step - loss: 137721.7129 - val_loss: 352591.0583\n",
      "Epoch 3942/5000\n",
      "134/134 [==============================] - 0s 320us/step - loss: 220060.5786 - val_loss: 164509.6968\n",
      "Epoch 3943/5000\n",
      "134/134 [==============================] - 0s 331us/step - loss: 251365.8300 - val_loss: 170906.3736\n",
      "Epoch 3944/5000\n",
      "134/134 [==============================] - 0s 336us/step - loss: 215960.8429 - val_loss: 408262.7514\n",
      "Epoch 3945/5000\n",
      "134/134 [==============================] - 0s 347us/step - loss: 327043.0272 - val_loss: 263623.8452\n",
      "Epoch 3946/5000\n",
      "134/134 [==============================] - 0s 318us/step - loss: 173281.3441 - val_loss: 162286.4662\n",
      "Epoch 3947/5000\n",
      "134/134 [==============================] - 0s 281us/step - loss: 174352.5564 - val_loss: 174800.2188\n",
      "Epoch 3948/5000\n",
      "134/134 [==============================] - 0s 274us/step - loss: 190661.4609 - val_loss: 142734.2397\n",
      "Epoch 3949/5000\n",
      "134/134 [==============================] - 0s 332us/step - loss: 134520.1190 - val_loss: 123638.6744\n",
      "Epoch 3950/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 131940.5791 - val_loss: 231055.1747\n",
      "Epoch 3951/5000\n",
      "134/134 [==============================] - 0s 394us/step - loss: 171313.4359 - val_loss: 132619.5767\n",
      "Epoch 3952/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 138827.1304 - val_loss: 133700.2584\n",
      "Epoch 3953/5000\n",
      "134/134 [==============================] - 0s 358us/step - loss: 126525.5395 - val_loss: 139870.3778\n",
      "Epoch 3954/5000\n",
      "134/134 [==============================] - 0s 390us/step - loss: 148349.3254 - val_loss: 152208.0723\n",
      "Epoch 3955/5000\n",
      "134/134 [==============================] - 0s 337us/step - loss: 155817.8808 - val_loss: 129402.8071\n",
      "Epoch 3956/5000\n",
      "134/134 [==============================] - 0s 344us/step - loss: 165368.9795 - val_loss: 183056.6339\n",
      "Epoch 3957/5000\n",
      "134/134 [==============================] - ETA: 0s - loss: 10562.631 - 0s 323us/step - loss: 179679.8836 - val_loss: 813743.8069\n",
      "Epoch 3958/5000\n",
      "134/134 [==============================] - 0s 349us/step - loss: 476691.5560 - val_loss: 153524.4384\n",
      "Epoch 3959/5000\n",
      "134/134 [==============================] - 0s 360us/step - loss: 148659.6926 - val_loss: 138583.3155\n",
      "Epoch 3960/5000\n",
      "134/134 [==============================] - 0s 346us/step - loss: 150492.5286 - val_loss: 142050.0359\n",
      "Epoch 3961/5000\n",
      "134/134 [==============================] - 0s 332us/step - loss: 130293.1202 - val_loss: 262649.3815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3962/5000\n",
      "134/134 [==============================] - 0s 402us/step - loss: 159783.4327 - val_loss: 137220.8440\n",
      "Epoch 3963/5000\n",
      "134/134 [==============================] - 0s 299us/step - loss: 147734.9569 - val_loss: 154689.3302\n",
      "Epoch 3964/5000\n",
      "134/134 [==============================] - 0s 287us/step - loss: 174910.8463 - val_loss: 165232.5896\n",
      "Epoch 3965/5000\n",
      "134/134 [==============================] - 0s 325us/step - loss: 146995.5169 - val_loss: 131598.3862\n",
      "Epoch 3966/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 141533.5278 - val_loss: 174310.5854\n",
      "Epoch 3967/5000\n",
      "134/134 [==============================] - 0s 338us/step - loss: 166896.9141 - val_loss: 133379.7638\n",
      "Epoch 3968/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 135715.7288 - val_loss: 155947.5826\n",
      "Epoch 3969/5000\n",
      "134/134 [==============================] - 0s 318us/step - loss: 161231.4387 - val_loss: 131259.2787\n",
      "Epoch 3970/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 155866.5969 - val_loss: 133578.5520\n",
      "Epoch 3971/5000\n",
      "134/134 [==============================] - 0s 349us/step - loss: 155378.9282 - val_loss: 153263.2337\n",
      "Epoch 3972/5000\n",
      "134/134 [==============================] - 0s 315us/step - loss: 161908.1394 - val_loss: 178906.4503\n",
      "Epoch 3973/5000\n",
      "134/134 [==============================] - 0s 349us/step - loss: 168037.3162 - val_loss: 265120.6409\n",
      "Epoch 3974/5000\n",
      "134/134 [==============================] - 0s 294us/step - loss: 242559.1945 - val_loss: 166210.9515\n",
      "Epoch 3975/5000\n",
      "134/134 [==============================] - 0s 321us/step - loss: 169731.1446 - val_loss: 588970.1922\n",
      "Epoch 3976/5000\n",
      "134/134 [==============================] - 0s 300us/step - loss: 211729.2018 - val_loss: 236210.5725\n",
      "Epoch 3977/5000\n",
      "134/134 [==============================] - 0s 333us/step - loss: 240382.7734 - val_loss: 166962.1381\n",
      "Epoch 3978/5000\n",
      "134/134 [==============================] - 0s 321us/step - loss: 235142.4458 - val_loss: 212769.1716\n",
      "Epoch 3979/5000\n",
      "134/134 [==============================] - 0s 348us/step - loss: 158481.0360 - val_loss: 141511.9706\n",
      "Epoch 3980/5000\n",
      "134/134 [==============================] - 0s 343us/step - loss: 165934.8700 - val_loss: 212058.8130\n",
      "Epoch 3981/5000\n",
      "134/134 [==============================] - 0s 339us/step - loss: 172679.6796 - val_loss: 161900.1968\n",
      "Epoch 3982/5000\n",
      "134/134 [==============================] - 0s 348us/step - loss: 170455.6202 - val_loss: 190803.9730\n",
      "Epoch 3983/5000\n",
      "134/134 [==============================] - 0s 353us/step - loss: 230584.6551 - val_loss: 159099.7845\n",
      "Epoch 3984/5000\n",
      "134/134 [==============================] - 0s 380us/step - loss: 138655.9835 - val_loss: 145932.6262\n",
      "Epoch 3985/5000\n",
      "134/134 [==============================] - 0s 401us/step - loss: 147370.5093 - val_loss: 209064.4590\n",
      "Epoch 3986/5000\n",
      "134/134 [==============================] - 0s 413us/step - loss: 149982.7403 - val_loss: 154556.5585\n",
      "Epoch 3987/5000\n",
      "134/134 [==============================] - 0s 507us/step - loss: 135461.3937 - val_loss: 207658.6521\n",
      "Epoch 3988/5000\n",
      "134/134 [==============================] - 0s 384us/step - loss: 237234.8862 - val_loss: 154187.8137\n",
      "Epoch 3989/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 188184.9789 - val_loss: 129645.5222\n",
      "Epoch 3990/5000\n",
      "134/134 [==============================] - 0s 317us/step - loss: 134500.4701 - val_loss: 138666.2558\n",
      "Epoch 3991/5000\n",
      "134/134 [==============================] - 0s 323us/step - loss: 127473.6470 - val_loss: 121623.2660\n",
      "Epoch 3992/5000\n",
      "134/134 [==============================] - 0s 323us/step - loss: 128394.7594 - val_loss: 174501.3396\n",
      "Epoch 3993/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 149595.5435 - val_loss: 216070.0373\n",
      "Epoch 3994/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 215472.3865 - val_loss: 271318.7670\n",
      "Epoch 3995/5000\n",
      "134/134 [==============================] - 0s 317us/step - loss: 178791.8434 - val_loss: 278199.8568\n",
      "Epoch 3996/5000\n",
      "134/134 [==============================] - 0s 325us/step - loss: 230405.5602 - val_loss: 202718.0746\n",
      "Epoch 3997/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 272135.2466 - val_loss: 338150.1119\n",
      "Epoch 3998/5000\n",
      "134/134 [==============================] - 0s 359us/step - loss: 185721.0396 - val_loss: 157340.6397\n",
      "Epoch 3999/5000\n",
      "134/134 [==============================] - 0s 360us/step - loss: 131537.8015 - val_loss: 139297.2111\n",
      "Epoch 4000/5000\n",
      "134/134 [==============================] - 0s 420us/step - loss: 128882.4118 - val_loss: 119477.3913\n",
      "Epoch 4001/5000\n",
      "134/134 [==============================] - 0s 387us/step - loss: 132573.5590 - val_loss: 132812.2880\n",
      "Epoch 4002/5000\n",
      "134/134 [==============================] - 0s 384us/step - loss: 124009.3705 - val_loss: 128845.4489\n",
      "Epoch 4003/5000\n",
      "134/134 [==============================] - 0s 437us/step - loss: 148100.4015 - val_loss: 121761.4412\n",
      "Epoch 4004/5000\n",
      "134/134 [==============================] - 0s 363us/step - loss: 131618.4268 - val_loss: 157380.3351\n",
      "Epoch 4005/5000\n",
      "134/134 [==============================] - 0s 384us/step - loss: 145557.3651 - val_loss: 167641.3575\n",
      "Epoch 4006/5000\n",
      "134/134 [==============================] - 0s 339us/step - loss: 145040.6522 - val_loss: 223779.8617\n",
      "Epoch 4007/5000\n",
      "134/134 [==============================] - 0s 343us/step - loss: 151544.1263 - val_loss: 253853.7178\n",
      "Epoch 4008/5000\n",
      "134/134 [==============================] - 0s 355us/step - loss: 234925.3538 - val_loss: 142481.0660\n",
      "Epoch 4009/5000\n",
      "134/134 [==============================] - 0s 405us/step - loss: 195771.1159 - val_loss: 595100.9963\n",
      "Epoch 4010/5000\n",
      "134/134 [==============================] - 0s 389us/step - loss: 284296.3514 - val_loss: 220900.9981\n",
      "Epoch 4011/5000\n",
      "134/134 [==============================] - 0s 408us/step - loss: 159273.9855 - val_loss: 130445.6523\n",
      "Epoch 4012/5000\n",
      "134/134 [==============================] - 0s 346us/step - loss: 137283.3692 - val_loss: 151527.6299\n",
      "Epoch 4013/5000\n",
      "134/134 [==============================] - ETA: 0s - loss: 197326.75 - 0s 303us/step - loss: 130233.9659 - val_loss: 119504.7059\n",
      "Epoch 4014/5000\n",
      "134/134 [==============================] - 0s 353us/step - loss: 123166.5026 - val_loss: 130576.9734\n",
      "Epoch 4015/5000\n",
      "134/134 [==============================] - 0s 363us/step - loss: 123862.7943 - val_loss: 245623.6586\n",
      "Epoch 4016/5000\n",
      "134/134 [==============================] - 0s 377us/step - loss: 182671.2771 - val_loss: 145128.7992\n",
      "Epoch 4017/5000\n",
      "134/134 [==============================] - 0s 418us/step - loss: 173741.0675 - val_loss: 250102.9445\n",
      "Epoch 4018/5000\n",
      "134/134 [==============================] - 0s 418us/step - loss: 175724.4024 - val_loss: 186556.0765\n",
      "Epoch 4019/5000\n",
      "134/134 [==============================] - 0s 450us/step - loss: 149856.3263 - val_loss: 257605.5672\n",
      "Epoch 4020/5000\n",
      "134/134 [==============================] - 0s 399us/step - loss: 156001.0922 - val_loss: 281622.7043\n",
      "Epoch 4021/5000\n",
      "134/134 [==============================] - 0s 345us/step - loss: 238337.7561 - val_loss: 155922.5382\n",
      "Epoch 4022/5000\n",
      "134/134 [==============================] - 0s 297us/step - loss: 167246.4028 - val_loss: 148831.9198\n",
      "Epoch 4023/5000\n",
      "134/134 [==============================] - ETA: 0s - loss: 446373.90 - 0s 366us/step - loss: 224766.7003 - val_loss: 168008.4543\n",
      "Epoch 4024/5000\n",
      "134/134 [==============================] - 0s 358us/step - loss: 163099.0583 - val_loss: 137071.1434\n",
      "Epoch 4025/5000\n",
      "134/134 [==============================] - 0s 362us/step - loss: 137223.8707 - val_loss: 123680.4200\n",
      "Epoch 4026/5000\n",
      "134/134 [==============================] - 0s 374us/step - loss: 131840.4875 - val_loss: 144773.2108\n",
      "Epoch 4027/5000\n",
      "134/134 [==============================] - 0s 338us/step - loss: 129747.5244 - val_loss: 127714.2225\n",
      "Epoch 4028/5000\n",
      "134/134 [==============================] - 0s 349us/step - loss: 139682.0659 - val_loss: 128008.5441\n",
      "Epoch 4029/5000\n",
      "134/134 [==============================] - 0s 344us/step - loss: 142588.8155 - val_loss: 248593.7463\n",
      "Epoch 4030/5000\n",
      "134/134 [==============================] - 0s 348us/step - loss: 322139.3267 - val_loss: 140153.8251\n",
      "Epoch 4031/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 342us/step - loss: 143962.6769 - val_loss: 373868.8312\n",
      "Epoch 4032/5000\n",
      "134/134 [==============================] - 0s 429us/step - loss: 263594.0905 - val_loss: 243632.6252\n",
      "Epoch 4033/5000\n",
      "134/134 [==============================] - 0s 451us/step - loss: 161180.4638 - val_loss: 125904.6434\n",
      "Epoch 4034/5000\n",
      "134/134 [==============================] - 0s 406us/step - loss: 132411.9170 - val_loss: 234189.9450\n",
      "Epoch 4035/5000\n",
      "134/134 [==============================] - 0s 402us/step - loss: 185301.7554 - val_loss: 136031.1891\n",
      "Epoch 4036/5000\n",
      "134/134 [==============================] - 0s 450us/step - loss: 227496.7584 - val_loss: 367440.2780\n",
      "Epoch 4037/5000\n",
      "134/134 [==============================] - 0s 453us/step - loss: 200081.8316 - val_loss: 155609.3605\n",
      "Epoch 4038/5000\n",
      "134/134 [==============================] - 0s 438us/step - loss: 140082.7808 - val_loss: 180535.4028\n",
      "Epoch 4039/5000\n",
      "134/134 [==============================] - 0s 457us/step - loss: 143339.4161 - val_loss: 151877.1210\n",
      "Epoch 4040/5000\n",
      "134/134 [==============================] - 0s 412us/step - loss: 146038.5532 - val_loss: 170686.9489\n",
      "Epoch 4041/5000\n",
      "134/134 [==============================] - 0s 296us/step - loss: 151015.4389 - val_loss: 260934.6632\n",
      "Epoch 4042/5000\n",
      "134/134 [==============================] - 0s 329us/step - loss: 216219.9570 - val_loss: 134113.4600\n",
      "Epoch 4043/5000\n",
      "134/134 [==============================] - 0s 420us/step - loss: 152227.3591 - val_loss: 134199.5949\n",
      "Epoch 4044/5000\n",
      "134/134 [==============================] - 0s 502us/step - loss: 152343.2938 - val_loss: 127913.7381\n",
      "Epoch 4045/5000\n",
      "134/134 [==============================] - 0s 531us/step - loss: 164495.2126 - val_loss: 332073.7864\n",
      "Epoch 4046/5000\n",
      "134/134 [==============================] - 0s 467us/step - loss: 219377.0661 - val_loss: 381343.7136\n",
      "Epoch 4047/5000\n",
      "134/134 [==============================] - 0s 361us/step - loss: 208301.4979 - val_loss: 246358.4571\n",
      "Epoch 4048/5000\n",
      "134/134 [==============================] - 0s 379us/step - loss: 167076.8471 - val_loss: 132992.6523\n",
      "Epoch 4049/5000\n",
      "134/134 [==============================] - 0s 339us/step - loss: 164342.2516 - val_loss: 694862.2985\n",
      "Epoch 4050/5000\n",
      "134/134 [==============================] - 0s 344us/step - loss: 355316.2733 - val_loss: 153685.3689\n",
      "Epoch 4051/5000\n",
      "134/134 [==============================] - 0s 363us/step - loss: 149412.8977 - val_loss: 140549.5466\n",
      "Epoch 4052/5000\n",
      "134/134 [==============================] - 0s 344us/step - loss: 140966.0131 - val_loss: 118848.0198\n",
      "Epoch 4053/5000\n",
      "134/134 [==============================] - 0s 360us/step - loss: 123108.0760 - val_loss: 116451.3591\n",
      "Epoch 4054/5000\n",
      "134/134 [==============================] - 0s 384us/step - loss: 120399.8590 - val_loss: 119235.7882\n",
      "Epoch 4055/5000\n",
      "134/134 [==============================] - 0s 388us/step - loss: 126207.5500 - val_loss: 126470.7864\n",
      "Epoch 4056/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 124280.8629 - val_loss: 118319.6213\n",
      "Epoch 4057/5000\n",
      "134/134 [==============================] - 0s 452us/step - loss: 119760.5198 - val_loss: 128145.3860\n",
      "Epoch 4058/5000\n",
      "134/134 [==============================] - 0s 427us/step - loss: 135884.1047 - val_loss: 143803.4016\n",
      "Epoch 4059/5000\n",
      "134/134 [==============================] - 0s 386us/step - loss: 205866.8815 - val_loss: 147902.1663\n",
      "Epoch 4060/5000\n",
      "134/134 [==============================] - 0s 370us/step - loss: 210054.5800 - val_loss: 283723.0942\n",
      "Epoch 4061/5000\n",
      "134/134 [==============================] - 0s 385us/step - loss: 159129.9951 - val_loss: 142331.4333\n",
      "Epoch 4062/5000\n",
      "134/134 [==============================] - 0s 342us/step - loss: 161395.1811 - val_loss: 384640.5576\n",
      "Epoch 4063/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 177822.2367 - val_loss: 234480.3102\n",
      "Epoch 4064/5000\n",
      "134/134 [==============================] - 0s 330us/step - loss: 166861.1773 - val_loss: 144156.3846\n",
      "Epoch 4065/5000\n",
      "134/134 [==============================] - 0s 299us/step - loss: 174994.2806 - val_loss: 218244.0280\n",
      "Epoch 4066/5000\n",
      "134/134 [==============================] - 0s 315us/step - loss: 158665.3302 - val_loss: 454388.8778\n",
      "Epoch 4067/5000\n",
      "134/134 [==============================] - 0s 304us/step - loss: 244406.9188 - val_loss: 191275.0616\n",
      "Epoch 4068/5000\n",
      "134/134 [==============================] - 0s 323us/step - loss: 147024.2460 - val_loss: 159467.9023\n",
      "Epoch 4069/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 129108.2998 - val_loss: 120195.3174\n",
      "Epoch 4070/5000\n",
      "134/134 [==============================] - 0s 333us/step - loss: 123914.2687 - val_loss: 128604.2035\n",
      "Epoch 4071/5000\n",
      "134/134 [==============================] - 0s 361us/step - loss: 137352.3005 - val_loss: 123688.1028\n",
      "Epoch 4072/5000\n",
      "134/134 [==============================] - 0s 339us/step - loss: 129008.9616 - val_loss: 146221.4501\n",
      "Epoch 4073/5000\n",
      "134/134 [==============================] - 0s 346us/step - loss: 157580.5533 - val_loss: 486405.7873\n",
      "Epoch 4074/5000\n",
      "134/134 [==============================] - 0s 377us/step - loss: 279395.1653 - val_loss: 137016.0082\n",
      "Epoch 4075/5000\n",
      "134/134 [==============================] - 0s 526us/step - loss: 170701.2372 - val_loss: 187960.7687\n",
      "Epoch 4076/5000\n",
      "134/134 [==============================] - 0s 536us/step - loss: 164907.4797 - val_loss: 197883.6017\n",
      "Epoch 4077/5000\n",
      "134/134 [==============================] - 0s 474us/step - loss: 161468.2224 - val_loss: 130009.8897\n",
      "Epoch 4078/5000\n",
      "134/134 [==============================] - 0s 422us/step - loss: 151492.3312 - val_loss: 143980.9124\n",
      "Epoch 4079/5000\n",
      "134/134 [==============================] - 0s 413us/step - loss: 244699.9574 - val_loss: 137541.7341\n",
      "Epoch 4080/5000\n",
      "134/134 [==============================] - 0s 357us/step - loss: 142410.9604 - val_loss: 150725.4585\n",
      "Epoch 4081/5000\n",
      "134/134 [==============================] - 0s 291us/step - loss: 147226.5918 - val_loss: 141680.4228\n",
      "Epoch 4082/5000\n",
      "134/134 [==============================] - 0s 351us/step - loss: 146123.3068 - val_loss: 125621.5300\n",
      "Epoch 4083/5000\n",
      "134/134 [==============================] - 0s 337us/step - loss: 180542.7299 - val_loss: 147328.7896\n",
      "Epoch 4084/5000\n",
      "134/134 [==============================] - 0s 329us/step - loss: 166888.6926 - val_loss: 169213.5219\n",
      "Epoch 4085/5000\n",
      "134/134 [==============================] - 0s 410us/step - loss: 148223.7674 - val_loss: 259808.2178\n",
      "Epoch 4086/5000\n",
      "134/134 [==============================] - 0s 483us/step - loss: 157013.6341 - val_loss: 188428.5408\n",
      "Epoch 4087/5000\n",
      "134/134 [==============================] - 0s 422us/step - loss: 133700.7432 - val_loss: 133336.0487\n",
      "Epoch 4088/5000\n",
      "134/134 [==============================] - 0s 396us/step - loss: 132277.3429 - val_loss: 154511.7470\n",
      "Epoch 4089/5000\n",
      "134/134 [==============================] - 0s 415us/step - loss: 147173.7927 - val_loss: 169207.2513\n",
      "Epoch 4090/5000\n",
      "134/134 [==============================] - 0s 374us/step - loss: 250446.3857 - val_loss: 278616.3899\n",
      "Epoch 4091/5000\n",
      "134/134 [==============================] - 0s 410us/step - loss: 209510.5340 - val_loss: 186439.4639\n",
      "Epoch 4092/5000\n",
      "134/134 [==============================] - 0s 402us/step - loss: 232547.4305 - val_loss: 246547.6343\n",
      "Epoch 4093/5000\n",
      "134/134 [==============================] - 0s 447us/step - loss: 177297.5536 - val_loss: 170984.7043\n",
      "Epoch 4094/5000\n",
      "134/134 [==============================] - 0s 363us/step - loss: 158084.7799 - val_loss: 161826.0282\n",
      "Epoch 4095/5000\n",
      "134/134 [==============================] - 0s 357us/step - loss: 139983.8659 - val_loss: 149374.8827\n",
      "Epoch 4096/5000\n",
      "134/134 [==============================] - 0s 345us/step - loss: 133852.9899 - val_loss: 144297.3829\n",
      "Epoch 4097/5000\n",
      "134/134 [==============================] - 0s 370us/step - loss: 173959.5021 - val_loss: 272726.4275\n",
      "Epoch 4098/5000\n",
      "134/134 [==============================] - 0s 453us/step - loss: 197068.2136 - val_loss: 220225.3253\n",
      "Epoch 4099/5000\n",
      "134/134 [==============================] - 0s 420us/step - loss: 192034.1026 - val_loss: 319174.8501\n",
      "Epoch 4100/5000\n",
      "134/134 [==============================] - 0s 366us/step - loss: 185004.5522 - val_loss: 140244.2143\n",
      "Epoch 4101/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 318us/step - loss: 155254.3349 - val_loss: 196710.1525\n",
      "Epoch 4102/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 242050.1434 - val_loss: 138703.1234\n",
      "Epoch 4103/5000\n",
      "134/134 [==============================] - 0s 366us/step - loss: 139322.6512 - val_loss: 128958.5241\n",
      "Epoch 4104/5000\n",
      "134/134 [==============================] - 0s 346us/step - loss: 130711.4016 - val_loss: 116896.8556\n",
      "Epoch 4105/5000\n",
      "134/134 [==============================] - 0s 323us/step - loss: 125026.0283 - val_loss: 122033.6128\n",
      "Epoch 4106/5000\n",
      "134/134 [==============================] - 0s 320us/step - loss: 120649.6686 - val_loss: 146244.3570\n",
      "Epoch 4107/5000\n",
      "134/134 [==============================] - 0s 320us/step - loss: 140227.9359 - val_loss: 150080.6693\n",
      "Epoch 4108/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 176500.7600 - val_loss: 150961.8657\n",
      "Epoch 4109/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 140721.5977 - val_loss: 128537.3757\n",
      "Epoch 4110/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 162383.8806 - val_loss: 702701.7966\n",
      "Epoch 4111/5000\n",
      "134/134 [==============================] - 0s 463us/step - loss: 303045.1298 - val_loss: 135283.8277\n",
      "Epoch 4112/5000\n",
      "134/134 [==============================] - 0s 374us/step - loss: 165986.3125 - val_loss: 196954.5084\n",
      "Epoch 4113/5000\n",
      "134/134 [==============================] - 0s 338us/step - loss: 173453.0121 - val_loss: 124396.6266\n",
      "Epoch 4114/5000\n",
      "134/134 [==============================] - 0s 321us/step - loss: 123525.5034 - val_loss: 119114.1838\n",
      "Epoch 4115/5000\n",
      "134/134 [==============================] - 0s 331us/step - loss: 122563.6082 - val_loss: 117453.1175\n",
      "Epoch 4116/5000\n",
      "134/134 [==============================] - 0s 318us/step - loss: 123574.0810 - val_loss: 121288.9767\n",
      "Epoch 4117/5000\n",
      "134/134 [==============================] - 0s 324us/step - loss: 123204.0133 - val_loss: 208287.1959\n",
      "Epoch 4118/5000\n",
      "134/134 [==============================] - 0s 331us/step - loss: 165334.2811 - val_loss: 201318.1385\n",
      "Epoch 4119/5000\n",
      "134/134 [==============================] - 0s 341us/step - loss: 176861.2400 - val_loss: 161199.9293\n",
      "Epoch 4120/5000\n",
      "134/134 [==============================] - 0s 292us/step - loss: 211752.4579 - val_loss: 132922.7605\n",
      "Epoch 4121/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 125732.0905 - val_loss: 154265.8869\n",
      "Epoch 4122/5000\n",
      "134/134 [==============================] - 0s 435us/step - loss: 156455.8986 - val_loss: 175154.0075\n",
      "Epoch 4123/5000\n",
      "134/134 [==============================] - 0s 436us/step - loss: 266537.7258 - val_loss: 163490.4618\n",
      "Epoch 4124/5000\n",
      "134/134 [==============================] - 0s 371us/step - loss: 163490.9814 - val_loss: 157560.6563\n",
      "Epoch 4125/5000\n",
      "134/134 [==============================] - 0s 456us/step - loss: 139783.4313 - val_loss: 379524.5410\n",
      "Epoch 4126/5000\n",
      "134/134 [==============================] - 0s 317us/step - loss: 191466.4766 - val_loss: 215406.4627\n",
      "Epoch 4127/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 335832.6598 - val_loss: 146929.2964\n",
      "Epoch 4128/5000\n",
      "134/134 [==============================] - 0s 344us/step - loss: 154479.6658 - val_loss: 117075.2129\n",
      "Epoch 4129/5000\n",
      "134/134 [==============================] - 0s 371us/step - loss: 126562.5577 - val_loss: 129164.8028\n",
      "Epoch 4130/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 126033.7980 - val_loss: 121352.3861\n",
      "Epoch 4131/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 118802.8472 - val_loss: 116460.8997\n",
      "Epoch 4132/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 116892.9498 - val_loss: 120990.5634\n",
      "Epoch 4133/5000\n",
      "134/134 [==============================] - 0s 385us/step - loss: 129335.0220 - val_loss: 407895.9142\n",
      "Epoch 4134/5000\n",
      "134/134 [==============================] - 0s 385us/step - loss: 359420.9771 - val_loss: 346220.9879\n",
      "Epoch 4135/5000\n",
      "134/134 [==============================] - 0s 510us/step - loss: 174672.6294 - val_loss: 171399.1250\n",
      "Epoch 4136/5000\n",
      "134/134 [==============================] - 0s 418us/step - loss: 122981.3373 - val_loss: 115360.1643\n",
      "Epoch 4137/5000\n",
      "134/134 [==============================] - 0s 474us/step - loss: 119188.6229 - val_loss: 153411.2024\n",
      "Epoch 4138/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 137541.2206 - val_loss: 113345.2369\n",
      "Epoch 4139/5000\n",
      "134/134 [==============================] - 0s 373us/step - loss: 116700.6193 - val_loss: 120645.0737\n",
      "Epoch 4140/5000\n",
      "134/134 [==============================] - 0s 332us/step - loss: 119657.7838 - val_loss: 115528.9025\n",
      "Epoch 4141/5000\n",
      "134/134 [==============================] - 0s 369us/step - loss: 117776.5851 - val_loss: 114631.0376\n",
      "Epoch 4142/5000\n",
      "134/134 [==============================] - 0s 405us/step - loss: 128315.7571 - val_loss: 131379.2271\n",
      "Epoch 4143/5000\n",
      "134/134 [==============================] - 0s 382us/step - loss: 132603.5716 - val_loss: 151145.5126\n",
      "Epoch 4144/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 143903.7227 - val_loss: 150110.2855\n",
      "Epoch 4145/5000\n",
      "134/134 [==============================] - 0s 405us/step - loss: 249465.3525 - val_loss: 1354582.5793\n",
      "Epoch 4146/5000\n",
      "134/134 [==============================] - 0s 378us/step - loss: 327751.1001 - val_loss: 450652.5504\n",
      "Epoch 4147/5000\n",
      "134/134 [==============================] - 0s 400us/step - loss: 201985.5621 - val_loss: 177251.8958\n",
      "Epoch 4148/5000\n",
      "134/134 [==============================] - 0s 377us/step - loss: 140180.4275 - val_loss: 125970.0541\n",
      "Epoch 4149/5000\n",
      "134/134 [==============================] - 0s 334us/step - loss: 127376.0971 - val_loss: 120241.0589\n",
      "Epoch 4150/5000\n",
      "134/134 [==============================] - 0s 278us/step - loss: 126995.9376 - val_loss: 124524.3179\n",
      "Epoch 4151/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 141972.3629 - val_loss: 205537.4785\n",
      "Epoch 4152/5000\n",
      "134/134 [==============================] - 0s 329us/step - loss: 170990.8684 - val_loss: 161275.3104\n",
      "Epoch 4153/5000\n",
      "134/134 [==============================] - 0s 324us/step - loss: 148872.7253 - val_loss: 138336.5016\n",
      "Epoch 4154/5000\n",
      "134/134 [==============================] - 0s 336us/step - loss: 190999.3549 - val_loss: 164188.1287\n",
      "Epoch 4155/5000\n",
      "134/134 [==============================] - 0s 337us/step - loss: 156499.3273 - val_loss: 169711.8857\n",
      "Epoch 4156/5000\n",
      "134/134 [==============================] - 0s 319us/step - loss: 198912.6084 - val_loss: 164056.7299\n",
      "Epoch 4157/5000\n",
      "134/134 [==============================] - 0s 362us/step - loss: 157054.0687 - val_loss: 230117.1017\n",
      "Epoch 4158/5000\n",
      "134/134 [==============================] - 0s 362us/step - loss: 280352.2763 - val_loss: 137861.9552\n",
      "Epoch 4159/5000\n",
      "134/134 [==============================] - 0s 390us/step - loss: 224634.7592 - val_loss: 156221.4702\n",
      "Epoch 4160/5000\n",
      "134/134 [==============================] - 0s 451us/step - loss: 208176.7435 - val_loss: 451884.4972\n",
      "Epoch 4161/5000\n",
      "134/134 [==============================] - 0s 417us/step - loss: 265191.3570 - val_loss: 142133.5090\n",
      "Epoch 4162/5000\n",
      "134/134 [==============================] - 0s 386us/step - loss: 150389.9182 - val_loss: 165778.2929\n",
      "Epoch 4163/5000\n",
      "134/134 [==============================] - 0s 377us/step - loss: 151533.0543 - val_loss: 130617.2773\n",
      "Epoch 4164/5000\n",
      "134/134 [==============================] - 0s 405us/step - loss: 126515.8253 - val_loss: 116649.3680\n",
      "Epoch 4165/5000\n",
      "134/134 [==============================] - 0s 378us/step - loss: 119196.8352 - val_loss: 111578.0963\n",
      "Epoch 4166/5000\n",
      "134/134 [==============================] - 0s 399us/step - loss: 116316.3918 - val_loss: 111992.4921\n",
      "Epoch 4167/5000\n",
      "134/134 [==============================] - 0s 394us/step - loss: 115595.2438 - val_loss: 112731.9955\n",
      "Epoch 4168/5000\n",
      "134/134 [==============================] - 0s 401us/step - loss: 119303.4701 - val_loss: 132868.6423\n",
      "Epoch 4169/5000\n",
      "134/134 [==============================] - 0s 376us/step - loss: 132365.3667 - val_loss: 432432.0322\n",
      "Epoch 4170/5000\n",
      "134/134 [==============================] - 0s 407us/step - loss: 283663.7887 - val_loss: 216706.9911\n",
      "Epoch 4171/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 388us/step - loss: 167598.7291 - val_loss: 182601.9207\n",
      "Epoch 4172/5000\n",
      "134/134 [==============================] - 0s 413us/step - loss: 141308.3404 - val_loss: 127827.2955\n",
      "Epoch 4173/5000\n",
      "134/134 [==============================] - 0s 366us/step - loss: 137605.7269 - val_loss: 178322.0735\n",
      "Epoch 4174/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 139689.3302 - val_loss: 130827.4923\n",
      "Epoch 4175/5000\n",
      "134/134 [==============================] - 0s 339us/step - loss: 147297.3107 - val_loss: 185663.8762\n",
      "Epoch 4176/5000\n",
      "134/134 [==============================] - 0s 390us/step - loss: 150321.3448 - val_loss: 221448.2323\n",
      "Epoch 4177/5000\n",
      "134/134 [==============================] - 0s 384us/step - loss: 141602.8991 - val_loss: 133403.7929\n",
      "Epoch 4178/5000\n",
      "134/134 [==============================] - 0s 420us/step - loss: 134351.3898 - val_loss: 163198.7283\n",
      "Epoch 4179/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 240256.4707 - val_loss: 170109.3780\n",
      "Epoch 4180/5000\n",
      "134/134 [==============================] - 0s 352us/step - loss: 154289.4679 - val_loss: 127195.2906\n",
      "Epoch 4181/5000\n",
      "134/134 [==============================] - 0s 376us/step - loss: 137390.9249 - val_loss: 158095.5075\n",
      "Epoch 4182/5000\n",
      "134/134 [==============================] - 0s 392us/step - loss: 151163.4029 - val_loss: 117314.4737\n",
      "Epoch 4183/5000\n",
      "134/134 [==============================] - 0s 365us/step - loss: 121024.7575 - val_loss: 123221.7176\n",
      "Epoch 4184/5000\n",
      "134/134 [==============================] - 0s 397us/step - loss: 122108.9738 - val_loss: 148037.3379\n",
      "Epoch 4185/5000\n",
      "134/134 [==============================] - 0s 353us/step - loss: 127514.6793 - val_loss: 124096.1273\n",
      "Epoch 4186/5000\n",
      "134/134 [==============================] - 0s 345us/step - loss: 123682.3692 - val_loss: 134924.5568\n",
      "Epoch 4187/5000\n",
      "134/134 [==============================] - 0s 344us/step - loss: 186677.7424 - val_loss: 465147.0980\n",
      "Epoch 4188/5000\n",
      "134/134 [==============================] - 0s 365us/step - loss: 340592.9451 - val_loss: 159106.3244\n",
      "Epoch 4189/5000\n",
      "134/134 [==============================] - 0s 402us/step - loss: 149960.8653 - val_loss: 142029.8610\n",
      "Epoch 4190/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 162282.9186 - val_loss: 526937.5168\n",
      "Epoch 4191/5000\n",
      "134/134 [==============================] - 0s 284us/step - loss: 347849.6487 - val_loss: 308311.1365\n",
      "Epoch 4192/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 468953.2314 - val_loss: 210665.3074\n",
      "Epoch 4193/5000\n",
      "134/134 [==============================] - 0s 299us/step - loss: 232016.2610 - val_loss: 227075.2118\n",
      "Epoch 4194/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 142988.9189 - val_loss: 124158.0357\n",
      "Epoch 4195/5000\n",
      "134/134 [==============================] - 0s 337us/step - loss: 120812.7859 - val_loss: 113178.5822\n",
      "Epoch 4196/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 116393.3017 - val_loss: 138074.1495\n",
      "Epoch 4197/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 136693.1247 - val_loss: 159695.4338\n",
      "Epoch 4198/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 131398.1330 - val_loss: 114249.5604\n",
      "Epoch 4199/5000\n",
      "134/134 [==============================] - 0s 504us/step - loss: 126031.0235 - val_loss: 116876.1961\n",
      "Epoch 4200/5000\n",
      "134/134 [==============================] - 0s 580us/step - loss: 120319.5663 - val_loss: 115866.8510\n",
      "Epoch 4201/5000\n",
      "134/134 [==============================] - 0s 439us/step - loss: 134342.9508 - val_loss: 149137.5289\n",
      "Epoch 4202/5000\n",
      "134/134 [==============================] - 0s 381us/step - loss: 153733.8134 - val_loss: 167274.8829\n",
      "Epoch 4203/5000\n",
      "134/134 [==============================] - 0s 358us/step - loss: 204523.9784 - val_loss: 258747.4081\n",
      "Epoch 4204/5000\n",
      "134/134 [==============================] - 0s 418us/step - loss: 186579.1566 - val_loss: 552714.8102\n",
      "Epoch 4205/5000\n",
      "134/134 [==============================] - 0s 353us/step - loss: 424947.5664 - val_loss: 236212.7659\n",
      "Epoch 4206/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 226857.8228 - val_loss: 225023.7083\n",
      "Epoch 4207/5000\n",
      "134/134 [==============================] - 0s 320us/step - loss: 200819.9966 - val_loss: 219489.8745\n",
      "Epoch 4208/5000\n",
      "134/134 [==============================] - 0s 372us/step - loss: 144324.6606 - val_loss: 120763.8657\n",
      "Epoch 4209/5000\n",
      "134/134 [==============================] - 0s 384us/step - loss: 121119.4955 - val_loss: 138513.1159\n",
      "Epoch 4210/5000\n",
      "134/134 [==============================] - 0s 428us/step - loss: 124397.9473 - val_loss: 132184.5581\n",
      "Epoch 4211/5000\n",
      "134/134 [==============================] - 0s 379us/step - loss: 120319.8755 - val_loss: 126807.7403\n",
      "Epoch 4212/5000\n",
      "134/134 [==============================] - 0s 348us/step - loss: 163619.1571 - val_loss: 134559.8703\n",
      "Epoch 4213/5000\n",
      "134/134 [==============================] - 0s 350us/step - loss: 133156.4111 - val_loss: 115164.8118\n",
      "Epoch 4214/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 124269.9787 - val_loss: 319044.2561\n",
      "Epoch 4215/5000\n",
      "134/134 [==============================] - 0s 301us/step - loss: 213203.7860 - val_loss: 165068.1614\n",
      "Epoch 4216/5000\n",
      "134/134 [==============================] - 0s 334us/step - loss: 144884.0024 - val_loss: 140243.4887\n",
      "Epoch 4217/5000\n",
      "134/134 [==============================] - 0s 324us/step - loss: 136350.3514 - val_loss: 122053.4307\n",
      "Epoch 4218/5000\n",
      "134/134 [==============================] - 0s 336us/step - loss: 121053.2510 - val_loss: 456823.5821\n",
      "Epoch 4219/5000\n",
      "134/134 [==============================] - 0s 378us/step - loss: 174523.1948 - val_loss: 239651.0861\n",
      "Epoch 4220/5000\n",
      "134/134 [==============================] - 0s 420us/step - loss: 193208.1889 - val_loss: 260091.0994\n",
      "Epoch 4221/5000\n",
      "134/134 [==============================] - 0s 331us/step - loss: 195453.6988 - val_loss: 176160.5513\n",
      "Epoch 4222/5000\n",
      "134/134 [==============================] - 0s 358us/step - loss: 181446.6347 - val_loss: 156655.5749\n",
      "Epoch 4223/5000\n",
      "134/134 [==============================] - 0s 374us/step - loss: 143881.1500 - val_loss: 152350.8820\n",
      "Epoch 4224/5000\n",
      "134/134 [==============================] - 0s 352us/step - loss: 209138.1442 - val_loss: 159088.5518\n",
      "Epoch 4225/5000\n",
      "134/134 [==============================] - 0s 341us/step - loss: 234815.3769 - val_loss: 288960.1446\n",
      "Epoch 4226/5000\n",
      "134/134 [==============================] - 0s 479us/step - loss: 233258.4366 - val_loss: 152619.3127\n",
      "Epoch 4227/5000\n",
      "134/134 [==============================] - 0s 438us/step - loss: 144257.1252 - val_loss: 179038.9590\n",
      "Epoch 4228/5000\n",
      "134/134 [==============================] - 0s 428us/step - loss: 143627.6479 - val_loss: 114227.4492\n",
      "Epoch 4229/5000\n",
      "134/134 [==============================] - 0s 444us/step - loss: 115973.2462 - val_loss: 117910.4430\n",
      "Epoch 4230/5000\n",
      "134/134 [==============================] - 0s 474us/step - loss: 121930.7781 - val_loss: 114169.5998\n",
      "Epoch 4231/5000\n",
      "134/134 [==============================] - 0s 413us/step - loss: 134271.9477 - val_loss: 215579.9410\n",
      "Epoch 4232/5000\n",
      "134/134 [==============================] - 0s 501us/step - loss: 220538.7901 - val_loss: 388716.4916\n",
      "Epoch 4233/5000\n",
      "134/134 [==============================] - 0s 428us/step - loss: 239973.6725 - val_loss: 373342.5625\n",
      "Epoch 4234/5000\n",
      "134/134 [==============================] - 0s 473us/step - loss: 262907.7018 - val_loss: 241707.0243\n",
      "Epoch 4235/5000\n",
      "134/134 [==============================] - 0s 456us/step - loss: 189302.6324 - val_loss: 155521.0310\n",
      "Epoch 4236/5000\n",
      "134/134 [==============================] - 0s 403us/step - loss: 133451.4850 - val_loss: 231346.5441\n",
      "Epoch 4237/5000\n",
      "134/134 [==============================] - 0s 470us/step - loss: 146444.5592 - val_loss: 202908.1712\n",
      "Epoch 4238/5000\n",
      "134/134 [==============================] - 0s 428us/step - loss: 136601.9830 - val_loss: 111164.3650\n",
      "Epoch 4239/5000\n",
      "134/134 [==============================] - 0s 470us/step - loss: 113180.0036 - val_loss: 111000.4288\n",
      "Epoch 4240/5000\n",
      "134/134 [==============================] - 0s 413us/step - loss: 112825.6854 - val_loss: 111628.5050\n",
      "Epoch 4241/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 396us/step - loss: 111666.2454 - val_loss: 130961.1863\n",
      "Epoch 4242/5000\n",
      "134/134 [==============================] - 0s 418us/step - loss: 121393.2198 - val_loss: 168843.5921\n",
      "Epoch 4243/5000\n",
      "134/134 [==============================] - 0s 577us/step - loss: 162263.3727 - val_loss: 589093.0868\n",
      "Epoch 4244/5000\n",
      "134/134 [==============================] - 0s 466us/step - loss: 336736.6987 - val_loss: 158902.3133\n",
      "Epoch 4245/5000\n",
      "134/134 [==============================] - 0s 485us/step - loss: 155490.6461 - val_loss: 130778.4882\n",
      "Epoch 4246/5000\n",
      "134/134 [==============================] - 0s 435us/step - loss: 135081.6763 - val_loss: 152569.1245\n",
      "Epoch 4247/5000\n",
      "134/134 [==============================] - 0s 358us/step - loss: 137543.1613 - val_loss: 135674.0882\n",
      "Epoch 4248/5000\n",
      "134/134 [==============================] - 0s 375us/step - loss: 120850.9721 - val_loss: 171545.4132\n",
      "Epoch 4249/5000\n",
      "134/134 [==============================] - 0s 345us/step - loss: 130285.2614 - val_loss: 124713.4228\n",
      "Epoch 4250/5000\n",
      "134/134 [==============================] - 0s 445us/step - loss: 134566.4900 - val_loss: 240512.3512\n",
      "Epoch 4251/5000\n",
      "134/134 [==============================] - 0s 453us/step - loss: 229013.9539 - val_loss: 237205.0616\n",
      "Epoch 4252/5000\n",
      "134/134 [==============================] - 0s 500us/step - loss: 287433.1482 - val_loss: 152915.3343\n",
      "Epoch 4253/5000\n",
      "134/134 [==============================] - 0s 444us/step - loss: 176512.5754 - val_loss: 212145.5464\n",
      "Epoch 4254/5000\n",
      "134/134 [==============================] - 0s 429us/step - loss: 163370.2508 - val_loss: 118949.2010\n",
      "Epoch 4255/5000\n",
      "134/134 [==============================] - 0s 521us/step - loss: 120087.7456 - val_loss: 119461.5209\n",
      "Epoch 4256/5000\n",
      "134/134 [==============================] - 0s 487us/step - loss: 125818.3036 - val_loss: 110548.6653\n",
      "Epoch 4257/5000\n",
      "134/134 [==============================] - 0s 484us/step - loss: 115006.7401 - val_loss: 145571.9496\n",
      "Epoch 4258/5000\n",
      "134/134 [==============================] - 0s 408us/step - loss: 149905.9049 - val_loss: 124354.6672\n",
      "Epoch 4259/5000\n",
      "134/134 [==============================] - 0s 337us/step - loss: 136381.2489 - val_loss: 120704.7863\n",
      "Epoch 4260/5000\n",
      "134/134 [==============================] - 0s 349us/step - loss: 229570.5747 - val_loss: 447566.8223\n",
      "Epoch 4261/5000\n",
      "134/134 [==============================] - 0s 341us/step - loss: 312458.9207 - val_loss: 140445.2706\n",
      "Epoch 4262/5000\n",
      "134/134 [==============================] - 0s 393us/step - loss: 166010.2608 - val_loss: 131322.0807\n",
      "Epoch 4263/5000\n",
      "134/134 [==============================] - 0s 370us/step - loss: 154082.7234 - val_loss: 265647.3815\n",
      "Epoch 4264/5000\n",
      "134/134 [==============================] - 0s 325us/step - loss: 131744.3864 - val_loss: 125793.7195\n",
      "Epoch 4265/5000\n",
      "134/134 [==============================] - 0s 405us/step - loss: 151392.2220 - val_loss: 183174.7341\n",
      "Epoch 4266/5000\n",
      "134/134 [==============================] - 0s 766us/step - loss: 164068.5120 - val_loss: 115401.1584\n",
      "Epoch 4267/5000\n",
      "134/134 [==============================] - 0s 510us/step - loss: 113791.1835 - val_loss: 113415.0662\n",
      "Epoch 4268/5000\n",
      "134/134 [==============================] - 0s 476us/step - loss: 116004.2761 - val_loss: 115482.1915\n",
      "Epoch 4269/5000\n",
      "134/134 [==============================] - 0s 621us/step - loss: 130715.2193 - val_loss: 126275.7225\n",
      "Epoch 4270/5000\n",
      "134/134 [==============================] - 0s 373us/step - loss: 127298.1682 - val_loss: 123899.7344\n",
      "Epoch 4271/5000\n",
      "134/134 [==============================] - 0s 332us/step - loss: 177915.3946 - val_loss: 122039.8202\n",
      "Epoch 4272/5000\n",
      "134/134 [==============================] - 0s 355us/step - loss: 134532.3510 - val_loss: 129907.7038\n",
      "Epoch 4273/5000\n",
      "134/134 [==============================] - 0s 368us/step - loss: 132156.9230 - val_loss: 243962.5126\n",
      "Epoch 4274/5000\n",
      "134/134 [==============================] - 0s 409us/step - loss: 218178.2009 - val_loss: 338496.7589\n",
      "Epoch 4275/5000\n",
      "134/134 [==============================] - 0s 391us/step - loss: 425085.3651 - val_loss: 162898.3896\n",
      "Epoch 4276/5000\n",
      "134/134 [==============================] - 0s 357us/step - loss: 160114.7797 - val_loss: 117975.5362\n",
      "Epoch 4277/5000\n",
      "134/134 [==============================] - 0s 363us/step - loss: 118528.1833 - val_loss: 110608.5702\n",
      "Epoch 4278/5000\n",
      "134/134 [==============================] - 0s 381us/step - loss: 115177.3064 - val_loss: 114175.1589\n",
      "Epoch 4279/5000\n",
      "134/134 [==============================] - 0s 523us/step - loss: 113643.7160 - val_loss: 123381.0700\n",
      "Epoch 4280/5000\n",
      "134/134 [==============================] - 0s 357us/step - loss: 133823.7574 - val_loss: 114067.0325\n",
      "Epoch 4281/5000\n",
      "134/134 [==============================] - 0s 346us/step - loss: 133064.8228 - val_loss: 195830.6525\n",
      "Epoch 4282/5000\n",
      "134/134 [==============================] - 0s 334us/step - loss: 154732.3701 - val_loss: 132836.2316\n",
      "Epoch 4283/5000\n",
      "134/134 [==============================] - 0s 324us/step - loss: 165470.8904 - val_loss: 288540.6730\n",
      "Epoch 4284/5000\n",
      "134/134 [==============================] - 0s 374us/step - loss: 177262.0086 - val_loss: 140094.0452\n",
      "Epoch 4285/5000\n",
      "134/134 [==============================] - 0s 371us/step - loss: 156407.4014 - val_loss: 148796.1679\n",
      "Epoch 4286/5000\n",
      "134/134 [==============================] - 0s 366us/step - loss: 146334.7597 - val_loss: 136915.7910\n",
      "Epoch 4287/5000\n",
      "134/134 [==============================] - 0s 390us/step - loss: 132730.8136 - val_loss: 120295.1207\n",
      "Epoch 4288/5000\n",
      "134/134 [==============================] - 0s 331us/step - loss: 204345.4285 - val_loss: 397700.5009\n",
      "Epoch 4289/5000\n",
      "134/134 [==============================] - 0s 412us/step - loss: 210087.4951 - val_loss: 132839.4174\n",
      "Epoch 4290/5000\n",
      "134/134 [==============================] - 0s 399us/step - loss: 128476.5141 - val_loss: 126617.1371\n",
      "Epoch 4291/5000\n",
      "134/134 [==============================] - 0s 344us/step - loss: 125520.0284 - val_loss: 113646.0009\n",
      "Epoch 4292/5000\n",
      "134/134 [==============================] - 0s 341us/step - loss: 118163.2163 - val_loss: 111415.6212\n",
      "Epoch 4293/5000\n",
      "134/134 [==============================] - 0s 331us/step - loss: 123690.7505 - val_loss: 207923.8442\n",
      "Epoch 4294/5000\n",
      "134/134 [==============================] - 0s 392us/step - loss: 129915.9867 - val_loss: 120199.9325\n",
      "Epoch 4295/5000\n",
      "134/134 [==============================] - 0s 410us/step - loss: 143328.3144 - val_loss: 140911.8366\n",
      "Epoch 4296/5000\n",
      "134/134 [==============================] - 0s 349us/step - loss: 242569.5519 - val_loss: 145537.3843\n",
      "Epoch 4297/5000\n",
      "134/134 [==============================] - 0s 424us/step - loss: 166935.1539 - val_loss: 248069.6698\n",
      "Epoch 4298/5000\n",
      "134/134 [==============================] - 0s 363us/step - loss: 196157.6955 - val_loss: 155812.5728\n",
      "Epoch 4299/5000\n",
      "134/134 [==============================] - 0s 348us/step - loss: 136367.8958 - val_loss: 124255.5697\n",
      "Epoch 4300/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 132922.6448 - val_loss: 130311.1549\n",
      "Epoch 4301/5000\n",
      "134/134 [==============================] - 0s 304us/step - loss: 125688.2342 - val_loss: 131281.0044\n",
      "Epoch 4302/5000\n",
      "134/134 [==============================] - 0s 345us/step - loss: 128654.1482 - val_loss: 153611.4723\n",
      "Epoch 4303/5000\n",
      "134/134 [==============================] - 0s 346us/step - loss: 143905.7767 - val_loss: 146366.5492\n",
      "Epoch 4304/5000\n",
      "134/134 [==============================] - 0s 346us/step - loss: 182347.2192 - val_loss: 121850.1285\n",
      "Epoch 4305/5000\n",
      "134/134 [==============================] - 0s 335us/step - loss: 145560.2024 - val_loss: 126310.9921\n",
      "Epoch 4306/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 197493.3333 - val_loss: 135169.3565\n",
      "Epoch 4307/5000\n",
      "134/134 [==============================] - 0s 278us/step - loss: 145253.3737 - val_loss: 125996.7600\n",
      "Epoch 4308/5000\n",
      "134/134 [==============================] - 0s 335us/step - loss: 143296.0915 - val_loss: 145796.8850\n",
      "Epoch 4309/5000\n",
      "134/134 [==============================] - 0s 315us/step - loss: 145200.9233 - val_loss: 307968.2528\n",
      "Epoch 4310/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 174150.7532 - val_loss: 243494.9202\n",
      "Epoch 4311/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 294us/step - loss: 291378.6268 - val_loss: 526398.3638\n",
      "Epoch 4312/5000\n",
      "134/134 [==============================] - 0s 353us/step - loss: 189204.4446 - val_loss: 159649.7589\n",
      "Epoch 4313/5000\n",
      "134/134 [==============================] - 0s 337us/step - loss: 144035.3204 - val_loss: 111686.6649\n",
      "Epoch 4314/5000\n",
      "134/134 [==============================] - 0s 354us/step - loss: 114923.5982 - val_loss: 108111.7188\n",
      "Epoch 4315/5000\n",
      "134/134 [==============================] - 0s 338us/step - loss: 113969.4548 - val_loss: 124010.9843\n",
      "Epoch 4316/5000\n",
      "134/134 [==============================] - 0s 320us/step - loss: 115803.8378 - val_loss: 111063.0819\n",
      "Epoch 4317/5000\n",
      "134/134 [==============================] - 0s 324us/step - loss: 113911.7469 - val_loss: 116530.2148\n",
      "Epoch 4318/5000\n",
      "134/134 [==============================] - 0s 335us/step - loss: 116522.9258 - val_loss: 124571.2675\n",
      "Epoch 4319/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 162118.8802 - val_loss: 130835.3041\n",
      "Epoch 4320/5000\n",
      "134/134 [==============================] - 0s 342us/step - loss: 158954.3025 - val_loss: 147310.2486\n",
      "Epoch 4321/5000\n",
      "134/134 [==============================] - 0s 549us/step - loss: 155634.8548 - val_loss: 126091.4502\n",
      "Epoch 4322/5000\n",
      "134/134 [==============================] - 0s 318us/step - loss: 148201.9808 - val_loss: 239114.5718\n",
      "Epoch 4323/5000\n",
      "134/134 [==============================] - 0s 395us/step - loss: 248665.0902 - val_loss: 161271.7593\n",
      "Epoch 4324/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 315392.9393 - val_loss: 127022.5585\n",
      "Epoch 4325/5000\n",
      "134/134 [==============================] - 0s 336us/step - loss: 128145.9198 - val_loss: 241093.1049\n",
      "Epoch 4326/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 155550.6601 - val_loss: 119981.0389\n",
      "Epoch 4327/5000\n",
      "134/134 [==============================] - 0s 331us/step - loss: 146177.8311 - val_loss: 189401.2193\n",
      "Epoch 4328/5000\n",
      "134/134 [==============================] - 0s 377us/step - loss: 181550.6425 - val_loss: 145977.2474\n",
      "Epoch 4329/5000\n",
      "134/134 [==============================] - 0s 521us/step - loss: 217354.3375 - val_loss: 143639.7957\n",
      "Epoch 4330/5000\n",
      "134/134 [==============================] - 0s 318us/step - loss: 153560.1051 - val_loss: 116850.0262\n",
      "Epoch 4331/5000\n",
      "134/134 [==============================] - 0s 284us/step - loss: 124457.3847 - val_loss: 120118.6945\n",
      "Epoch 4332/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 130734.5855 - val_loss: 139757.6980\n",
      "Epoch 4333/5000\n",
      "134/134 [==============================] - 0s 323us/step - loss: 141036.6676 - val_loss: 137290.5322\n",
      "Epoch 4334/5000\n",
      "134/134 [==============================] - 0s 368us/step - loss: 133048.3070 - val_loss: 178111.7780\n",
      "Epoch 4335/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 145457.8486 - val_loss: 188021.8563\n",
      "Epoch 4336/5000\n",
      "134/134 [==============================] - 0s 366us/step - loss: 192537.4800 - val_loss: 427366.8988\n",
      "Epoch 4337/5000\n",
      "134/134 [==============================] - 0s 321us/step - loss: 208260.1222 - val_loss: 965384.7192\n",
      "Epoch 4338/5000\n",
      "134/134 [==============================] - 0s 288us/step - loss: 464658.0385 - val_loss: 148013.8883\n",
      "Epoch 4339/5000\n",
      "134/134 [==============================] - 0s 369us/step - loss: 158818.1219 - val_loss: 117858.6974\n",
      "Epoch 4340/5000\n",
      "134/134 [==============================] - 0s 409us/step - loss: 121434.6201 - val_loss: 123582.1733\n",
      "Epoch 4341/5000\n",
      "134/134 [==============================] - 0s 427us/step - loss: 120833.8795 - val_loss: 119919.0209\n",
      "Epoch 4342/5000\n",
      "134/134 [==============================] - 0s 336us/step - loss: 123677.0819 - val_loss: 131386.4942\n",
      "Epoch 4343/5000\n",
      "134/134 [==============================] - 0s 389us/step - loss: 118660.8330 - val_loss: 109980.0342\n",
      "Epoch 4344/5000\n",
      "134/134 [==============================] - 0s 400us/step - loss: 114933.8236 - val_loss: 132158.2220\n",
      "Epoch 4345/5000\n",
      "134/134 [==============================] - 0s 344us/step - loss: 120561.6801 - val_loss: 110951.8822\n",
      "Epoch 4346/5000\n",
      "134/134 [==============================] - 0s 293us/step - loss: 122640.4987 - val_loss: 178595.1964\n",
      "Epoch 4347/5000\n",
      "134/134 [==============================] - 0s 440us/step - loss: 132352.8110 - val_loss: 115915.1849\n",
      "Epoch 4348/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 124542.6621 - val_loss: 231886.7108\n",
      "Epoch 4349/5000\n",
      "134/134 [==============================] - 0s 376us/step - loss: 187988.7488 - val_loss: 227064.8475\n",
      "Epoch 4350/5000\n",
      "134/134 [==============================] - 0s 439us/step - loss: 205755.2041 - val_loss: 543620.0431\n",
      "Epoch 4351/5000\n",
      "134/134 [==============================] - 0s 415us/step - loss: 252281.8941 - val_loss: 119342.3792\n",
      "Epoch 4352/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 117478.1892 - val_loss: 226520.9767\n",
      "Epoch 4353/5000\n",
      "134/134 [==============================] - 0s 445us/step - loss: 151131.6002 - val_loss: 139063.7137\n",
      "Epoch 4354/5000\n",
      "134/134 [==============================] - 0s 339us/step - loss: 176903.3093 - val_loss: 790576.4515\n",
      "Epoch 4355/5000\n",
      "134/134 [==============================] - 0s 331us/step - loss: 201252.3396 - val_loss: 148124.7104\n",
      "Epoch 4356/5000\n",
      "134/134 [==============================] - 0s 284us/step - loss: 298733.3242 - val_loss: 258380.0858\n",
      "Epoch 4357/5000\n",
      "134/134 [==============================] - 0s 391us/step - loss: 286777.0293 - val_loss: 389349.7948\n",
      "Epoch 4358/5000\n",
      "134/134 [==============================] - 0s 334us/step - loss: 210942.5328 - val_loss: 183501.2276\n",
      "Epoch 4359/5000\n",
      "134/134 [==============================] - 0s 460us/step - loss: 148957.4369 - val_loss: 138219.0140\n",
      "Epoch 4360/5000\n",
      "134/134 [==============================] - 0s 351us/step - loss: 133737.5204 - val_loss: 128161.5590\n",
      "Epoch 4361/5000\n",
      "134/134 [==============================] - 0s 332us/step - loss: 124468.1631 - val_loss: 113556.6856\n",
      "Epoch 4362/5000\n",
      "134/134 [==============================] - 0s 332us/step - loss: 113140.3191 - val_loss: 111381.5771\n",
      "Epoch 4363/5000\n",
      "134/134 [==============================] - 0s 363us/step - loss: 111411.6470 - val_loss: 108110.5554\n",
      "Epoch 4364/5000\n",
      "134/134 [==============================] - 0s 370us/step - loss: 111510.3495 - val_loss: 107801.0486\n",
      "Epoch 4365/5000\n",
      "134/134 [==============================] - 0s 550us/step - loss: 110291.6430 - val_loss: 111846.2927\n",
      "Epoch 4366/5000\n",
      "134/134 [==============================] - 0s 550us/step - loss: 117383.5717 - val_loss: 123914.2320\n",
      "Epoch 4367/5000\n",
      "134/134 [==============================] - 0s 342us/step - loss: 118569.8039 - val_loss: 224680.0518\n",
      "Epoch 4368/5000\n",
      "134/134 [==============================] - 0s 359us/step - loss: 141830.3766 - val_loss: 166657.1248\n",
      "Epoch 4369/5000\n",
      "134/134 [==============================] - 0s 304us/step - loss: 175438.4270 - val_loss: 254946.3587\n",
      "Epoch 4370/5000\n",
      "134/134 [==============================] - 0s 329us/step - loss: 215976.4170 - val_loss: 284929.3811\n",
      "Epoch 4371/5000\n",
      "134/134 [==============================] - 0s 299us/step - loss: 193492.8451 - val_loss: 298623.6992\n",
      "Epoch 4372/5000\n",
      "134/134 [==============================] - 0s 315us/step - loss: 248351.3175 - val_loss: 154197.4578\n",
      "Epoch 4373/5000\n",
      "134/134 [==============================] - 0s 367us/step - loss: 143742.3860 - val_loss: 133348.3303\n",
      "Epoch 4374/5000\n",
      "134/134 [==============================] - 0s 374us/step - loss: 180399.1051 - val_loss: 176500.2104\n",
      "Epoch 4375/5000\n",
      "134/134 [==============================] - 0s 374us/step - loss: 132389.3775 - val_loss: 127098.0515\n",
      "Epoch 4376/5000\n",
      "134/134 [==============================] - 0s 362us/step - loss: 173550.8315 - val_loss: 143941.8598\n",
      "Epoch 4377/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 141636.7309 - val_loss: 163599.0149\n",
      "Epoch 4378/5000\n",
      "134/134 [==============================] - 0s 345us/step - loss: 156118.0608 - val_loss: 120863.9119\n",
      "Epoch 4379/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 140557.3085 - val_loss: 432720.8867\n",
      "Epoch 4380/5000\n",
      "134/134 [==============================] - 0s 293us/step - loss: 256708.9644 - val_loss: 208450.4384\n",
      "Epoch 4381/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 338us/step - loss: 165950.7954 - val_loss: 136641.1196\n",
      "Epoch 4382/5000\n",
      "134/134 [==============================] - 0s 369us/step - loss: 145840.0061 - val_loss: 200474.1772\n",
      "Epoch 4383/5000\n",
      "134/134 [==============================] - 0s 393us/step - loss: 156457.1451 - val_loss: 153646.7992\n",
      "Epoch 4384/5000\n",
      "134/134 [==============================] - 0s 442us/step - loss: 136016.7948 - val_loss: 157025.9419\n",
      "Epoch 4385/5000\n",
      "134/134 [==============================] - 0s 385us/step - loss: 136747.6351 - val_loss: 124664.2020\n",
      "Epoch 4386/5000\n",
      "134/134 [==============================] - 0s 354us/step - loss: 130304.7570 - val_loss: 410749.7910\n",
      "Epoch 4387/5000\n",
      "134/134 [==============================] - 0s 331us/step - loss: 145104.5606 - val_loss: 162021.2901\n",
      "Epoch 4388/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 305761.6444 - val_loss: 356276.8265\n",
      "Epoch 4389/5000\n",
      "134/134 [==============================] - 0s 335us/step - loss: 301271.2563 - val_loss: 145172.9179\n",
      "Epoch 4390/5000\n",
      "134/134 [==============================] - 0s 368us/step - loss: 218588.1142 - val_loss: 199678.8629\n",
      "Epoch 4391/5000\n",
      "134/134 [==============================] - 0s 468us/step - loss: 138488.2879 - val_loss: 188829.4634\n",
      "Epoch 4392/5000\n",
      "134/134 [==============================] - 0s 441us/step - loss: 139066.4447 - val_loss: 107497.5949\n",
      "Epoch 4393/5000\n",
      "134/134 [==============================] - 0s 519us/step - loss: 124050.9362 - val_loss: 108907.1549\n",
      "Epoch 4394/5000\n",
      "134/134 [==============================] - 0s 400us/step - loss: 110844.0073 - val_loss: 104121.1481\n",
      "Epoch 4395/5000\n",
      "134/134 [==============================] - 0s 315us/step - loss: 108358.9702 - val_loss: 104901.3118\n",
      "Epoch 4396/5000\n",
      "134/134 [==============================] - 0s 334us/step - loss: 107953.3443 - val_loss: 115907.8646\n",
      "Epoch 4397/5000\n",
      "134/134 [==============================] - 0s 616us/step - loss: 111459.5089 - val_loss: 117463.4468\n",
      "Epoch 4398/5000\n",
      "134/134 [==============================] - 0s 477us/step - loss: 110378.9164 - val_loss: 107517.4149\n",
      "Epoch 4399/5000\n",
      "134/134 [==============================] - 0s 486us/step - loss: 114579.7650 - val_loss: 132233.2369\n",
      "Epoch 4400/5000\n",
      "134/134 [==============================] - 0s 352us/step - loss: 121455.8057 - val_loss: 163768.1164\n",
      "Epoch 4401/5000\n",
      "134/134 [==============================] - 0s 332us/step - loss: 181187.3745 - val_loss: 240738.4146\n",
      "Epoch 4402/5000\n",
      "134/134 [==============================] - 0s 315us/step - loss: 270989.3051 - val_loss: 173488.3808\n",
      "Epoch 4403/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 349600.8989 - val_loss: 230836.3281\n",
      "Epoch 4404/5000\n",
      "134/134 [==============================] - 0s 319us/step - loss: 237818.0060 - val_loss: 175044.9951\n",
      "Epoch 4405/5000\n",
      "134/134 [==============================] - 0s 324us/step - loss: 174945.4855 - val_loss: 365787.3703\n",
      "Epoch 4406/5000\n",
      "134/134 [==============================] - 0s 358us/step - loss: 377518.6269 - val_loss: 951117.1938\n",
      "Epoch 4407/5000\n",
      "134/134 [==============================] - 0s 366us/step - loss: 407682.9057 - val_loss: 266429.2934\n",
      "Epoch 4408/5000\n",
      "134/134 [==============================] - 0s 342us/step - loss: 366292.7535 - val_loss: 210273.2708\n",
      "Epoch 4409/5000\n",
      "134/134 [==============================] - 0s 373us/step - loss: 166080.6881 - val_loss: 121057.2008\n",
      "Epoch 4410/5000\n",
      "134/134 [==============================] - 0s 435us/step - loss: 118715.5046 - val_loss: 111886.8591\n",
      "Epoch 4411/5000\n",
      "134/134 [==============================] - 0s 417us/step - loss: 117276.1943 - val_loss: 125639.7260\n",
      "Epoch 4412/5000\n",
      "134/134 [==============================] - 0s 363us/step - loss: 118915.5456 - val_loss: 113566.0266\n",
      "Epoch 4413/5000\n",
      "134/134 [==============================] - 0s 351us/step - loss: 112075.2750 - val_loss: 106693.5175\n",
      "Epoch 4414/5000\n",
      "134/134 [==============================] - 0s 359us/step - loss: 115548.1399 - val_loss: 112634.3454\n",
      "Epoch 4415/5000\n",
      "134/134 [==============================] - ETA: 0s - loss: 174858.40 - 0s 344us/step - loss: 113434.9993 - val_loss: 370898.0508\n",
      "Epoch 4416/5000\n",
      "134/134 [==============================] - 0s 372us/step - loss: 233934.6866 - val_loss: 157906.7990\n",
      "Epoch 4417/5000\n",
      "134/134 [==============================] - 0s 440us/step - loss: 127998.7771 - val_loss: 127190.6413\n",
      "Epoch 4418/5000\n",
      "134/134 [==============================] - 0s 385us/step - loss: 128096.2860 - val_loss: 114336.1917\n",
      "Epoch 4419/5000\n",
      "134/134 [==============================] - 0s 356us/step - loss: 136282.2587 - val_loss: 125297.6192\n",
      "Epoch 4420/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 131248.4977 - val_loss: 117655.2603\n",
      "Epoch 4421/5000\n",
      "134/134 [==============================] - 0s 414us/step - loss: 116463.7668 - val_loss: 114989.0849\n",
      "Epoch 4422/5000\n",
      "134/134 [==============================] - 0s 345us/step - loss: 110225.5045 - val_loss: 122390.8375\n",
      "Epoch 4423/5000\n",
      "134/134 [==============================] - 0s 346us/step - loss: 113873.8070 - val_loss: 136940.3112\n",
      "Epoch 4424/5000\n",
      "134/134 [==============================] - 0s 393us/step - loss: 133035.3525 - val_loss: 152015.6072\n",
      "Epoch 4425/5000\n",
      "134/134 [==============================] - 0s 406us/step - loss: 161872.2474 - val_loss: 156854.4207\n",
      "Epoch 4426/5000\n",
      "134/134 [==============================] - 0s 365us/step - loss: 177400.2421 - val_loss: 222882.5934\n",
      "Epoch 4427/5000\n",
      "134/134 [==============================] - 0s 423us/step - loss: 198050.4305 - val_loss: 147304.6474\n",
      "Epoch 4428/5000\n",
      "134/134 [==============================] - 0s 374us/step - loss: 214789.7803 - val_loss: 683601.4198\n",
      "Epoch 4429/5000\n",
      "134/134 [==============================] - 0s 332us/step - loss: 592984.6909 - val_loss: 154498.6624\n",
      "Epoch 4430/5000\n",
      "134/134 [==============================] - 0s 396us/step - loss: 148760.7915 - val_loss: 203193.2227\n",
      "Epoch 4431/5000\n",
      "134/134 [==============================] - 0s 429us/step - loss: 153111.4483 - val_loss: 130970.1961\n",
      "Epoch 4432/5000\n",
      "134/134 [==============================] - 0s 394us/step - loss: 117027.6313 - val_loss: 123945.7311\n",
      "Epoch 4433/5000\n",
      "134/134 [==============================] - 0s 333us/step - loss: 154668.5167 - val_loss: 183116.0138\n",
      "Epoch 4434/5000\n",
      "134/134 [==============================] - 0s 379us/step - loss: 142878.0114 - val_loss: 106289.2836\n",
      "Epoch 4435/5000\n",
      "134/134 [==============================] - 0s 391us/step - loss: 115066.3603 - val_loss: 119072.5040\n",
      "Epoch 4436/5000\n",
      "134/134 [==============================] - 0s 376us/step - loss: 119295.2075 - val_loss: 110374.0238\n",
      "Epoch 4437/5000\n",
      "134/134 [==============================] - 0s 360us/step - loss: 118422.6100 - val_loss: 117654.8106\n",
      "Epoch 4438/5000\n",
      "134/134 [==============================] - 0s 375us/step - loss: 126497.1695 - val_loss: 124436.0774\n",
      "Epoch 4439/5000\n",
      "134/134 [==============================] - 0s 419us/step - loss: 136070.2385 - val_loss: 128354.5138\n",
      "Epoch 4440/5000\n",
      "134/134 [==============================] - 0s 376us/step - loss: 130521.6510 - val_loss: 148501.4380\n",
      "Epoch 4441/5000\n",
      "134/134 [==============================] - 0s 362us/step - loss: 145426.1934 - val_loss: 145923.3717\n",
      "Epoch 4442/5000\n",
      "134/134 [==============================] - 0s 396us/step - loss: 157639.6433 - val_loss: 183098.5775\n",
      "Epoch 4443/5000\n",
      "134/134 [==============================] - 0s 390us/step - loss: 147153.8561 - val_loss: 147905.5711\n",
      "Epoch 4444/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 136439.9174 - val_loss: 141666.7029\n",
      "Epoch 4445/5000\n",
      "134/134 [==============================] - 0s 331us/step - loss: 113478.4443 - val_loss: 128460.1439\n",
      "Epoch 4446/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 138724.5950 - val_loss: 129215.8598\n",
      "Epoch 4447/5000\n",
      "134/134 [==============================] - 0s 349us/step - loss: 169449.2404 - val_loss: 196436.8377\n",
      "Epoch 4448/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 165501.2653 - val_loss: 138858.5159\n",
      "Epoch 4449/5000\n",
      "134/134 [==============================] - 0s 353us/step - loss: 153084.7354 - val_loss: 136573.5443\n",
      "Epoch 4450/5000\n",
      "134/134 [==============================] - 0s 447us/step - loss: 139165.5765 - val_loss: 359902.2234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4451/5000\n",
      "134/134 [==============================] - 0s 426us/step - loss: 247234.8204 - val_loss: 175053.6769\n",
      "Epoch 4452/5000\n",
      "134/134 [==============================] - 0s 616us/step - loss: 256705.7020 - val_loss: 185462.5443\n",
      "Epoch 4453/5000\n",
      "134/134 [==============================] - 0s 360us/step - loss: 144043.8884 - val_loss: 135260.1911\n",
      "Epoch 4454/5000\n",
      "134/134 [==============================] - 0s 383us/step - loss: 141458.7872 - val_loss: 128101.2880\n",
      "Epoch 4455/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 150439.8054 - val_loss: 220494.2416\n",
      "Epoch 4456/5000\n",
      "134/134 [==============================] - 0s 356us/step - loss: 176854.2768 - val_loss: 173987.8368\n",
      "Epoch 4457/5000\n",
      "134/134 [==============================] - 0s 425us/step - loss: 135165.7049 - val_loss: 127331.5345\n",
      "Epoch 4458/5000\n",
      "134/134 [==============================] - 0s 356us/step - loss: 125065.1971 - val_loss: 137538.8784\n",
      "Epoch 4459/5000\n",
      "134/134 [==============================] - 0s 329us/step - loss: 190994.9418 - val_loss: 338915.6565\n",
      "Epoch 4460/5000\n",
      "134/134 [==============================] - 0s 357us/step - loss: 263187.6235 - val_loss: 267370.5714\n",
      "Epoch 4461/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 157723.0652 - val_loss: 120238.4077\n",
      "Epoch 4462/5000\n",
      "134/134 [==============================] - 0s 372us/step - loss: 125700.3014 - val_loss: 143720.3361\n",
      "Epoch 4463/5000\n",
      "134/134 [==============================] - 0s 381us/step - loss: 156771.5091 - val_loss: 137794.7404\n",
      "Epoch 4464/5000\n",
      "134/134 [==============================] - 0s 423us/step - loss: 149036.7465 - val_loss: 128795.6228\n",
      "Epoch 4465/5000\n",
      "134/134 [==============================] - 0s 366us/step - loss: 204865.5971 - val_loss: 265803.6395\n",
      "Epoch 4466/5000\n",
      "134/134 [==============================] - 0s 447us/step - loss: 206294.9065 - val_loss: 250819.3584\n",
      "Epoch 4467/5000\n",
      "134/134 [==============================] - 0s 486us/step - loss: 167524.3859 - val_loss: 116318.3438\n",
      "Epoch 4468/5000\n",
      "134/134 [==============================] - 0s 504us/step - loss: 138230.1389 - val_loss: 128638.0809\n",
      "Epoch 4469/5000\n",
      "134/134 [==============================] - 0s 427us/step - loss: 119267.8232 - val_loss: 107919.0471\n",
      "Epoch 4470/5000\n",
      "134/134 [==============================] - 0s 401us/step - loss: 109129.0694 - val_loss: 108851.1154\n",
      "Epoch 4471/5000\n",
      "134/134 [==============================] - 0s 381us/step - loss: 107977.2541 - val_loss: 128294.0068\n",
      "Epoch 4472/5000\n",
      "134/134 [==============================] - 0s 381us/step - loss: 129682.2697 - val_loss: 159951.8218\n",
      "Epoch 4473/5000\n",
      "134/134 [==============================] - 0s 409us/step - loss: 138900.7058 - val_loss: 107516.9830\n",
      "Epoch 4474/5000\n",
      "134/134 [==============================] - 0s 363us/step - loss: 111979.5273 - val_loss: 103356.5114\n",
      "Epoch 4475/5000\n",
      "134/134 [==============================] - 0s 488us/step - loss: 106497.0932 - val_loss: 120994.8357\n",
      "Epoch 4476/5000\n",
      "134/134 [==============================] - 0s 481us/step - loss: 137510.4040 - val_loss: 163088.3074\n",
      "Epoch 4477/5000\n",
      "134/134 [==============================] - 0s 441us/step - loss: 237296.6382 - val_loss: 161543.9071\n",
      "Epoch 4478/5000\n",
      "134/134 [==============================] - 0s 452us/step - loss: 202360.0543 - val_loss: 273696.6936\n",
      "Epoch 4479/5000\n",
      "134/134 [==============================] - 0s 468us/step - loss: 196459.2592 - val_loss: 412897.3358\n",
      "Epoch 4480/5000\n",
      "134/134 [==============================] - 0s 422us/step - loss: 206945.6718 - val_loss: 154628.1282\n",
      "Epoch 4481/5000\n",
      "134/134 [==============================] - 0s 426us/step - loss: 171176.0429 - val_loss: 139307.8277\n",
      "Epoch 4482/5000\n",
      "134/134 [==============================] - 0s 390us/step - loss: 115945.7636 - val_loss: 168308.6987\n",
      "Epoch 4483/5000\n",
      "134/134 [==============================] - 0s 389us/step - loss: 160065.4170 - val_loss: 119053.6933\n",
      "Epoch 4484/5000\n",
      "134/134 [==============================] - 0s 472us/step - loss: 118492.9769 - val_loss: 276444.6744\n",
      "Epoch 4485/5000\n",
      "134/134 [==============================] - 0s 575us/step - loss: 154117.8007 - val_loss: 116509.4754\n",
      "Epoch 4486/5000\n",
      "134/134 [==============================] - 0s 494us/step - loss: 120838.0057 - val_loss: 120970.6418\n",
      "Epoch 4487/5000\n",
      "134/134 [==============================] - 0s 564us/step - loss: 145392.0725 - val_loss: 277781.2917\n",
      "Epoch 4488/5000\n",
      "134/134 [==============================] - 0s 456us/step - loss: 244013.6447 - val_loss: 503501.3330\n",
      "Epoch 4489/5000\n",
      "134/134 [==============================] - 0s 459us/step - loss: 356375.1738 - val_loss: 121140.2348\n",
      "Epoch 4490/5000\n",
      "134/134 [==============================] - 0s 436us/step - loss: 134224.7917 - val_loss: 115348.5789\n",
      "Epoch 4491/5000\n",
      "134/134 [==============================] - 0s 441us/step - loss: 118539.4602 - val_loss: 161343.2532\n",
      "Epoch 4492/5000\n",
      "134/134 [==============================] - 0s 454us/step - loss: 155804.9848 - val_loss: 123370.9873\n",
      "Epoch 4493/5000\n",
      "134/134 [==============================] - 0s 374us/step - loss: 112605.6493 - val_loss: 111696.5455\n",
      "Epoch 4494/5000\n",
      "134/134 [==============================] - 0s 351us/step - loss: 129600.9928 - val_loss: 110715.2929\n",
      "Epoch 4495/5000\n",
      "134/134 [==============================] - 0s 353us/step - loss: 112839.6607 - val_loss: 103067.9689\n",
      "Epoch 4496/5000\n",
      "134/134 [==============================] - 0s 348us/step - loss: 112449.8089 - val_loss: 103816.6530\n",
      "Epoch 4497/5000\n",
      "134/134 [==============================] - 0s 376us/step - loss: 107947.7853 - val_loss: 103618.8553\n",
      "Epoch 4498/5000\n",
      "134/134 [==============================] - 0s 460us/step - loss: 108042.0357 - val_loss: 112512.3884\n",
      "Epoch 4499/5000\n",
      "134/134 [==============================] - 0s 305us/step - loss: 128521.3783 - val_loss: 118118.5758\n",
      "Epoch 4500/5000\n",
      "134/134 [==============================] - 0s 376us/step - loss: 148353.8187 - val_loss: 134825.9797\n",
      "Epoch 4501/5000\n",
      "134/134 [==============================] - 0s 308us/step - loss: 162107.7767 - val_loss: 130764.3039\n",
      "Epoch 4502/5000\n",
      "134/134 [==============================] - 0s 342us/step - loss: 114791.5732 - val_loss: 116137.1052\n",
      "Epoch 4503/5000\n",
      "134/134 [==============================] - 0s 376us/step - loss: 146396.4818 - val_loss: 159388.5299\n",
      "Epoch 4504/5000\n",
      "134/134 [==============================] - 0s 434us/step - loss: 194287.8671 - val_loss: 443766.8433\n",
      "Epoch 4505/5000\n",
      "134/134 [==============================] - 0s 488us/step - loss: 224906.5624 - val_loss: 130780.6714\n",
      "Epoch 4506/5000\n",
      "134/134 [==============================] - ETA: 0s - loss: 167778.87 - 0s 477us/step - loss: 128129.7743 - val_loss: 171866.6656\n",
      "Epoch 4507/5000\n",
      "134/134 [==============================] - 0s 407us/step - loss: 166441.1364 - val_loss: 211102.7481\n",
      "Epoch 4508/5000\n",
      "134/134 [==============================] - 0s 398us/step - loss: 177592.2020 - val_loss: 255837.9732\n",
      "Epoch 4509/5000\n",
      "134/134 [==============================] - 0s 427us/step - loss: 242993.6713 - val_loss: 172264.3556\n",
      "Epoch 4510/5000\n",
      "134/134 [==============================] - 0s 418us/step - loss: 161355.6769 - val_loss: 126300.2383\n",
      "Epoch 4511/5000\n",
      "134/134 [==============================] - 0s 451us/step - loss: 130111.4080 - val_loss: 208420.2556\n",
      "Epoch 4512/5000\n",
      "134/134 [==============================] - 0s 392us/step - loss: 264592.2169 - val_loss: 143657.9979\n",
      "Epoch 4513/5000\n",
      "134/134 [==============================] - 0s 390us/step - loss: 199919.1629 - val_loss: 199403.4256\n",
      "Epoch 4514/5000\n",
      "134/134 [==============================] - 0s 413us/step - loss: 164859.8085 - val_loss: 490436.2057\n",
      "Epoch 4515/5000\n",
      "134/134 [==============================] - 0s 360us/step - loss: 325144.1762 - val_loss: 138556.1390\n",
      "Epoch 4516/5000\n",
      "134/134 [==============================] - 0s 366us/step - loss: 138780.4859 - val_loss: 121425.8734\n",
      "Epoch 4517/5000\n",
      "134/134 [==============================] - 0s 439us/step - loss: 114263.0660 - val_loss: 109450.6256\n",
      "Epoch 4518/5000\n",
      "134/134 [==============================] - 0s 387us/step - loss: 112134.1117 - val_loss: 138435.2024\n",
      "Epoch 4519/5000\n",
      "134/134 [==============================] - 0s 397us/step - loss: 110267.3135 - val_loss: 101595.6700\n",
      "Epoch 4520/5000\n",
      "134/134 [==============================] - 0s 358us/step - loss: 104036.2428 - val_loss: 103249.7955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4521/5000\n",
      "134/134 [==============================] - 0s 411us/step - loss: 109523.0413 - val_loss: 119030.4855\n",
      "Epoch 4522/5000\n",
      "134/134 [==============================] - 0s 430us/step - loss: 114441.3947 - val_loss: 174250.8904\n",
      "Epoch 4523/5000\n",
      "134/134 [==============================] - 0s 410us/step - loss: 190090.1091 - val_loss: 404202.1189\n",
      "Epoch 4524/5000\n",
      "134/134 [==============================] - 0s 402us/step - loss: 312232.2192 - val_loss: 115601.3116\n",
      "Epoch 4525/5000\n",
      "134/134 [==============================] - 0s 420us/step - loss: 114585.4535 - val_loss: 111170.4767\n",
      "Epoch 4526/5000\n",
      "134/134 [==============================] - 0s 421us/step - loss: 109307.6802 - val_loss: 126821.3151\n",
      "Epoch 4527/5000\n",
      "134/134 [==============================] - 0s 408us/step - loss: 122177.5396 - val_loss: 138808.4015\n",
      "Epoch 4528/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 121424.0648 - val_loss: 129098.5802\n",
      "Epoch 4529/5000\n",
      "134/134 [==============================] - 0s 380us/step - loss: 110800.2373 - val_loss: 213846.7223\n",
      "Epoch 4530/5000\n",
      "134/134 [==============================] - 0s 355us/step - loss: 155423.6719 - val_loss: 104951.1861\n",
      "Epoch 4531/5000\n",
      "134/134 [==============================] - 0s 362us/step - loss: 111141.3046 - val_loss: 114586.4521\n",
      "Epoch 4532/5000\n",
      "134/134 [==============================] - 0s 376us/step - loss: 136533.3338 - val_loss: 177510.4578\n",
      "Epoch 4533/5000\n",
      "134/134 [==============================] - 0s 405us/step - loss: 176958.8895 - val_loss: 156318.2561\n",
      "Epoch 4534/5000\n",
      "134/134 [==============================] - 0s 543us/step - loss: 211203.3598 - val_loss: 158051.8843\n",
      "Epoch 4535/5000\n",
      "134/134 [==============================] - 0s 436us/step - loss: 201927.6231 - val_loss: 280341.6390\n",
      "Epoch 4536/5000\n",
      "134/134 [==============================] - 0s 426us/step - loss: 227784.8132 - val_loss: 131171.0725\n",
      "Epoch 4537/5000\n",
      "134/134 [==============================] - 0s 374us/step - loss: 129856.4411 - val_loss: 224360.7257\n",
      "Epoch 4538/5000\n",
      "134/134 [==============================] - 0s 370us/step - loss: 124221.2381 - val_loss: 119333.2590\n",
      "Epoch 4539/5000\n",
      "134/134 [==============================] - 0s 336us/step - loss: 118319.3692 - val_loss: 296120.1982\n",
      "Epoch 4540/5000\n",
      "134/134 [==============================] - 0s 347us/step - loss: 162177.5107 - val_loss: 128594.1714\n",
      "Epoch 4541/5000\n",
      "134/134 [==============================] - 0s 345us/step - loss: 136672.3366 - val_loss: 118828.2948\n",
      "Epoch 4542/5000\n",
      "134/134 [==============================] - 0s 338us/step - loss: 124918.0022 - val_loss: 634071.0625\n",
      "Epoch 4543/5000\n",
      "134/134 [==============================] - 0s 387us/step - loss: 191557.3336 - val_loss: 150036.7971\n",
      "Epoch 4544/5000\n",
      "134/134 [==============================] - 0s 372us/step - loss: 167956.8038 - val_loss: 304904.3923\n",
      "Epoch 4545/5000\n",
      "134/134 [==============================] - 0s 293us/step - loss: 169136.9765 - val_loss: 374846.6679\n",
      "Epoch 4546/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 172061.5957 - val_loss: 116690.1214\n",
      "Epoch 4547/5000\n",
      "134/134 [==============================] - 0s 348us/step - loss: 136856.5184 - val_loss: 116321.9324\n",
      "Epoch 4548/5000\n",
      "134/134 [==============================] - 0s 346us/step - loss: 120007.4837 - val_loss: 130917.0105\n",
      "Epoch 4549/5000\n",
      "134/134 [==============================] - 0s 338us/step - loss: 128555.8201 - val_loss: 105701.3661\n",
      "Epoch 4550/5000\n",
      "134/134 [==============================] - 0s 362us/step - loss: 127053.9936 - val_loss: 272205.7617\n",
      "Epoch 4551/5000\n",
      "134/134 [==============================] - 0s 378us/step - loss: 163236.8190 - val_loss: 184196.5099\n",
      "Epoch 4552/5000\n",
      "134/134 [==============================] - 0s 381us/step - loss: 152887.6219 - val_loss: 274991.9506\n",
      "Epoch 4553/5000\n",
      "134/134 [==============================] - 0s 368us/step - loss: 172509.6760 - val_loss: 203959.8666\n",
      "Epoch 4554/5000\n",
      "134/134 [==============================] - 0s 342us/step - loss: 142453.0476 - val_loss: 227157.6688\n",
      "Epoch 4555/5000\n",
      "134/134 [==============================] - 0s 368us/step - loss: 200944.0931 - val_loss: 116626.2878\n",
      "Epoch 4556/5000\n",
      "134/134 [==============================] - 0s 526us/step - loss: 137676.4007 - val_loss: 158463.0110\n",
      "Epoch 4557/5000\n",
      "134/134 [==============================] - 0s 485us/step - loss: 147803.1371 - val_loss: 139659.8347\n",
      "Epoch 4558/5000\n",
      "134/134 [==============================] - 0s 356us/step - loss: 145781.0365 - val_loss: 141552.0006\n",
      "Epoch 4559/5000\n",
      "134/134 [==============================] - 0s 479us/step - loss: 124114.7081 - val_loss: 109177.6171\n",
      "Epoch 4560/5000\n",
      "134/134 [==============================] - 0s 429us/step - loss: 122199.1904 - val_loss: 208415.1777\n",
      "Epoch 4561/5000\n",
      "134/134 [==============================] - 0s 413us/step - loss: 123817.7944 - val_loss: 105299.6959\n",
      "Epoch 4562/5000\n",
      "134/134 [==============================] - 0s 396us/step - loss: 106950.2462 - val_loss: 98798.2365\n",
      "Epoch 4563/5000\n",
      "134/134 [==============================] - 0s 450us/step - loss: 110748.2423 - val_loss: 261173.4748\n",
      "Epoch 4564/5000\n",
      "134/134 [==============================] - 0s 460us/step - loss: 209704.3703 - val_loss: 150218.5247\n",
      "Epoch 4565/5000\n",
      "134/134 [==============================] - 0s 362us/step - loss: 199820.3209 - val_loss: 235432.5882\n",
      "Epoch 4566/5000\n",
      "134/134 [==============================] - 0s 381us/step - loss: 210626.6322 - val_loss: 176484.3426\n",
      "Epoch 4567/5000\n",
      "134/134 [==============================] - 0s 364us/step - loss: 206211.2998 - val_loss: 139949.0548\n",
      "Epoch 4568/5000\n",
      "134/134 [==============================] - 0s 420us/step - loss: 126059.0900 - val_loss: 153770.3377\n",
      "Epoch 4569/5000\n",
      "134/134 [==============================] - 0s 951us/step - loss: 137850.3389 - val_loss: 164900.3871\n",
      "Epoch 4570/5000\n",
      "134/134 [==============================] - 0s 608us/step - loss: 164333.9995 - val_loss: 194214.2275\n",
      "Epoch 4571/5000\n",
      "134/134 [==============================] - 0s 634us/step - loss: 264656.8092 - val_loss: 260086.8102\n",
      "Epoch 4572/5000\n",
      "134/134 [==============================] - 0s 538us/step - loss: 233190.3518 - val_loss: 160140.3440\n",
      "Epoch 4573/5000\n",
      "134/134 [==============================] - 0s 402us/step - loss: 147120.9240 - val_loss: 133553.7344\n",
      "Epoch 4574/5000\n",
      "134/134 [==============================] - 0s 425us/step - loss: 158867.5071 - val_loss: 161966.9130\n",
      "Epoch 4575/5000\n",
      "134/134 [==============================] - 0s 417us/step - loss: 126042.2820 - val_loss: 121586.9515\n",
      "Epoch 4576/5000\n",
      "134/134 [==============================] - 0s 338us/step - loss: 135896.1960 - val_loss: 305833.4550\n",
      "Epoch 4577/5000\n",
      "134/134 [==============================] - 0s 333us/step - loss: 247045.8730 - val_loss: 144239.9473\n",
      "Epoch 4578/5000\n",
      "134/134 [==============================] - 0s 362us/step - loss: 199617.7548 - val_loss: 149396.3223\n",
      "Epoch 4579/5000\n",
      "134/134 [==============================] - 0s 342us/step - loss: 172639.3776 - val_loss: 127884.7943\n",
      "Epoch 4580/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 225915.5695 - val_loss: 988295.3573\n",
      "Epoch 4581/5000\n",
      "134/134 [==============================] - 0s 336us/step - loss: 560453.9601 - val_loss: 135217.1097\n",
      "Epoch 4582/5000\n",
      "134/134 [==============================] - 0s 350us/step - loss: 134926.4370 - val_loss: 107986.0513\n",
      "Epoch 4583/5000\n",
      "134/134 [==============================] - 0s 359us/step - loss: 108285.6716 - val_loss: 102125.8396\n",
      "Epoch 4584/5000\n",
      "134/134 [==============================] - 0s 360us/step - loss: 105355.3258 - val_loss: 138463.8410\n",
      "Epoch 4585/5000\n",
      "134/134 [==============================] - 0s 297us/step - loss: 113303.1230 - val_loss: 101669.6432\n",
      "Epoch 4586/5000\n",
      "134/134 [==============================] - 0s 364us/step - loss: 103012.2764 - val_loss: 102157.5461\n",
      "Epoch 4587/5000\n",
      "134/134 [==============================] - 0s 387us/step - loss: 100482.4721 - val_loss: 98368.9699\n",
      "Epoch 4588/5000\n",
      "134/134 [==============================] - 0s 360us/step - loss: 101926.9241 - val_loss: 108106.3761\n",
      "Epoch 4589/5000\n",
      "134/134 [==============================] - 0s 358us/step - loss: 112470.4962 - val_loss: 135023.7435\n",
      "Epoch 4590/5000\n",
      "134/134 [==============================] - 0s 373us/step - loss: 146280.8866 - val_loss: 112771.1872\n",
      "Epoch 4591/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 372us/step - loss: 128939.6784 - val_loss: 113521.3531\n",
      "Epoch 4592/5000\n",
      "134/134 [==============================] - 0s 317us/step - loss: 130938.3000 - val_loss: 370209.7183\n",
      "Epoch 4593/5000\n",
      "134/134 [==============================] - 0s 412us/step - loss: 156802.5775 - val_loss: 117328.3576\n",
      "Epoch 4594/5000\n",
      "134/134 [==============================] - 0s 342us/step - loss: 126175.5921 - val_loss: 112709.8329\n",
      "Epoch 4595/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 116779.8752 - val_loss: 135955.9117\n",
      "Epoch 4596/5000\n",
      "134/134 [==============================] - 0s 382us/step - loss: 147239.2255 - val_loss: 218727.3769\n",
      "Epoch 4597/5000\n",
      "134/134 [==============================] - 0s 366us/step - loss: 206016.3309 - val_loss: 117541.9552\n",
      "Epoch 4598/5000\n",
      "134/134 [==============================] - 0s 336us/step - loss: 154700.4636 - val_loss: 207296.5308\n",
      "Epoch 4599/5000\n",
      "134/134 [==============================] - 0s 398us/step - loss: 134796.6698 - val_loss: 141236.4571\n",
      "Epoch 4600/5000\n",
      "134/134 [==============================] - 0s 321us/step - loss: 154578.7488 - val_loss: 305973.8927\n",
      "Epoch 4601/5000\n",
      "134/134 [==============================] - 0s 379us/step - loss: 153495.0954 - val_loss: 112738.4219\n",
      "Epoch 4602/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 152980.4467 - val_loss: 147186.4681\n",
      "Epoch 4603/5000\n",
      "134/134 [==============================] - 0s 377us/step - loss: 134683.6373 - val_loss: 197103.5546\n",
      "Epoch 4604/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 163625.3521 - val_loss: 118831.8299\n",
      "Epoch 4605/5000\n",
      "134/134 [==============================] - 0s 389us/step - loss: 122285.9959 - val_loss: 152670.6847\n",
      "Epoch 4606/5000\n",
      "134/134 [==============================] - 0s 348us/step - loss: 162277.5918 - val_loss: 100852.4984\n",
      "Epoch 4607/5000\n",
      "134/134 [==============================] - 0s 338us/step - loss: 107442.0393 - val_loss: 142171.0534\n",
      "Epoch 4608/5000\n",
      "134/134 [==============================] - 0s 383us/step - loss: 122994.8057 - val_loss: 220277.0373\n",
      "Epoch 4609/5000\n",
      "134/134 [==============================] - 0s 332us/step - loss: 161917.9627 - val_loss: 217380.6377\n",
      "Epoch 4610/5000\n",
      "134/134 [==============================] - 0s 366us/step - loss: 377071.7327 - val_loss: 154921.3161\n",
      "Epoch 4611/5000\n",
      "134/134 [==============================] - 0s 333us/step - loss: 157207.2280 - val_loss: 125730.7579\n",
      "Epoch 4612/5000\n",
      "134/134 [==============================] - 0s 383us/step - loss: 123225.4840 - val_loss: 102332.9667\n",
      "Epoch 4613/5000\n",
      "134/134 [==============================] - 0s 355us/step - loss: 109338.3180 - val_loss: 109565.7317\n",
      "Epoch 4614/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 103322.0494 - val_loss: 117916.3193\n",
      "Epoch 4615/5000\n",
      "134/134 [==============================] - 0s 405us/step - loss: 109672.9469 - val_loss: 107412.6810\n",
      "Epoch 4616/5000\n",
      "134/134 [==============================] - 0s 361us/step - loss: 107329.3309 - val_loss: 138815.7903\n",
      "Epoch 4617/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 116385.6325 - val_loss: 111631.4157\n",
      "Epoch 4618/5000\n",
      "134/134 [==============================] - 0s 388us/step - loss: 120995.6680 - val_loss: 168568.7689\n",
      "Epoch 4619/5000\n",
      "134/134 [==============================] - 0s 332us/step - loss: 133616.3568 - val_loss: 111277.5449\n",
      "Epoch 4620/5000\n",
      "134/134 [==============================] - ETA: 0s - loss: 41996.578 - 0s 384us/step - loss: 120851.3429 - val_loss: 372121.4888\n",
      "Epoch 4621/5000\n",
      "134/134 [==============================] - 0s 398us/step - loss: 230799.8173 - val_loss: 192520.4419\n",
      "Epoch 4622/5000\n",
      "134/134 [==============================] - 0s 369us/step - loss: 141531.4790 - val_loss: 124096.1413\n",
      "Epoch 4623/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 138753.6301 - val_loss: 149941.7547\n",
      "Epoch 4624/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 152852.5509 - val_loss: 149259.5744\n",
      "Epoch 4625/5000\n",
      "134/134 [==============================] - 0s 344us/step - loss: 144434.1365 - val_loss: 118488.7794\n",
      "Epoch 4626/5000\n",
      "134/134 [==============================] - 0s 338us/step - loss: 123469.0482 - val_loss: 120556.6526\n",
      "Epoch 4627/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 124141.6606 - val_loss: 107163.1469\n",
      "Epoch 4628/5000\n",
      "134/134 [==============================] - 0s 317us/step - loss: 122698.9738 - val_loss: 199791.5107\n",
      "Epoch 4629/5000\n",
      "134/134 [==============================] - 0s 325us/step - loss: 148544.7719 - val_loss: 175977.2141\n",
      "Epoch 4630/5000\n",
      "134/134 [==============================] - 0s 342us/step - loss: 224717.2339 - val_loss: 148717.2003\n",
      "Epoch 4631/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 155153.7861 - val_loss: 513069.3246\n",
      "Epoch 4632/5000\n",
      "134/134 [==============================] - 0s 332us/step - loss: 284467.1504 - val_loss: 246907.4123\n",
      "Epoch 4633/5000\n",
      "134/134 [==============================] - 0s 319us/step - loss: 176519.7895 - val_loss: 212059.3797\n",
      "Epoch 4634/5000\n",
      "134/134 [==============================] - 0s 346us/step - loss: 171838.8620 - val_loss: 142263.6123\n",
      "Epoch 4635/5000\n",
      "134/134 [==============================] - 0s 337us/step - loss: 153020.4189 - val_loss: 131929.8165\n",
      "Epoch 4636/5000\n",
      "134/134 [==============================] - 0s 339us/step - loss: 130285.0130 - val_loss: 126420.5140\n",
      "Epoch 4637/5000\n",
      "134/134 [==============================] - 0s 349us/step - loss: 138940.2370 - val_loss: 106221.2168\n",
      "Epoch 4638/5000\n",
      "134/134 [==============================] - 0s 341us/step - loss: 113266.3106 - val_loss: 123671.2495\n",
      "Epoch 4639/5000\n",
      "134/134 [==============================] - 0s 361us/step - loss: 138309.2725 - val_loss: 128919.6415\n",
      "Epoch 4640/5000\n",
      "134/134 [==============================] - ETA: 0s - loss: 124949.54 - 0s 359us/step - loss: 117195.4932 - val_loss: 238731.6726\n",
      "Epoch 4641/5000\n",
      "134/134 [==============================] - 0s 333us/step - loss: 240095.0196 - val_loss: 109360.6293\n",
      "Epoch 4642/5000\n",
      "134/134 [==============================] - 0s 397us/step - loss: 134605.2888 - val_loss: 163593.9146\n",
      "Epoch 4643/5000\n",
      "134/134 [==============================] - 0s 356us/step - loss: 142592.2782 - val_loss: 143989.2960\n",
      "Epoch 4644/5000\n",
      "134/134 [==============================] - 0s 362us/step - loss: 128467.6447 - val_loss: 119830.0211\n",
      "Epoch 4645/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 137501.7488 - val_loss: 532808.6147\n",
      "Epoch 4646/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 332278.6259 - val_loss: 134891.4855\n",
      "Epoch 4647/5000\n",
      "134/134 [==============================] - 0s 379us/step - loss: 133567.4448 - val_loss: 104540.9263\n",
      "Epoch 4648/5000\n",
      "134/134 [==============================] - 0s 370us/step - loss: 103980.1218 - val_loss: 102090.8158\n",
      "Epoch 4649/5000\n",
      "134/134 [==============================] - 0s 345us/step - loss: 100769.3065 - val_loss: 96906.4641\n",
      "Epoch 4650/5000\n",
      "134/134 [==============================] - 0s 406us/step - loss: 104544.9922 - val_loss: 116510.5182\n",
      "Epoch 4651/5000\n",
      "134/134 [==============================] - 0s 343us/step - loss: 109358.7004 - val_loss: 105206.2540\n",
      "Epoch 4652/5000\n",
      "134/134 [==============================] - 0s 347us/step - loss: 114929.5829 - val_loss: 132424.5524\n",
      "Epoch 4653/5000\n",
      "134/134 [==============================] - 0s 372us/step - loss: 122233.5694 - val_loss: 102380.0338\n",
      "Epoch 4654/5000\n",
      "134/134 [==============================] - 0s 367us/step - loss: 106354.9448 - val_loss: 143295.9583\n",
      "Epoch 4655/5000\n",
      "134/134 [==============================] - 0s 363us/step - loss: 198578.4012 - val_loss: 208959.1863\n",
      "Epoch 4656/5000\n",
      "134/134 [==============================] - 0s 360us/step - loss: 187145.5512 - val_loss: 130062.3400\n",
      "Epoch 4657/5000\n",
      "134/134 [==============================] - 0s 333us/step - loss: 121252.4679 - val_loss: 130183.1201\n",
      "Epoch 4658/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 145005.0476 - val_loss: 135502.5020\n",
      "Epoch 4659/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 125414.8557 - val_loss: 382712.2271\n",
      "Epoch 4660/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 316us/step - loss: 159998.1592 - val_loss: 152563.2642\n",
      "Epoch 4661/5000\n",
      "134/134 [==============================] - 0s 321us/step - loss: 151897.3920 - val_loss: 145605.6835\n",
      "Epoch 4662/5000\n",
      "134/134 [==============================] - 0s 389us/step - loss: 148388.2469 - val_loss: 136423.9678\n",
      "Epoch 4663/5000\n",
      "134/134 [==============================] - 0s 412us/step - loss: 122309.5919 - val_loss: 102366.6286\n",
      "Epoch 4664/5000\n",
      "134/134 [==============================] - 0s 348us/step - loss: 109873.8416 - val_loss: 121216.9370\n",
      "Epoch 4665/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 117684.8082 - val_loss: 158464.6733\n",
      "Epoch 4666/5000\n",
      "134/134 [==============================] - 0s 372us/step - loss: 113844.1768 - val_loss: 523893.3153\n",
      "Epoch 4667/5000\n",
      "134/134 [==============================] - 0s 378us/step - loss: 154308.3253 - val_loss: 162184.3842\n",
      "Epoch 4668/5000\n",
      "134/134 [==============================] - 0s 371us/step - loss: 160026.8176 - val_loss: 245198.3480\n",
      "Epoch 4669/5000\n",
      "134/134 [==============================] - 0s 345us/step - loss: 137532.4892 - val_loss: 120405.3757\n",
      "Epoch 4670/5000\n",
      "134/134 [==============================] - 0s 307us/step - loss: 118940.6847 - val_loss: 114876.8783\n",
      "Epoch 4671/5000\n",
      "134/134 [==============================] - 0s 372us/step - loss: 125220.2920 - val_loss: 163068.9363\n",
      "Epoch 4672/5000\n",
      "134/134 [==============================] - 0s 290us/step - loss: 138058.0727 - val_loss: 256647.8897\n",
      "Epoch 4673/5000\n",
      "134/134 [==============================] - 0s 355us/step - loss: 185298.1295 - val_loss: 240565.0746\n",
      "Epoch 4674/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 199358.8434 - val_loss: 314738.9370\n",
      "Epoch 4675/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 250503.4279 - val_loss: 155735.3001\n",
      "Epoch 4676/5000\n",
      "134/134 [==============================] - 0s 329us/step - loss: 184210.8961 - val_loss: 129888.1663\n",
      "Epoch 4677/5000\n",
      "134/134 [==============================] - 0s 333us/step - loss: 116570.6196 - val_loss: 141756.2097\n",
      "Epoch 4678/5000\n",
      "134/134 [==============================] - 0s 318us/step - loss: 135514.6756 - val_loss: 108980.8041\n",
      "Epoch 4679/5000\n",
      "134/134 [==============================] - 0s 350us/step - loss: 117200.1584 - val_loss: 112726.9192\n",
      "Epoch 4680/5000\n",
      "134/134 [==============================] - 0s 342us/step - loss: 118208.9957 - val_loss: 122813.8593\n",
      "Epoch 4681/5000\n",
      "134/134 [==============================] - 0s 343us/step - loss: 120054.9853 - val_loss: 176268.0597\n",
      "Epoch 4682/5000\n",
      "134/134 [==============================] - 0s 292us/step - loss: 139021.2702 - val_loss: 105520.8563\n",
      "Epoch 4683/5000\n",
      "134/134 [==============================] - 0s 329us/step - loss: 102908.5756 - val_loss: 100570.5403\n",
      "Epoch 4684/5000\n",
      "134/134 [==============================] - 0s 331us/step - loss: 103293.8683 - val_loss: 101394.2212\n",
      "Epoch 4685/5000\n",
      "134/134 [==============================] - 0s 333us/step - loss: 115545.7193 - val_loss: 133772.3568\n",
      "Epoch 4686/5000\n",
      "134/134 [==============================] - 0s 344us/step - loss: 121196.4938 - val_loss: 105930.5780\n",
      "Epoch 4687/5000\n",
      "134/134 [==============================] - 0s 344us/step - loss: 130482.7785 - val_loss: 104455.1749\n",
      "Epoch 4688/5000\n",
      "134/134 [==============================] - 0s 376us/step - loss: 203861.2968 - val_loss: 269165.4002\n",
      "Epoch 4689/5000\n",
      "134/134 [==============================] - 0s 321us/step - loss: 249635.5421 - val_loss: 101512.9861\n",
      "Epoch 4690/5000\n",
      "134/134 [==============================] - 0s 352us/step - loss: 115436.7528 - val_loss: 160481.8428\n",
      "Epoch 4691/5000\n",
      "134/134 [==============================] - 0s 331us/step - loss: 141076.0464 - val_loss: 116707.6749\n",
      "Epoch 4692/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 140345.5544 - val_loss: 120613.8435\n",
      "Epoch 4693/5000\n",
      "134/134 [==============================] - 0s 302us/step - loss: 133505.7158 - val_loss: 99581.0672\n",
      "Epoch 4694/5000\n",
      "134/134 [==============================] - 0s 346us/step - loss: 132139.7947 - val_loss: 136368.5262\n",
      "Epoch 4695/5000\n",
      "134/134 [==============================] - 0s 320us/step - loss: 138979.9522 - val_loss: 135322.5835\n",
      "Epoch 4696/5000\n",
      "134/134 [==============================] - 0s 330us/step - loss: 178558.8212 - val_loss: 172901.6031\n",
      "Epoch 4697/5000\n",
      "134/134 [==============================] - 0s 330us/step - loss: 161030.3946 - val_loss: 550244.6693\n",
      "Epoch 4698/5000\n",
      "134/134 [==============================] - 0s 291us/step - loss: 395354.0054 - val_loss: 144771.4904\n",
      "Epoch 4699/5000\n",
      "134/134 [==============================] - 0s 324us/step - loss: 170774.4234 - val_loss: 111598.2023\n",
      "Epoch 4700/5000\n",
      "134/134 [==============================] - 0s 337us/step - loss: 109859.9928 - val_loss: 95756.2219\n",
      "Epoch 4701/5000\n",
      "134/134 [==============================] - 0s 276us/step - loss: 99390.3561 - val_loss: 117243.9235\n",
      "Epoch 4702/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 108136.9593 - val_loss: 94690.4559\n",
      "Epoch 4703/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 98971.6831 - val_loss: 95290.2202\n",
      "Epoch 4704/5000\n",
      "134/134 [==============================] - 0s 354us/step - loss: 100622.7499 - val_loss: 96677.1540\n",
      "Epoch 4705/5000\n",
      "134/134 [==============================] - 0s 347us/step - loss: 104878.4621 - val_loss: 206915.4483\n",
      "Epoch 4706/5000\n",
      "134/134 [==============================] - 0s 339us/step - loss: 143793.1307 - val_loss: 155606.2439\n",
      "Epoch 4707/5000\n",
      "134/134 [==============================] - 0s 346us/step - loss: 175299.2771 - val_loss: 113582.5501\n",
      "Epoch 4708/5000\n",
      "134/134 [==============================] - 0s 395us/step - loss: 157426.6086 - val_loss: 159829.1665\n",
      "Epoch 4709/5000\n",
      "134/134 [==============================] - 0s 398us/step - loss: 184315.3204 - val_loss: 225756.1264\n",
      "Epoch 4710/5000\n",
      "134/134 [==============================] - 0s 355us/step - loss: 241472.3373 - val_loss: 341815.1567\n",
      "Epoch 4711/5000\n",
      "134/134 [==============================] - 0s 354us/step - loss: 224708.0312 - val_loss: 258866.5105\n",
      "Epoch 4712/5000\n",
      "134/134 [==============================] - 0s 342us/step - loss: 153582.7299 - val_loss: 203648.3144\n",
      "Epoch 4713/5000\n",
      "134/134 [==============================] - 0s 342us/step - loss: 135033.2723 - val_loss: 162044.9226\n",
      "Epoch 4714/5000\n",
      "134/134 [==============================] - 0s 353us/step - loss: 116235.4997 - val_loss: 108643.5826\n",
      "Epoch 4715/5000\n",
      "134/134 [==============================] - 0s 315us/step - loss: 120889.9914 - val_loss: 109911.1458\n",
      "Epoch 4716/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 109797.0986 - val_loss: 125636.6824\n",
      "Epoch 4717/5000\n",
      "134/134 [==============================] - 0s 278us/step - loss: 131852.1031 - val_loss: 130653.7905\n",
      "Epoch 4718/5000\n",
      "134/134 [==============================] - 0s 334us/step - loss: 126153.3391 - val_loss: 292123.2263\n",
      "Epoch 4719/5000\n",
      "134/134 [==============================] - 0s 339us/step - loss: 190469.3747 - val_loss: 229787.0420\n",
      "Epoch 4720/5000\n",
      "134/134 [==============================] - 0s 287us/step - loss: 128585.3499 - val_loss: 236939.8645\n",
      "Epoch 4721/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 138797.4242 - val_loss: 140062.5919\n",
      "Epoch 4722/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 138799.3510 - val_loss: 118149.0826\n",
      "Epoch 4723/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 125385.6642 - val_loss: 98988.8141\n",
      "Epoch 4724/5000\n",
      "134/134 [==============================] - 0s 314us/step - loss: 104040.4224 - val_loss: 156541.2327\n",
      "Epoch 4725/5000\n",
      "134/134 [==============================] - 0s 309us/step - loss: 151193.5363 - val_loss: 105461.7847\n",
      "Epoch 4726/5000\n",
      "134/134 [==============================] - 0s 335us/step - loss: 108345.7634 - val_loss: 134623.4249\n",
      "Epoch 4727/5000\n",
      "134/134 [==============================] - 0s 323us/step - loss: 106267.1621 - val_loss: 111062.5917\n",
      "Epoch 4728/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 111752.4646 - val_loss: 107086.6124\n",
      "Epoch 4729/5000\n",
      "134/134 [==============================] - 0s 377us/step - loss: 138059.3349 - val_loss: 639204.6007\n",
      "Epoch 4730/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 349us/step - loss: 236670.7935 - val_loss: 118073.1751\n",
      "Epoch 4731/5000\n",
      "134/134 [==============================] - 0s 355us/step - loss: 121307.0099 - val_loss: 122035.4223\n",
      "Epoch 4732/5000\n",
      "134/134 [==============================] - 0s 395us/step - loss: 200199.3282 - val_loss: 218332.9212\n",
      "Epoch 4733/5000\n",
      "134/134 [==============================] - 0s 393us/step - loss: 169669.2646 - val_loss: 113200.0605\n",
      "Epoch 4734/5000\n",
      "134/134 [==============================] - 0s 361us/step - loss: 111093.1323 - val_loss: 108440.0508\n",
      "Epoch 4735/5000\n",
      "134/134 [==============================] - 0s 387us/step - loss: 103824.1619 - val_loss: 106777.5130\n",
      "Epoch 4736/5000\n",
      "134/134 [==============================] - 0s 335us/step - loss: 134215.2414 - val_loss: 142181.5665\n",
      "Epoch 4737/5000\n",
      "134/134 [==============================] - 0s 378us/step - loss: 116994.5602 - val_loss: 146581.1931\n",
      "Epoch 4738/5000\n",
      "134/134 [==============================] - 0s 327us/step - loss: 144641.0580 - val_loss: 140918.6676\n",
      "Epoch 4739/5000\n",
      "134/134 [==============================] - 0s 353us/step - loss: 134089.4815 - val_loss: 110412.8436\n",
      "Epoch 4740/5000\n",
      "134/134 [==============================] - 0s 362us/step - loss: 132238.3259 - val_loss: 115092.1667\n",
      "Epoch 4741/5000\n",
      "134/134 [==============================] - 0s 406us/step - loss: 164373.5792 - val_loss: 312437.6287\n",
      "Epoch 4742/5000\n",
      "134/134 [==============================] - 0s 324us/step - loss: 222937.3972 - val_loss: 144718.7498\n",
      "Epoch 4743/5000\n",
      "134/134 [==============================] - 0s 359us/step - loss: 150470.4670 - val_loss: 242278.5550\n",
      "Epoch 4744/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 140730.2519 - val_loss: 99553.9811\n",
      "Epoch 4745/5000\n",
      "134/134 [==============================] - 0s 442us/step - loss: 104956.9762 - val_loss: 102172.0281\n",
      "Epoch 4746/5000\n",
      "134/134 [==============================] - 0s 342us/step - loss: 114518.1547 - val_loss: 113077.3211\n",
      "Epoch 4747/5000\n",
      "134/134 [==============================] - 0s 315us/step - loss: 136045.9053 - val_loss: 233059.9785\n",
      "Epoch 4748/5000\n",
      "134/134 [==============================] - 0s 358us/step - loss: 132397.5070 - val_loss: 157861.3328\n",
      "Epoch 4749/5000\n",
      "134/134 [==============================] - 0s 358us/step - loss: 255116.1695 - val_loss: 130425.6091\n",
      "Epoch 4750/5000\n",
      "134/134 [==============================] - 0s 379us/step - loss: 159356.1264 - val_loss: 218071.6042\n",
      "Epoch 4751/5000\n",
      "134/134 [==============================] - 0s 410us/step - loss: 209426.0739 - val_loss: 196563.4424\n",
      "Epoch 4752/5000\n",
      "134/134 [==============================] - 0s 358us/step - loss: 154158.3853 - val_loss: 128678.0408\n",
      "Epoch 4753/5000\n",
      "134/134 [==============================] - 0s 401us/step - loss: 204951.2511 - val_loss: 645036.2099\n",
      "Epoch 4754/5000\n",
      "134/134 [==============================] - 0s 324us/step - loss: 254813.7208 - val_loss: 112238.0704\n",
      "Epoch 4755/5000\n",
      "134/134 [==============================] - 0s 426us/step - loss: 107616.5321 - val_loss: 97865.8466\n",
      "Epoch 4756/5000\n",
      "134/134 [==============================] - 0s 391us/step - loss: 95393.7570 - val_loss: 94543.5127\n",
      "Epoch 4757/5000\n",
      "134/134 [==============================] - 0s 392us/step - loss: 97429.5664 - val_loss: 92564.4741\n",
      "Epoch 4758/5000\n",
      "134/134 [==============================] - 0s 341us/step - loss: 97269.8515 - val_loss: 91883.2289\n",
      "Epoch 4759/5000\n",
      "134/134 [==============================] - 0s 398us/step - loss: 95492.0981 - val_loss: 91822.0968\n",
      "Epoch 4760/5000\n",
      "134/134 [==============================] - 0s 384us/step - loss: 95514.6985 - val_loss: 94186.6764\n",
      "Epoch 4761/5000\n",
      "134/134 [==============================] - 0s 349us/step - loss: 103426.0120 - val_loss: 119667.6181\n",
      "Epoch 4762/5000\n",
      "134/134 [==============================] - 0s 332us/step - loss: 134161.7924 - val_loss: 105492.6357\n",
      "Epoch 4763/5000\n",
      "134/134 [==============================] - 0s 343us/step - loss: 132527.7463 - val_loss: 153711.1803\n",
      "Epoch 4764/5000\n",
      "134/134 [==============================] - 0s 393us/step - loss: 137523.6565 - val_loss: 283210.6087\n",
      "Epoch 4765/5000\n",
      "134/134 [==============================] - 0s 389us/step - loss: 178800.3622 - val_loss: 135895.3793\n",
      "Epoch 4766/5000\n",
      "134/134 [==============================] - 0s 330us/step - loss: 176137.4370 - val_loss: 667777.0886\n",
      "Epoch 4767/5000\n",
      "134/134 [==============================] - 0s 337us/step - loss: 473696.9192 - val_loss: 144544.3573\n",
      "Epoch 4768/5000\n",
      "134/134 [==============================] - 0s 341us/step - loss: 149049.6693 - val_loss: 97921.8647\n",
      "Epoch 4769/5000\n",
      "134/134 [==============================] - 0s 364us/step - loss: 101324.4779 - val_loss: 93428.1900\n",
      "Epoch 4770/5000\n",
      "134/134 [==============================] - 0s 335us/step - loss: 96396.2914 - val_loss: 93676.3105\n",
      "Epoch 4771/5000\n",
      "134/134 [==============================] - 0s 377us/step - loss: 97545.8755 - val_loss: 100783.5271\n",
      "Epoch 4772/5000\n",
      "134/134 [==============================] - 0s 388us/step - loss: 98556.1185 - val_loss: 94949.8291\n",
      "Epoch 4773/5000\n",
      "134/134 [==============================] - 0s 353us/step - loss: 98658.0704 - val_loss: 94453.7008\n",
      "Epoch 4774/5000\n",
      "134/134 [==============================] - 0s 365us/step - loss: 96011.9832 - val_loss: 98099.7391\n",
      "Epoch 4775/5000\n",
      "134/134 [==============================] - 0s 423us/step - loss: 96332.0791 - val_loss: 104067.3186\n",
      "Epoch 4776/5000\n",
      "134/134 [==============================] - 0s 394us/step - loss: 109669.0246 - val_loss: 185184.3762\n",
      "Epoch 4777/5000\n",
      "134/134 [==============================] - 0s 432us/step - loss: 120210.7780 - val_loss: 359088.6189\n",
      "Epoch 4778/5000\n",
      "134/134 [==============================] - 0s 390us/step - loss: 134332.7753 - val_loss: 131133.0793\n",
      "Epoch 4779/5000\n",
      "134/134 [==============================] - 0s 364us/step - loss: 160407.8870 - val_loss: 112204.9748\n",
      "Epoch 4780/5000\n",
      "134/134 [==============================] - 0s 339us/step - loss: 122858.9035 - val_loss: 105332.1933\n",
      "Epoch 4781/5000\n",
      "134/134 [==============================] - 0s 410us/step - loss: 101045.7814 - val_loss: 122086.3447\n",
      "Epoch 4782/5000\n",
      "134/134 [==============================] - 0s 387us/step - loss: 121439.8637 - val_loss: 280686.7766\n",
      "Epoch 4783/5000\n",
      "134/134 [==============================] - 0s 320us/step - loss: 179778.7554 - val_loss: 189823.8829\n",
      "Epoch 4784/5000\n",
      "134/134 [==============================] - 0s 356us/step - loss: 176490.3853 - val_loss: 362385.0751\n",
      "Epoch 4785/5000\n",
      "134/134 [==============================] - 0s 424us/step - loss: 309298.7293 - val_loss: 254986.7971\n",
      "Epoch 4786/5000\n",
      "134/134 [==============================] - 0s 397us/step - loss: 357093.6813 - val_loss: 150980.1442\n",
      "Epoch 4787/5000\n",
      "134/134 [==============================] - 0s 397us/step - loss: 275408.2333 - val_loss: 139362.3853\n",
      "Epoch 4788/5000\n",
      "134/134 [==============================] - 0s 343us/step - loss: 175891.4596 - val_loss: 147896.5837\n",
      "Epoch 4789/5000\n",
      "134/134 [==============================] - 0s 315us/step - loss: 192486.7407 - val_loss: 316621.4277\n",
      "Epoch 4790/5000\n",
      "134/134 [==============================] - 0s 359us/step - loss: 156373.7930 - val_loss: 140732.3568\n",
      "Epoch 4791/5000\n",
      "134/134 [==============================] - 0s 362us/step - loss: 292585.8967 - val_loss: 335451.6623\n",
      "Epoch 4792/5000\n",
      "134/134 [==============================] - 0s 413us/step - loss: 192907.5086 - val_loss: 198616.9178\n",
      "Epoch 4793/5000\n",
      "134/134 [==============================] - 0s 399us/step - loss: 147756.3660 - val_loss: 112953.1901\n",
      "Epoch 4794/5000\n",
      "134/134 [==============================] - 0s 333us/step - loss: 99596.6057 - val_loss: 98207.5721\n",
      "Epoch 4795/5000\n",
      "134/134 [==============================] - 0s 310us/step - loss: 105000.6406 - val_loss: 113769.9220\n",
      "Epoch 4796/5000\n",
      "134/134 [==============================] - 0s 356us/step - loss: 103513.6330 - val_loss: 115659.1433\n",
      "Epoch 4797/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 114561.9552 - val_loss: 155427.6959\n",
      "Epoch 4798/5000\n",
      "134/134 [==============================] - 0s 328us/step - loss: 115191.3505 - val_loss: 99647.5170\n",
      "Epoch 4799/5000\n",
      "134/134 [==============================] - 0s 306us/step - loss: 124048.1549 - val_loss: 114937.2185\n",
      "Epoch 4800/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 350us/step - loss: 104673.8322 - val_loss: 112540.2530\n",
      "Epoch 4801/5000\n",
      "134/134 [==============================] - 0s 378us/step - loss: 109564.6964 - val_loss: 151660.5429\n",
      "Epoch 4802/5000\n",
      "134/134 [==============================] - 0s 415us/step - loss: 124885.4040 - val_loss: 271385.5805\n",
      "Epoch 4803/5000\n",
      "134/134 [==============================] - 0s 352us/step - loss: 254353.3902 - val_loss: 380544.5833\n",
      "Epoch 4804/5000\n",
      "134/134 [==============================] - 0s 315us/step - loss: 156788.2578 - val_loss: 126359.1465\n",
      "Epoch 4805/5000\n",
      "134/134 [==============================] - 0s 319us/step - loss: 200101.3204 - val_loss: 181593.5343\n",
      "Epoch 4806/5000\n",
      "134/134 [==============================] - 0s 322us/step - loss: 193273.9198 - val_loss: 260797.6399\n",
      "Epoch 4807/5000\n",
      "134/134 [==============================] - 0s 370us/step - loss: 190380.7596 - val_loss: 148018.6355\n",
      "Epoch 4808/5000\n",
      "134/134 [==============================] - 0s 365us/step - loss: 145110.6568 - val_loss: 195197.1278\n",
      "Epoch 4809/5000\n",
      "134/134 [==============================] - 0s 440us/step - loss: 139708.7528 - val_loss: 179632.7869\n",
      "Epoch 4810/5000\n",
      "134/134 [==============================] - 0s 404us/step - loss: 135988.3124 - val_loss: 95996.2976\n",
      "Epoch 4811/5000\n",
      "134/134 [==============================] - 0s 326us/step - loss: 100898.2764 - val_loss: 93173.1893\n",
      "Epoch 4812/5000\n",
      "134/134 [==============================] - 0s 338us/step - loss: 95317.2392 - val_loss: 93797.8232\n",
      "Epoch 4813/5000\n",
      "134/134 [==============================] - 0s 341us/step - loss: 94126.7659 - val_loss: 101405.9056\n",
      "Epoch 4814/5000\n",
      "134/134 [==============================] - 0s 303us/step - loss: 101705.4885 - val_loss: 135649.8159\n",
      "Epoch 4815/5000\n",
      "134/134 [==============================] - 0s 357us/step - loss: 163076.6297 - val_loss: 234708.5040\n",
      "Epoch 4816/5000\n",
      "134/134 [==============================] - 0s 341us/step - loss: 174943.7161 - val_loss: 106425.6360\n",
      "Epoch 4817/5000\n",
      "134/134 [==============================] - 0s 384us/step - loss: 137218.0436 - val_loss: 215388.6532\n",
      "Epoch 4818/5000\n",
      "134/134 [==============================] - 0s 445us/step - loss: 357154.0668 - val_loss: 139713.1199\n",
      "Epoch 4819/5000\n",
      "134/134 [==============================] - 0s 408us/step - loss: 131214.7359 - val_loss: 210431.5184\n",
      "Epoch 4820/5000\n",
      "134/134 [==============================] - 0s 347us/step - loss: 150011.9958 - val_loss: 105906.4258\n",
      "Epoch 4821/5000\n",
      "134/134 [==============================] - 0s 379us/step - loss: 96080.9613 - val_loss: 98268.6138\n",
      "Epoch 4822/5000\n",
      "134/134 [==============================] - 0s 338us/step - loss: 97975.5984 - val_loss: 99693.4036\n",
      "Epoch 4823/5000\n",
      "134/134 [==============================] - 0s 366us/step - loss: 96981.9703 - val_loss: 100013.8496\n",
      "Epoch 4824/5000\n",
      "134/134 [==============================] - 0s 397us/step - loss: 105284.1229 - val_loss: 155079.6646\n",
      "Epoch 4825/5000\n",
      "134/134 [==============================] - 0s 369us/step - loss: 113131.6578 - val_loss: 102572.7045\n",
      "Epoch 4826/5000\n",
      "134/134 [==============================] - 0s 325us/step - loss: 108014.8331 - val_loss: 244851.2915\n",
      "Epoch 4827/5000\n",
      "134/134 [==============================] - 0s 331us/step - loss: 212897.1762 - val_loss: 415055.7505\n",
      "Epoch 4828/5000\n",
      "134/134 [==============================] - 0s 374us/step - loss: 205439.6818 - val_loss: 105555.9802\n",
      "Epoch 4829/5000\n",
      "134/134 [==============================] - ETA: 0s - loss: 271273.25 - 0s 387us/step - loss: 101903.8780 - val_loss: 97790.9886\n",
      "Epoch 4830/5000\n",
      "134/134 [==============================] - 0s 374us/step - loss: 100346.0823 - val_loss: 116081.0676\n",
      "Epoch 4831/5000\n",
      "134/134 [==============================] - 0s 358us/step - loss: 113214.9426 - val_loss: 99654.4286\n",
      "Epoch 4832/5000\n",
      "134/134 [==============================] - 0s 371us/step - loss: 107931.2561 - val_loss: 102638.3041\n",
      "Epoch 4833/5000\n",
      "134/134 [==============================] - 0s 320us/step - loss: 101136.0252 - val_loss: 95132.5886\n",
      "Epoch 4834/5000\n",
      "134/134 [==============================] - 0s 476us/step - loss: 102171.9825 - val_loss: 154911.3104\n",
      "Epoch 4835/5000\n",
      "134/134 [==============================] - 0s 363us/step - loss: 110206.1763 - val_loss: 138580.4216\n",
      "Epoch 4836/5000\n",
      "134/134 [==============================] - 0s 397us/step - loss: 158175.7982 - val_loss: 244111.6098\n",
      "Epoch 4837/5000\n",
      "134/134 [==============================] - 0s 352us/step - loss: 211294.3808 - val_loss: 115218.5341\n",
      "Epoch 4838/5000\n",
      "134/134 [==============================] - 0s 365us/step - loss: 136154.1605 - val_loss: 93355.9627\n",
      "Epoch 4839/5000\n",
      "134/134 [==============================] - 0s 417us/step - loss: 95477.9249 - val_loss: 172884.8790\n",
      "Epoch 4840/5000\n",
      "134/134 [==============================] - 0s 776us/step - loss: 119254.4709 - val_loss: 95949.2832\n",
      "Epoch 4841/5000\n",
      "134/134 [==============================] - 0s 375us/step - loss: 100998.3293 - val_loss: 270877.4105\n",
      "Epoch 4842/5000\n",
      "134/134 [==============================] - 0s 345us/step - loss: 137683.6113 - val_loss: 122182.6817\n",
      "Epoch 4843/5000\n",
      "134/134 [==============================] - 0s 375us/step - loss: 133883.9183 - val_loss: 112503.6704\n",
      "Epoch 4844/5000\n",
      "134/134 [==============================] - 0s 372us/step - loss: 135508.1753 - val_loss: 123791.6698\n",
      "Epoch 4845/5000\n",
      "134/134 [==============================] - 0s 397us/step - loss: 143236.1872 - val_loss: 281121.8190\n",
      "Epoch 4846/5000\n",
      "134/134 [==============================] - 0s 369us/step - loss: 180799.7729 - val_loss: 246995.5345\n",
      "Epoch 4847/5000\n",
      "134/134 [==============================] - 0s 340us/step - loss: 197150.7316 - val_loss: 327406.5042\n",
      "Epoch 4848/5000\n",
      "134/134 [==============================] - 0s 333us/step - loss: 142472.0375 - val_loss: 104839.8050\n",
      "Epoch 4849/5000\n",
      "134/134 [==============================] - 0s 356us/step - loss: 116098.7940 - val_loss: 113868.7829\n",
      "Epoch 4850/5000\n",
      "134/134 [==============================] - 0s 361us/step - loss: 124106.3125 - val_loss: 176271.1678\n",
      "Epoch 4851/5000\n",
      "134/134 [==============================] - 0s 558us/step - loss: 176495.5038 - val_loss: 108332.6793\n",
      "Epoch 4852/5000\n",
      "134/134 [==============================] - 0s 459us/step - loss: 107114.9251 - val_loss: 99917.2540\n",
      "Epoch 4853/5000\n",
      "134/134 [==============================] - 0s 479us/step - loss: 112476.2715 - val_loss: 155972.2882\n",
      "Epoch 4854/5000\n",
      "134/134 [==============================] - 0s 361us/step - loss: 110931.6281 - val_loss: 100360.5554\n",
      "Epoch 4855/5000\n",
      "134/134 [==============================] - 0s 330us/step - loss: 100685.9092 - val_loss: 144933.3159\n",
      "Epoch 4856/5000\n",
      "134/134 [==============================] - 0s 297us/step - loss: 122675.9943 - val_loss: 121289.9986\n",
      "Epoch 4857/5000\n",
      "134/134 [==============================] - 0s 346us/step - loss: 131065.9187 - val_loss: 127485.6783\n",
      "Epoch 4858/5000\n",
      "134/134 [==============================] - 0s 313us/step - loss: 141849.0862 - val_loss: 209338.1959\n",
      "Epoch 4859/5000\n",
      "134/134 [==============================] - 0s 312us/step - loss: 125031.5660 - val_loss: 327117.6182\n",
      "Epoch 4860/5000\n",
      "134/134 [==============================] - 0s 315us/step - loss: 194776.0701 - val_loss: 205273.9359\n",
      "Epoch 4861/5000\n",
      "134/134 [==============================] - 0s 337us/step - loss: 243740.3426 - val_loss: 209978.2813\n",
      "Epoch 4862/5000\n",
      "134/134 [==============================] - 0s 374us/step - loss: 128181.2099 - val_loss: 103378.0511\n",
      "Epoch 4863/5000\n",
      "134/134 [==============================] - 0s 356us/step - loss: 124969.0912 - val_loss: 389161.2085\n",
      "Epoch 4864/5000\n",
      "134/134 [==============================] - 0s 342us/step - loss: 144053.2968 - val_loss: 149045.7760\n",
      "Epoch 4865/5000\n",
      "134/134 [==============================] - 0s 383us/step - loss: 128336.4530 - val_loss: 103310.8932\n",
      "Epoch 4866/5000\n",
      "134/134 [==============================] - 0s 381us/step - loss: 107040.6502 - val_loss: 100774.3787\n",
      "Epoch 4867/5000\n",
      "134/134 [==============================] - 0s 360us/step - loss: 99832.2257 - val_loss: 94414.0475\n",
      "Epoch 4868/5000\n",
      "134/134 [==============================] - 0s 361us/step - loss: 99837.8033 - val_loss: 172459.7593\n",
      "Epoch 4869/5000\n",
      "134/134 [==============================] - 0s 361us/step - loss: 171123.8207 - val_loss: 180636.9916\n",
      "Epoch 4870/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 367us/step - loss: 140097.9584 - val_loss: 165001.7780\n",
      "Epoch 4871/5000\n",
      "134/134 [==============================] - 0s 342us/step - loss: 201367.9375 - val_loss: 143513.2003\n",
      "Epoch 4872/5000\n",
      "134/134 [==============================] - 0s 334us/step - loss: 225615.4593 - val_loss: 111414.6821\n",
      "Epoch 4873/5000\n",
      "134/134 [==============================] - 0s 378us/step - loss: 115882.2344 - val_loss: 121051.2893\n",
      "Epoch 4874/5000\n",
      "134/134 [==============================] - 0s 351us/step - loss: 117297.9952 - val_loss: 147015.5895\n",
      "Epoch 4875/5000\n",
      "134/134 [==============================] - 0s 390us/step - loss: 128391.0717 - val_loss: 285148.3848\n",
      "Epoch 4876/5000\n",
      "134/134 [==============================] - 0s 349us/step - loss: 217894.0831 - val_loss: 185103.6772\n",
      "Epoch 4877/5000\n",
      "134/134 [==============================] - 0s 347us/step - loss: 301877.9586 - val_loss: 110260.7360\n",
      "Epoch 4878/5000\n",
      "134/134 [==============================] - 0s 324us/step - loss: 108973.8451 - val_loss: 104950.0758\n",
      "Epoch 4879/5000\n",
      "134/134 [==============================] - 0s 392us/step - loss: 111274.2106 - val_loss: 92970.4116\n",
      "Epoch 4880/5000\n",
      "134/134 [==============================] - 0s 347us/step - loss: 101064.8223 - val_loss: 92310.3223\n",
      "Epoch 4881/5000\n",
      "134/134 [==============================] - 0s 505us/step - loss: 94784.5379 - val_loss: 92335.6599\n",
      "Epoch 4882/5000\n",
      "134/134 [==============================] - 0s 407us/step - loss: 97692.2079 - val_loss: 98620.3115\n",
      "Epoch 4883/5000\n",
      "134/134 [==============================] - 0s 385us/step - loss: 101300.0005 - val_loss: 241622.1101\n",
      "Epoch 4884/5000\n",
      "134/134 [==============================] - 0s 361us/step - loss: 231464.8893 - val_loss: 101538.6722\n",
      "Epoch 4885/5000\n",
      "134/134 [==============================] - 0s 411us/step - loss: 107516.6600 - val_loss: 197463.7898\n",
      "Epoch 4886/5000\n",
      "134/134 [==============================] - 0s 774us/step - loss: 113738.9595 - val_loss: 111096.5027\n",
      "Epoch 4887/5000\n",
      "134/134 [==============================] - 0s 420us/step - loss: 123564.2502 - val_loss: 109902.1086\n",
      "Epoch 4888/5000\n",
      "134/134 [==============================] - 0s 482us/step - loss: 130904.2529 - val_loss: 124103.3449\n",
      "Epoch 4889/5000\n",
      "134/134 [==============================] - 0s 462us/step - loss: 117459.7131 - val_loss: 133360.8431\n",
      "Epoch 4890/5000\n",
      "134/134 [==============================] - 0s 512us/step - loss: 107397.2821 - val_loss: 109562.0485\n",
      "Epoch 4891/5000\n",
      "134/134 [==============================] - 0s 398us/step - loss: 115597.6651 - val_loss: 128700.0434\n",
      "Epoch 4892/5000\n",
      "134/134 [==============================] - 0s 438us/step - loss: 109374.4555 - val_loss: 352280.1388\n",
      "Epoch 4893/5000\n",
      "134/134 [==============================] - 0s 562us/step - loss: 182968.2015 - val_loss: 121825.4609\n",
      "Epoch 4894/5000\n",
      "134/134 [==============================] - 0s 546us/step - loss: 118554.6231 - val_loss: 125216.2664\n",
      "Epoch 4895/5000\n",
      "134/134 [==============================] - 0s 415us/step - loss: 105272.4889 - val_loss: 107874.1437\n",
      "Epoch 4896/5000\n",
      "134/134 [==============================] - 0s 432us/step - loss: 100602.2137 - val_loss: 92925.7190\n",
      "Epoch 4897/5000\n",
      "134/134 [==============================] - 0s 447us/step - loss: 99955.6164 - val_loss: 95230.6784\n",
      "Epoch 4898/5000\n",
      "134/134 [==============================] - 0s 397us/step - loss: 102588.2910 - val_loss: 119159.7674\n",
      "Epoch 4899/5000\n",
      "134/134 [==============================] - 0s 448us/step - loss: 153032.5829 - val_loss: 102428.1896\n",
      "Epoch 4900/5000\n",
      "134/134 [==============================] - 0s 397us/step - loss: 107110.4816 - val_loss: 93885.6327\n",
      "Epoch 4901/5000\n",
      "134/134 [==============================] - 0s 375us/step - loss: 105256.7215 - val_loss: 564548.3265\n",
      "Epoch 4902/5000\n",
      "134/134 [==============================] - 0s 406us/step - loss: 174711.4971 - val_loss: 104352.8748\n",
      "Epoch 4903/5000\n",
      "134/134 [==============================] - 0s 431us/step - loss: 107002.1835 - val_loss: 186992.8573\n",
      "Epoch 4904/5000\n",
      "134/134 [==============================] - 0s 355us/step - loss: 160675.0825 - val_loss: 102269.6318\n",
      "Epoch 4905/5000\n",
      "134/134 [==============================] - 0s 409us/step - loss: 124134.8030 - val_loss: 123368.5914\n",
      "Epoch 4906/5000\n",
      "134/134 [==============================] - 0s 334us/step - loss: 206926.7210 - val_loss: 174520.8088\n",
      "Epoch 4907/5000\n",
      "134/134 [==============================] - 0s 373us/step - loss: 126538.1702 - val_loss: 114919.5112\n",
      "Epoch 4908/5000\n",
      "134/134 [==============================] - 0s 374us/step - loss: 132457.4401 - val_loss: 131827.7421\n",
      "Epoch 4909/5000\n",
      "134/134 [==============================] - 0s 338us/step - loss: 116209.0099 - val_loss: 97312.6749\n",
      "Epoch 4910/5000\n",
      "134/134 [==============================] - 0s 357us/step - loss: 103160.9689 - val_loss: 117949.2906\n",
      "Epoch 4911/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 119742.7069 - val_loss: 100327.8780\n",
      "Epoch 4912/5000\n",
      "134/134 [==============================] - 0s 342us/step - loss: 115490.1726 - val_loss: 108180.9220\n",
      "Epoch 4913/5000\n",
      "134/134 [==============================] - 0s 374us/step - loss: 110549.3027 - val_loss: 195820.0484\n",
      "Epoch 4914/5000\n",
      "134/134 [==============================] - 0s 424us/step - loss: 139019.6415 - val_loss: 149147.3016\n",
      "Epoch 4915/5000\n",
      "134/134 [==============================] - 0s 371us/step - loss: 265664.3966 - val_loss: 107540.6165\n",
      "Epoch 4916/5000\n",
      "134/134 [==============================] - 0s 420us/step - loss: 176506.2989 - val_loss: 184085.0816\n",
      "Epoch 4917/5000\n",
      "134/134 [==============================] - 0s 494us/step - loss: 126748.8057 - val_loss: 102167.5512\n",
      "Epoch 4918/5000\n",
      "134/134 [==============================] - 0s 500us/step - loss: 102159.3660 - val_loss: 96004.4965\n",
      "Epoch 4919/5000\n",
      "134/134 [==============================] - 0s 440us/step - loss: 105888.0778 - val_loss: 94765.4907\n",
      "Epoch 4920/5000\n",
      "134/134 [==============================] - 0s 435us/step - loss: 100413.8243 - val_loss: 90903.7561\n",
      "Epoch 4921/5000\n",
      "134/134 [==============================] - 0s 395us/step - loss: 121951.2889 - val_loss: 108166.3825\n",
      "Epoch 4922/5000\n",
      "134/134 [==============================] - 0s 513us/step - loss: 107149.8557 - val_loss: 109141.0464\n",
      "Epoch 4923/5000\n",
      "134/134 [==============================] - 0s 437us/step - loss: 203498.8715 - val_loss: 680829.0019\n",
      "Epoch 4924/5000\n",
      "134/134 [==============================] - 0s 866us/step - loss: 247523.6446 - val_loss: 99138.3617\n",
      "Epoch 4925/5000\n",
      "134/134 [==============================] - 0s 546us/step - loss: 105489.1357 - val_loss: 94407.8299\n",
      "Epoch 4926/5000\n",
      "134/134 [==============================] - 0s 623us/step - loss: 96140.4103 - val_loss: 92338.4442\n",
      "Epoch 4927/5000\n",
      "134/134 [==============================] - 0s 531us/step - loss: 92443.3260 - val_loss: 99325.6326\n",
      "Epoch 4928/5000\n",
      "134/134 [==============================] - 0s 582us/step - loss: 95021.4939 - val_loss: 88995.1832\n",
      "Epoch 4929/5000\n",
      "134/134 [==============================] - 0s 498us/step - loss: 89890.5951 - val_loss: 87168.5121\n",
      "Epoch 4930/5000\n",
      "134/134 [==============================] - 0s 377us/step - loss: 90249.8039 - val_loss: 86179.4145\n",
      "Epoch 4931/5000\n",
      "134/134 [==============================] - 0s 412us/step - loss: 89959.8797 - val_loss: 87558.6393\n",
      "Epoch 4932/5000\n",
      "134/134 [==============================] - 0s 423us/step - loss: 97838.0648 - val_loss: 102483.3554\n",
      "Epoch 4933/5000\n",
      "134/134 [==============================] - 0s 447us/step - loss: 107031.5304 - val_loss: 172368.7149\n",
      "Epoch 4934/5000\n",
      "134/134 [==============================] - 0s 451us/step - loss: 134314.1396 - val_loss: 150148.6413\n",
      "Epoch 4935/5000\n",
      "134/134 [==============================] - 0s 386us/step - loss: 131368.5276 - val_loss: 215664.6080\n",
      "Epoch 4936/5000\n",
      "134/134 [==============================] - 0s 481us/step - loss: 281173.1844 - val_loss: 149686.2971\n",
      "Epoch 4937/5000\n",
      "134/134 [==============================] - 0s 349us/step - loss: 115141.3681 - val_loss: 229434.1384\n",
      "Epoch 4938/5000\n",
      "134/134 [==============================] - 0s 387us/step - loss: 216046.8708 - val_loss: 160122.0665\n",
      "Epoch 4939/5000\n",
      "134/134 [==============================] - 0s 438us/step - loss: 190475.5608 - val_loss: 95582.4894\n",
      "Epoch 4940/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134/134 [==============================] - 0s 432us/step - loss: 110211.0362 - val_loss: 117954.9246\n",
      "Epoch 4941/5000\n",
      "134/134 [==============================] - 0s 415us/step - loss: 113429.0425 - val_loss: 145009.6937\n",
      "Epoch 4942/5000\n",
      "134/134 [==============================] - 0s 432us/step - loss: 135037.9121 - val_loss: 126263.9515\n",
      "Epoch 4943/5000\n",
      "134/134 [==============================] - 0s 609us/step - loss: 132769.5738 - val_loss: 147346.8899\n",
      "Epoch 4944/5000\n",
      "134/134 [==============================] - 0s 527us/step - loss: 113412.7007 - val_loss: 200328.6670\n",
      "Epoch 4945/5000\n",
      "134/134 [==============================] - 0s 471us/step - loss: 146235.3215 - val_loss: 297236.8981\n",
      "Epoch 4946/5000\n",
      "134/134 [==============================] - 0s 514us/step - loss: 210509.0086 - val_loss: 132660.0381\n",
      "Epoch 4947/5000\n",
      "134/134 [==============================] - 0s 543us/step - loss: 116650.2351 - val_loss: 94447.3174\n",
      "Epoch 4948/5000\n",
      "134/134 [==============================] - 0s 494us/step - loss: 102154.5186 - val_loss: 97008.1783\n",
      "Epoch 4949/5000\n",
      "134/134 [==============================] - 0s 417us/step - loss: 98952.0798 - val_loss: 94092.0348\n",
      "Epoch 4950/5000\n",
      "134/134 [==============================] - 0s 493us/step - loss: 94871.2680 - val_loss: 88142.9281\n",
      "Epoch 4951/5000\n",
      "134/134 [==============================] - 0s 423us/step - loss: 93533.7185 - val_loss: 100395.3660\n",
      "Epoch 4952/5000\n",
      "134/134 [==============================] - 0s 394us/step - loss: 101195.8909 - val_loss: 103258.3533\n",
      "Epoch 4953/5000\n",
      "134/134 [==============================] - 0s 407us/step - loss: 122351.3392 - val_loss: 108214.6429\n",
      "Epoch 4954/5000\n",
      "134/134 [==============================] - 0s 386us/step - loss: 137529.2917 - val_loss: 301738.9762\n",
      "Epoch 4955/5000\n",
      "134/134 [==============================] - 0s 388us/step - loss: 137099.1628 - val_loss: 105916.3476\n",
      "Epoch 4956/5000\n",
      "134/134 [==============================] - 0s 419us/step - loss: 120144.4813 - val_loss: 110138.8841\n",
      "Epoch 4957/5000\n",
      "134/134 [==============================] - 0s 454us/step - loss: 99493.1342 - val_loss: 96217.9098\n",
      "Epoch 4958/5000\n",
      "134/134 [==============================] - 0s 389us/step - loss: 115974.7197 - val_loss: 286168.9716\n",
      "Epoch 4959/5000\n",
      "134/134 [==============================] - 0s 435us/step - loss: 281654.0114 - val_loss: 563290.6521\n",
      "Epoch 4960/5000\n",
      "134/134 [==============================] - 0s 422us/step - loss: 383579.7829 - val_loss: 165177.4334\n",
      "Epoch 4961/5000\n",
      "134/134 [==============================] - 0s 425us/step - loss: 166150.6268 - val_loss: 127482.7965\n",
      "Epoch 4962/5000\n",
      "134/134 [==============================] - 0s 462us/step - loss: 101806.6557 - val_loss: 276108.8568\n",
      "Epoch 4963/5000\n",
      "134/134 [==============================] - 0s 417us/step - loss: 147439.9118 - val_loss: 114309.9744\n",
      "Epoch 4964/5000\n",
      "134/134 [==============================] - 0s 474us/step - loss: 114218.1405 - val_loss: 102484.0240\n",
      "Epoch 4965/5000\n",
      "134/134 [==============================] - 0s 513us/step - loss: 103340.4016 - val_loss: 101689.3197\n",
      "Epoch 4966/5000\n",
      "134/134 [==============================] - 0s 509us/step - loss: 97444.4990 - val_loss: 93459.4531\n",
      "Epoch 4967/5000\n",
      "134/134 [==============================] - 0s 424us/step - loss: 115113.4170 - val_loss: 192001.6619\n",
      "Epoch 4968/5000\n",
      "134/134 [==============================] - 0s 413us/step - loss: 123682.0856 - val_loss: 254384.5609\n",
      "Epoch 4969/5000\n",
      "134/134 [==============================] - 0s 455us/step - loss: 191911.1003 - val_loss: 127031.3183\n",
      "Epoch 4970/5000\n",
      "134/134 [==============================] - 0s 431us/step - loss: 135871.7454 - val_loss: 101638.7099\n",
      "Epoch 4971/5000\n",
      "134/134 [==============================] - 0s 410us/step - loss: 127758.0082 - val_loss: 135188.3195\n",
      "Epoch 4972/5000\n",
      "134/134 [==============================] - 0s 391us/step - loss: 142033.4990 - val_loss: 128120.1789\n",
      "Epoch 4973/5000\n",
      "134/134 [==============================] - 0s 463us/step - loss: 130988.0589 - val_loss: 120652.7057\n",
      "Epoch 4974/5000\n",
      "134/134 [==============================] - 0s 438us/step - loss: 186861.6134 - val_loss: 140307.7422\n",
      "Epoch 4975/5000\n",
      "134/134 [==============================] - 0s 466us/step - loss: 196830.1147 - val_loss: 153188.0110\n",
      "Epoch 4976/5000\n",
      "134/134 [==============================] - 0s 442us/step - loss: 110221.4308 - val_loss: 91500.5054\n",
      "Epoch 4977/5000\n",
      "134/134 [==============================] - 0s 445us/step - loss: 102882.8219 - val_loss: 106904.8869\n",
      "Epoch 4978/5000\n",
      "134/134 [==============================] - 0s 409us/step - loss: 104302.3238 - val_loss: 97428.6645\n",
      "Epoch 4979/5000\n",
      "134/134 [==============================] - 0s 405us/step - loss: 155393.7812 - val_loss: 140268.4753\n",
      "Epoch 4980/5000\n",
      "134/134 [==============================] - 0s 353us/step - loss: 117323.8343 - val_loss: 101753.4544\n",
      "Epoch 4981/5000\n",
      "134/134 [==============================] - 0s 364us/step - loss: 158436.5875 - val_loss: 190421.6269\n",
      "Epoch 4982/5000\n",
      "134/134 [==============================] - 0s 338us/step - loss: 166369.4498 - val_loss: 100347.1603\n",
      "Epoch 4983/5000\n",
      "134/134 [==============================] - 0s 349us/step - loss: 109650.0895 - val_loss: 410891.1698\n",
      "Epoch 4984/5000\n",
      "134/134 [==============================] - 0s 319us/step - loss: 363902.5947 - val_loss: 154544.7316\n",
      "Epoch 4985/5000\n",
      "134/134 [==============================] - 0s 316us/step - loss: 164157.5976 - val_loss: 96938.1818\n",
      "Epoch 4986/5000\n",
      "134/134 [==============================] - 0s 491us/step - loss: 124396.0786 - val_loss: 174815.8568\n",
      "Epoch 4987/5000\n",
      "134/134 [==============================] - 0s 443us/step - loss: 128129.5451 - val_loss: 94572.4601\n",
      "Epoch 4988/5000\n",
      "134/134 [==============================] - 0s 390us/step - loss: 104110.1968 - val_loss: 98203.2423\n",
      "Epoch 4989/5000\n",
      "134/134 [==============================] - 0s 426us/step - loss: 93518.4862 - val_loss: 91368.1044\n",
      "Epoch 4990/5000\n",
      "134/134 [==============================] - 0s 375us/step - loss: 97873.2087 - val_loss: 222388.5131\n",
      "Epoch 4991/5000\n",
      "134/134 [==============================] - 0s 517us/step - loss: 178517.7979 - val_loss: 123369.4414\n",
      "Epoch 4992/5000\n",
      "134/134 [==============================] - 0s 408us/step - loss: 127314.8633 - val_loss: 97712.5963\n",
      "Epoch 4993/5000\n",
      "134/134 [==============================] - 0s 396us/step - loss: 118191.7399 - val_loss: 309688.5371\n",
      "Epoch 4994/5000\n",
      "134/134 [==============================] - 0s 380us/step - loss: 161021.0522 - val_loss: 300802.7771\n",
      "Epoch 4995/5000\n",
      "134/134 [==============================] - 0s 449us/step - loss: 179820.9120 - val_loss: 117235.2356\n",
      "Epoch 4996/5000\n",
      "134/134 [==============================] - 0s 462us/step - loss: 146987.5178 - val_loss: 109017.0546\n",
      "Epoch 4997/5000\n",
      "134/134 [==============================] - 0s 429us/step - loss: 138971.6588 - val_loss: 318266.6908\n",
      "Epoch 4998/5000\n",
      "134/134 [==============================] - 0s 412us/step - loss: 172493.8414 - val_loss: 171010.0343\n",
      "Epoch 4999/5000\n",
      "134/134 [==============================] - 0s 433us/step - loss: 195875.9985 - val_loss: 105406.7249\n",
      "Epoch 5000/5000\n",
      "134/134 [==============================] - 0s 403us/step - loss: 132650.5869 - val_loss: 128588.8581\n"
     ]
    }
   ],
   "source": [
    "inputs_weather = Input(shape=(10,),name='weather')\n",
    "# weather model\n",
    "x1 = Dense(32, activation='relu',name='wea_layer_1')(inputs_weather)\n",
    "x1 = Dense(32, activation='relu',name='wea_layer_2')(x1)\n",
    "x1 = Dense(32, activation='relu',name='wea_layer_3')(x1)\n",
    "out_x1 = Dense(6,activation='relu',name='weather_output')(x1)\n",
    "#model1 = Model(inputs=inputs_weather, outputs=out_x1)\n",
    "\n",
    "\n",
    "inputs_stationary = Input(shape=(6,),name='stationary')\n",
    "# stationary model\n",
    "x2 = Dense(32, activation='relu',name='stat_layer_1')(inputs_stationary)\n",
    "x2 = Dense(32, activation='relu',name='stat_layer_2')(x2)\n",
    "x2 = Dense(32, activation='relu',name='stat_layer_3')(x2)\n",
    "out_x2 = Dense(6,activation='relu',name='stationary_output')(x2)\n",
    "#model2 = Model(inputs=inputs_stationary, outputs=out_x2)\n",
    "\n",
    "#GPS_input = Input(shape=(3,),name='GPS_value')\n",
    "GPS_label = Input(shape=(1,),name='GPS_label')\n",
    "#middle_layer = concatenate([out_x1,out_x2,GPS_input,GPS_label],axis=1)\n",
    "middle_layer = concatenate([out_x1,out_x2,GPS_label],axis=1)\n",
    "\n",
    "# merge models\n",
    "x = Dense(32, activation='relu', name='weighted')(middle_layer)\n",
    "main_out = Dense(6, activation='relu',name='main_output')(x)\n",
    "\n",
    "merged_model = Model(inputs=[inputs_weather,inputs_stationary,GPS_label], outputs=[main_out])\n",
    "\n",
    "\n",
    "adadelta = keras.optimizers.Adadelta(lr=1.0, rho=0.95, epsilon=None, decay=0.0)\n",
    "merged_model.compile(loss='mean_squared_error', optimizer='adadelta')\n",
    "#history = merged_model.fit([X_train_weather, X_train_stationary,X_train_GPS,GPS_label_train], y_train, validation_data=([X_train_weather, X_train_stationary,X_train_GPS,GPS_label_train], y_train), batch_size=16, epochs=5000)\n",
    "history = merged_model.fit([X_train_weather, X_train_stationary,GPS_label_train], y_train, validation_data=([X_train_weather, X_train_stationary,GPS_label_train], y_train), batch_size=16, epochs=5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.yscale('log')\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#y_pred = merged_model.predict([X_test_weather,X_test_stationary,X_test_GPS, GPS_label_test])\n",
    "y_pred = merged_model.predict([X_test_weather,X_test_stationary, GPS_label_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(y_test,y_pred, color = 'red')\n",
    "plt.title('Weighted Function Prediction')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22578520.699758116\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "print mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
